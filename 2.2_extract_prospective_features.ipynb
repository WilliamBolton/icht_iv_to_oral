{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1687870532643
        }
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 40)\n",
        "pd.set_option('display.width', 2000)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from sktime.transformations.panel.catch22 import Catch22\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1687870537226
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Supress mean of empty slice warning\n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1687871156521
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/antibiotic_po_flag_2023.csv'\n",
        "antibiotic_df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1687775650821
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3217"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "3431"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "antibiotic_df.SUBJECT.nunique()\n",
        "antibiotic_df.SPELL_IDENTIFIER.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1687775859304
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save text file to get subjects to filter for sql\n",
        "np.savetxt(\"antibiotic_subjects_2023.txt\", antibiotic_df.SUBJECT.unique(), fmt='%s', delimiter=\",\", newline=\"','\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687776943473
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import json, snowflake.connector\n",
        "\n",
        "# establish the connection to snowflake\n",
        "ctx = snowflake.connector.connect( \n",
        "    **json.load(open('/opt/ich/python-snowflake-defaults.json')))\n",
        "    \n",
        "# verify and test if connection is working\n",
        "try: \n",
        "    cs = ctx.cursor() \n",
        "    cs.execute('SELECT current_version(), current_role(), current_warehouse()')\n",
        "    print(cs.fetchone())\n",
        "finally: \n",
        "    cs.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1687777125965
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import \n",
        "query = '''\n",
        "SELECT * from ICHT_SANDBOX_PROD.COVOAM_22016.SWITCH_VITALS_filtered_2023\n",
        "'''\n",
        "cur = ctx.cursor().execute(query)\n",
        "switch_vitals = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1687777189711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Filter columns\n",
        "switch_vitals = switch_vitals[['SUBJECT', 'OBSERVATION_CODE', 'OBSERVATION_NAME', 'OBSERVATION_DATETIME', 'OBSERVATION_START_DATETIME', 'OBSERVATION_END_DATETIME', 'OBSERVATION_RESULT', 'OBSERVATION_RESULT_CLEAN', 'OBSERVATION_UNIT']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1687777229289
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save\n",
        "#switch_vitals.to_csv('switch_data/switch_vitals_filtered_2023.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1687871215569
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_6070/399965645.py:3: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  switch_vitals = pd.read_csv(path)\n"
          ]
        }
      ],
      "source": [
        "# Import\n",
        "path = r'switch_data/switch_vitals_filtered_2023.csv'\n",
        "switch_vitals = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1687777262801
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OBSERVATION_NAME\n",
              "Diastolic Blood Pressure            1\n",
              "Diastolic Blood Pressure Cuff       1\n",
              "Glasgow Coma Score                  0\n",
              "HR - SpO2 (AN)                      1\n",
              "Heart Rate                          1\n",
              "Mean Arterial Pressure, Cuff        1\n",
              "Mean Arterial Pressure, Invasive    1\n",
              "NEWS Conscious Level Score          0\n",
              "NEWS Supplemental Oxygen Calc       0\n",
              "Respiratory Rate                    1\n",
              "SaO2%                               1\n",
              "SpO2                                1\n",
              "SpO2 (AN)                           1\n",
              "Systolic Blood Pressure             1\n",
              "Systolic Blood Pressure Cuff        1\n",
              "Temperature                         1\n",
              "Name: OBSERVATION_UNIT, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Chech units \n",
        "switch_vitals.groupby('OBSERVATION_NAME')['OBSERVATION_UNIT'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1687871269553
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Rename some OBSERVATION_NAME\n",
        "switch_vitals['OBSERVATION_NAME'] = switch_vitals['OBSERVATION_NAME'].replace({'SpO2 (AN)': 'SpO2', 'SaO2%':'SpO2', 'Systolic Blood Pressure Cuff':'Systolic Blood Pressure', 'Diastolic Blood Pressure Cuff':'Diastolic Blood Pressure', 'Mean Arterial Pressure, Cuff': 'Mean Arterial Pressure', 'Mean Arterial Pressure, Invasive': 'Mean Arterial Pressure', 'HR - SpO2 (AN)': 'Heart Rate'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1687871273464
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "array(['Temperature', 'Mean Arterial Pressure', 'Systolic Blood Pressure',\n",
              "       'Diastolic Blood Pressure', 'Heart Rate',\n",
              "       'NEWS Conscious Level Score', 'NEWS Supplemental Oxygen Calc',\n",
              "       'Respiratory Rate', 'Glasgow Coma Score', 'SpO2'], dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "switch_vitals['OBSERVATION_NAME'].nunique()\n",
        "switch_vitals['OBSERVATION_NAME'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1687871831459
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create date column for merge\n",
        "switch_vitals['date'] =  pd.to_datetime(switch_vitals['OBSERVATION_DATETIME']).dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1687871832464
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Conver to datetime \n",
        "switch_vitals['date'] =  pd.to_datetime(switch_vitals['date'])\n",
        "antibiotic_df['ADMINISTRATION_DATETIME'] =  pd.to_datetime(antibiotic_df['ADMINISTRATION_DATETIME'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1687871842983
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Merge\n",
        "antibiotic_vitals = pd.merge(antibiotic_df, switch_vitals, left_on=['SUBJECT', 'ADMINISTRATION_DATETIME'], right_on=['SUBJECT', 'date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1687777493452
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3217"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "3431"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "antibiotic_vitals.SUBJECT.nunique()\n",
        "antibiotic_vitals.SPELL_IDENTIFIER.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1687871859925
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Filter columns\n",
        "antibiotic_vitals = antibiotic_vitals[['SUBJECT', 'SPELL_IDENTIFIER', 'ADMINISTRATION_DATETIME', 'ROUTE', 'po_flag', 'iv_treatment_length', 'OBSERVATION_NAME', 'OBSERVATION_DATETIME', 'OBSERVATION_RESULT_CLEAN', 'date']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1687871861592
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Order\n",
        "antibiotic_vitals.sort_values(by=['SUBJECT', 'SPELL_IDENTIFIER', 'ADMINISTRATION_DATETIME', 'OBSERVATION_NAME', 'OBSERVATION_DATETIME'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1687871863945
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Reset index\n",
        "antibiotic_vitals.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1687777576564
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.386282532634344"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mean number of observations per stay per observation per day\n",
        "antibiotic_vitals.groupby(['SPELL_IDENTIFIER', 'OBSERVATION_NAME', 'date']).size().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687777602517
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create hour column\n",
        "antibiotic_vitals['hour'] =  pd.to_datetime(antibiotic_vitals['OBSERVATION_DATETIME']).dt.hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1687777631979
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def hours_grouped_fun(row):\n",
        "    if row['hour'] < 6:\n",
        "        return 1\n",
        "    elif row['hour'] < 12:\n",
        "        return 2\n",
        "    elif row['hour'] < 18:\n",
        "        return 3\n",
        "    elif row['hour'] < 24:\n",
        "        return 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687777703556
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "antibiotic_vitals['hours_grouped'] = antibiotic_vitals.apply(hours_grouped_fun, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1687777801273
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Pivot\n",
        "antibiotic_vitals_pivoted = pd.pivot_table(antibiotic_vitals, index=['SPELL_IDENTIFIER', 'date', 'hours_grouped'], columns=['OBSERVATION_NAME'], values=['OBSERVATION_RESULT_CLEAN'])\n",
        "antibiotic_vitals_pivoted.columns = antibiotic_vitals_pivoted.columns.droplevel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1687777930068
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def add_all_hours_grouped(df):\n",
        "    final_new_df = pd.DataFrame(columns=df.columns)\n",
        "    spell_list = df['SPELL_IDENTIFIER'].unique().tolist()\n",
        "    for spell in spell_list:\n",
        "        temp_df = df[df['SPELL_IDENTIFIER'] == spell]\n",
        "        temp_df.reset_index(drop=True, inplace=True)\n",
        "        # Convert to str\n",
        "        temp_df['date'] = temp_df['date'].astype(str)\n",
        "        date_list = temp_df['date'].unique().tolist()\n",
        "        for x in range(len(date_list)):\n",
        "            temp_df2 = temp_df[temp_df['date'].isin([date_list[x]])]\n",
        "            temp_df2.reset_index(drop=True, inplace=True)\n",
        "            new_df = pd.DataFrame(columns=temp_df2.columns)\n",
        "\n",
        "            if x == 0:\n",
        "                for i in range(temp_df2['hours_grouped'].iloc[0],5):\n",
        "                    day_df = temp_df2[temp_df2['hours_grouped'] == i]\n",
        "                    if day_df.empty:\n",
        "                        new_df.loc[i] = np.nan\n",
        "                        new_df.loc[i, 'hours_grouped'] = i\n",
        "                        new_df.loc[i, 'SPELL_IDENTIFIER'] = temp_df2.iloc[0]['SPELL_IDENTIFIER']\n",
        "                        new_df.loc[i, 'date'] = temp_df2.iloc[0]['date']\n",
        "                    else:\n",
        "                        new_df = pd.concat([new_df, temp_df2[temp_df2['hours_grouped'] == i]])\n",
        "                    \n",
        "            elif x == len(date_list) - 1:\n",
        "                for i in range(1,temp_df2['hours_grouped'].iloc[-1]+1):\n",
        "                    day_df = temp_df2[temp_df2['hours_grouped'] == i]\n",
        "                    if day_df.empty:\n",
        "                        new_df.loc[i] = np.nan\n",
        "                        new_df.loc[i, 'hours_grouped'] = i\n",
        "                        new_df.loc[i, 'SPELL_IDENTIFIER'] = temp_df2.iloc[0]['SPELL_IDENTIFIER']\n",
        "                        new_df.loc[i, 'date'] = temp_df2.iloc[0]['date']\n",
        "                    else:\n",
        "                        new_df = pd.concat([new_df, temp_df2[temp_df2['hours_grouped'] == i]])\n",
        "            else:\n",
        "                for i in range(1,5):\n",
        "                    day_df = temp_df2[temp_df2['hours_grouped'] == i]\n",
        "                    if day_df.empty:\n",
        "                        new_df.loc[i] = np.nan\n",
        "                        new_df.loc[i, 'hours_grouped'] = i\n",
        "                        new_df.loc[i, 'SPELL_IDENTIFIER'] = temp_df2.iloc[0]['SPELL_IDENTIFIER']\n",
        "                        new_df.loc[i, 'date'] = temp_df2.iloc[0]['date']\n",
        "                    else:\n",
        "                        new_df = pd.concat([new_df, temp_df2[temp_df2['hours_grouped'] == i]])\n",
        "            final_new_df = pd.concat([final_new_df, new_df], ignore_index=True)\n",
        "    return final_new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687778089609
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "antibiotic_vitals_pivoted_2 = add_all_hours_grouped(antibiotic_vitals_pivoted.reset_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1687778207131
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    18056\n",
              "3    17698\n",
              "1    17079\n",
              "4    16715\n",
              "Name: hours_grouped, dtype: int64"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "antibiotic_vitals_pivoted_2.hours_grouped.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687778226430
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Forward fill\n",
        "antibiotic_vitals_pivoted_3 = antibiotic_vitals_pivoted_2.groupby(['SPELL_IDENTIFIER'])['Diastolic Blood Pressure', 'Glasgow Coma Score', 'Heart Rate', 'Mean Arterial Pressure', 'NEWS Conscious Level Score', 'NEWS Supplemental Oxygen Calc', 'Respiratory Rate', 'SpO2', 'Systolic Blood Pressure', 'Temperature'].ffill()\n",
        "antibiotic_vitals_pivoted_3 = antibiotic_vitals_pivoted_2[['SPELL_IDENTIFIER', 'date', 'hours_grouped']].join(antibiotic_vitals_pivoted_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Remove those with less than 24 hours of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1687778234298
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "antibiotic_vitals_pivoted_4 = antibiotic_vitals_pivoted_3[antibiotic_vitals_pivoted_3['SPELL_IDENTIFIER'].isin((antibiotic_vitals_pivoted_3.groupby('SPELL_IDENTIFIER').size() > 3).where(lambda x : x == True).dropna().reset_index()['SPELL_IDENTIFIER'].to_list())]\n",
        "antibiotic_vitals_pivoted_4.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1687778254322
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save\n",
        "#antibiotic_vitals_pivoted_4.to_csv('switch_data/antibiotic_vitals_2023.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1687778294444
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 69536 entries, 0 to 69535\n",
            "Data columns (total 13 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   SPELL_IDENTIFIER               69536 non-null  object \n",
            " 1   date                           69536 non-null  object \n",
            " 2   hours_grouped                  69536 non-null  object \n",
            " 3   Diastolic Blood Pressure       69468 non-null  float64\n",
            " 4   Glasgow Coma Score             52354 non-null  float64\n",
            " 5   Heart Rate                     69500 non-null  float64\n",
            " 6   Mean Arterial Pressure         69228 non-null  float64\n",
            " 7   NEWS Conscious Level Score     60009 non-null  float64\n",
            " 8   NEWS Supplemental Oxygen Calc  59710 non-null  float64\n",
            " 9   Respiratory Rate               69383 non-null  float64\n",
            " 10  SpO2                           69434 non-null  float64\n",
            " 11  Systolic Blood Pressure        69470 non-null  float64\n",
            " 12  Temperature                    69434 non-null  float64\n",
            "dtypes: float64(10), object(3)\n",
            "memory usage: 6.9+ MB\n"
          ]
        }
      ],
      "source": [
        "antibiotic_vitals_pivoted_4.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1687778372352
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_11271/3047171301.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  antibiotic_vitals_pivoted_4['hours_grouped'] = antibiotic_vitals_pivoted_4['hours_grouped'].astype(int)\n"
          ]
        }
      ],
      "source": [
        "# Needs to be type int for c22 to work\n",
        "antibiotic_vitals_pivoted_4['hours_grouped'] = antibiotic_vitals_pivoted_4['hours_grouped'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "### 24 hours ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1687778393902
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "c22_24 = antibiotic_vitals_pivoted_4.groupby('SPELL_IDENTIFIER').head(4)\n",
        "c22_24.set_index(['SPELL_IDENTIFIER', 'date', 'hours_grouped'] ,inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1687778691714
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sktime.datatypes import check_raise\n",
        "check_raise(c22_24, 'pd_multiindex_hier')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1687778822578
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define C22 function\n",
        "def c22_24_fun(df):\n",
        "    c22 = Catch22(catch24=True) # Add catch24 = True\n",
        "    master_df = pd.DataFrame()\n",
        "    overlord_df = pd.DataFrame()\n",
        "    remove_set = set()\n",
        "    for x in range(len(df.columns)): # Iterate through columns so not to many nans\n",
        "        print('column number:', x)\n",
        "        working_df = df.iloc[:, x]\n",
        "        working_df = working_df.to_frame()\n",
        "        for column_name in working_df:\n",
        "            master_df = pd.DataFrame()\n",
        "            master_df2 = pd.DataFrame()\n",
        "            for stay_id, new_df in working_df[[column_name]].groupby(level=0):\n",
        "                    new_df2 = new_df.reset_index(drop=True).dropna()\n",
        "                    \n",
        "                    # C22 for current day\n",
        "                    if len(new_df2) <= 2: # c22 only works with 3 or more timepoints\n",
        "                        transformed_data = pd.DataFrame()\n",
        "                        np_data = new_df2.to_numpy()\n",
        "                        if not np_data.size == 0:\n",
        "                            transformed_data['22'] = np.mean(new_df2.to_numpy())\n",
        "                            transformed_data['23'] = np.std(new_df.to_numpy())\n",
        "                    else:\n",
        "                        transformed_data = c22.fit_transform(new_df2)\n",
        "\n",
        "                    transformed_data = transformed_data.add_prefix(column_name)           \n",
        "                    transformed_data.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                    transformed_data.insert(1, 'date', new_df.reset_index().iloc[-1]['date'])\n",
        "                    transformed_data.insert(2, '24_hour_flag', 1)\n",
        "\n",
        "                    # C22 for all data to date for stay - same for first 24 hours\n",
        "                    transformed_data2 = transformed_data.iloc[:,3:].copy()\n",
        "                    transformed_data2 = transformed_data2.add_suffix('_current_stay') # Indicate different as temporal over whole of current stay\n",
        "                    transformed_data2.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                    transformed_data2.insert(1, 'date', new_df.reset_index().iloc[-1]['date'])\n",
        "                    transformed_data2.insert(2, '24_hour_flag', 1)\n",
        "\n",
        "                    # Create master df's\n",
        "                    master_df = pd.concat([master_df, transformed_data])\n",
        "                    master_df2 = pd.concat([master_df2, transformed_data2])\n",
        "\n",
        "\n",
        "            master_df.reset_index(inplace=True, drop=True)\n",
        "            master_df2.reset_index(inplace=True, drop=True)\n",
        "\n",
        "            master_df = master_df.merge(master_df2, how='left', on=['SPELL_IDENTIFIER', 'date', '24_hour_flag'])\n",
        "\n",
        "        if x == 0:\n",
        "            overlord_df = master_df.copy()\n",
        "        else:\n",
        "            overlord_df = overlord_df.merge(master_df, how='outer', on=['SPELL_IDENTIFIER', 'date', '24_hour_flag'])\n",
        "        \n",
        "    return overlord_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687779946492
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "c22_24_hour_df = c22_24_fun(c22_24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1687779947702
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save\n",
        "#c22_24_hour_df.to_csv('switch_data/c22_24_hour_2023.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "### 48 hours ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "gather": {
          "logged": 1687780037699
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define C22 function\n",
        "def c22_48_fun(df):\n",
        "    c22 = Catch22(catch24=True)\n",
        "    c22_2 = Catch22(catch24=True)\n",
        "    master_df = pd.DataFrame()\n",
        "    overlord_df = pd.DataFrame()\n",
        "    remove_set = set()\n",
        "    for x in range(len(df.columns)): # Iterate through columns so not to many nans\n",
        "        print('column number:', x)\n",
        "        working_df = df.iloc[:, x]\n",
        "        working_df = working_df.to_frame()\n",
        "        for column_name in working_df:\n",
        "            master_df = pd.DataFrame()\n",
        "            master_df2 = pd.DataFrame()\n",
        "            for stay_id, new_df in working_df[[column_name]].groupby(level=0):\n",
        "\n",
        "                    new_df2 = new_df.tail(4).reset_index(drop=True).dropna()\n",
        "                    new_df3 = new_df.reset_index(drop=True).dropna()\n",
        "                    \n",
        "                    # C22 for latest day\n",
        "                    if len(new_df2) <= 2: # c22 only works with 3 or more timepoints\n",
        "                        transformed_data = pd.DataFrame()\n",
        "                        np_data = new_df2.to_numpy()\n",
        "                        if not np_data.size == 0:\n",
        "                            transformed_data['22'] = np.mean(np_data)\n",
        "                            transformed_data['23'] = np.std(np_data)\n",
        "                    else: \n",
        "                        transformed_data = c22.fit_transform(new_df2)\n",
        "                    transformed_data = transformed_data.add_prefix(column_name)           \n",
        "                    transformed_data.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                    transformed_data.insert(1, 'date', new_df.reset_index().iloc[-1]['date'])\n",
        "                    transformed_data.insert(2, '48_hour_flag', 1)\n",
        "\n",
        "                    # C22 for all data to date for stay\n",
        "                    if len(new_df3) <= 2: # c22 only works with 3 or more timepoints\n",
        "                        transformed_data2 = pd.DataFrame()\n",
        "                        np_data = new_df3.to_numpy()\n",
        "                        if not np_data.size == 0:\n",
        "                            transformed_data2['22'] = np.mean(np_data)\n",
        "                            transformed_data2['23'] = np.std(np_data) \n",
        "                    else:\n",
        "                        transformed_data2 = c22_2.fit_transform(new_df3)\n",
        "                    transformed_data2 = transformed_data2.add_prefix(column_name)  \n",
        "                    transformed_data2 = transformed_data2.add_suffix('_current_stay') # Indicate different as temporal over whole of current stay             \n",
        "                    transformed_data2.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                    transformed_data2.insert(1, 'date', new_df.reset_index().iloc[-1]['date'])\n",
        "                    transformed_data2.insert(2, '48_hour_flag', 1)\n",
        "\n",
        "                    # Create master df's\n",
        "                    master_df = pd.concat([master_df, transformed_data])\n",
        "                    master_df2 = pd.concat([master_df2, transformed_data2])\n",
        "\n",
        "            master_df.reset_index(inplace=True, drop=True)\n",
        "            master_df2.reset_index(inplace=True, drop=True)\n",
        "\n",
        "            master_df = master_df.merge(master_df2, how='left', on=['SPELL_IDENTIFIER', 'date', '48_hour_flag'])\n",
        "\n",
        "        if x == 0:\n",
        "            overlord_df = master_df.copy()\n",
        "        else:\n",
        "            overlord_df = overlord_df.merge(master_df, how='outer', on=['SPELL_IDENTIFIER', 'date', '48_hour_flag'])\n",
        "\n",
        "    return overlord_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1687778618457
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define\n",
        "c22_48 = antibiotic_vitals_pivoted_4.groupby('SPELL_IDENTIFIER').head(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1687778619754
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Remove those without enough data\n",
        "c22_48 = c22_48[c22_48['SPELL_IDENTIFIER'].isin((c22_48.groupby('SPELL_IDENTIFIER').size() > 7).where(lambda x : x == True).dropna().reset_index()['SPELL_IDENTIFIER'].to_list())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1687778654039
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Set index\n",
        "c22_48.set_index(['SPELL_IDENTIFIER', 'date', 'hours_grouped'] ,inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687780979931
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "c22_48_hour_df = c22_48_fun(c22_48)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "gather": {
          "logged": 1687780980936
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save\n",
        "c22_48_hour_df.to_csv('switch_data/c22_48_hour_2023.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "### Other ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "gather": {
          "logged": 1687782182673
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Remove those without enough data\n",
        "c22_other = antibiotic_vitals_pivoted_4[antibiotic_vitals_pivoted_4['SPELL_IDENTIFIER'].isin((antibiotic_vitals_pivoted_4.groupby('SPELL_IDENTIFIER').size() > 8).where(lambda x : x == True).dropna().reset_index()['SPELL_IDENTIFIER'].to_list())]\n",
        "# Set index\n",
        "c22_other.set_index(['SPELL_IDENTIFIER', 'date', 'hours_grouped'] ,inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "gather": {
          "logged": 1687782199968
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "gather": {
          "logged": 1687782201357
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def c22_other_fun(df):\n",
        "    c22 = Catch22(catch24=True)\n",
        "    master_df = pd.DataFrame()\n",
        "    overlord_df = pd.DataFrame()\n",
        "    for x in range(len(df.columns)): # Iterate through columns sas this c22 does not work on multiple columns\n",
        "        print('column number:', x)\n",
        "        working_df = df.iloc[:, x]\n",
        "        working_df = working_df.to_frame()\n",
        "        for column_name in working_df:\n",
        "            master_df = pd.DataFrame()\n",
        "            master_df2 = pd.DataFrame()\n",
        "            for stay_id, new_df in working_df[[column_name]].groupby(level=0, dropna=False): # Iterate through stays\n",
        "\n",
        "                n_list = list(range(1, math.ceil(len(new_df)/4)+1))\n",
        "                for n in range(1, math.ceil(len(new_df)/4)+1): # Do this to understand how many 'days' / sets of data we will have for each stay beyond 24 and 48 hours\n",
        "                    # Ignore first 48 hours as calculated seperatly\n",
        "                    if n == 1:\n",
        "                        continue\n",
        "                    elif n == 2:\n",
        "                        continue\n",
        "                    # This is for exceptional cases where we want hours grouped 1 for last day and the spell starts on hours grouped 2\n",
        "                    elif (new_df.reset_index().iloc[0]['hours_grouped'] == 2) and ((n == (len(new_df)/4)) and (n == n_list[-1])):\n",
        "                        exit_flag = True\n",
        "                        flag_2 = False\n",
        "                        flag_1 = False\n",
        "                        # Get index of nth 2 hours grouped value\n",
        "                        try:\n",
        "                            index_value = new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index][new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index]['hours_grouped'] == 2].index.values[0]\n",
        "                            new_df2 = new_df.iloc[:index_value+1]\n",
        "                            exit_flag = False\n",
        "                            flag_2 = True\n",
        "                        #  Look at nth 1 hours grouped  \n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                        try:\n",
        "                            index_value = new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index][new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index]['hours_grouped'] == 1].index.values[0]\n",
        "                            new_df3 = new_df.iloc[:index_value+1]\n",
        "                            exit_flag = False\n",
        "                            flag_1 = True\n",
        "                        except:\n",
        "                            pass\n",
        "                        \n",
        "                        if exit_flag == True:\n",
        "                            continue\n",
        "                        \n",
        "                        if flag_2 == True:\n",
        "                            new_df2_2 = new_df2.tail(4).reset_index(drop=True).dropna()\n",
        "                            new_df2_3 = new_df2.reset_index(drop=True).dropna()\n",
        "                    \n",
        "                            # C22 for latest day\n",
        "                            if len(new_df2_2) <= 2: # c22 only works with 3 or more timepoints\n",
        "                                transformed_data = pd.DataFrame()\n",
        "                                np_data = new_df2_2.to_numpy()\n",
        "                                if not np_data.size == 0:\n",
        "                                    transformed_data['22'] = np.mean(np_data)\n",
        "                                    transformed_data['23'] = np.std(np_data) \n",
        "                            else: \n",
        "                                transformed_data = c22.fit_transform(new_df2_2)\n",
        "\n",
        "                            transformed_data = transformed_data.add_prefix(column_name)           \n",
        "                            transformed_data.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                            transformed_data.insert(1, 'date', new_df2.reset_index().iloc[-1]['date'])\n",
        "\n",
        "                            # C22 for all data to date for stay\n",
        "                            if len(new_df2_3) <= 2: # c22 only works with 3 or more timepoints\n",
        "                                transformed_data2 = pd.DataFrame()\n",
        "                                np_data = new_df2_3.to_numpy()\n",
        "                                if not np_data.size == 0:\n",
        "                                    transformed_data2['22'] = np.mean(np_data)\n",
        "                                    transformed_data2['23'] = np.std(np_data)\n",
        "                            else: \n",
        "                                transformed_data2 = c22.fit_transform(new_df2_3)\n",
        "\n",
        "                            transformed_data2 = transformed_data2.add_prefix(column_name)  \n",
        "                            transformed_data2 = transformed_data2.add_suffix('_current_stay') # Indicate different as temporal over whole of current stay             \n",
        "                            transformed_data2.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                            transformed_data2.insert(1, 'date', new_df2.reset_index().iloc[-1]['date'])\n",
        "\n",
        "                        else:\n",
        "                            transformed_data = pd.DataFrame()\n",
        "                            transformed_data2 = pd.DataFrame()\n",
        "                        \n",
        "                        if flag_1 == True:\n",
        "                            new_df3_2 = new_df3.tail(4).reset_index(drop=True).dropna()\n",
        "                            new_df3_3 = new_df3.reset_index(drop=True).dropna()\n",
        "\n",
        "                            # C22 for latest day\n",
        "                            if len(new_df3_2) <= 2: # c22 only works with 3 or more timepoints\n",
        "                                transformed_data3 = pd.DataFrame()\n",
        "                                np_data = new_df3_2.to_numpy()\n",
        "                                if not np_data.size == 0:\n",
        "                                    transformed_data3['22'] = np.mean(np_data)\n",
        "                                    transformed_data3['23'] = np.std(np_data)\n",
        "                            else: \n",
        "                                transformed_data3 = c22.fit_transform(new_df3_2)\n",
        "\n",
        "                            transformed_data3 = transformed_data3.add_prefix(column_name)           \n",
        "                            transformed_data3.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                            transformed_data3.insert(1, 'date', new_df.reset_index().iloc[-1]['date'])\n",
        "\n",
        "                            # C22 for all data to date for stay\n",
        "                            if len(new_df3_3) <= 2: # c22 only works with 3 or more timepoints\n",
        "                                transformed_data4 = pd.DataFrame()\n",
        "                                np_data = new_df3_3.to_numpy()\n",
        "                                if not np_data.size == 0:\n",
        "                                    transformed_data4['22'] = np.mean(np_data)\n",
        "                                    transformed_data4['23'] = np.std(np_data) \n",
        "                            else: \n",
        "                                transformed_data4 = c22.fit_transform(new_df3_3)\n",
        "                                transformed_data4 = transformed_data4.add_prefix(column_name)  \n",
        "                                transformed_data4 = transformed_data4.add_suffix('_current_stay') # Indicate different as temporal over whole of current stay             \n",
        "                                transformed_data4.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                                transformed_data4.insert(1, 'date', new_df3.reset_index().iloc[-1]['date'])\n",
        "                        else:\n",
        "                            transformed_data3 = pd.DataFrame()\n",
        "                            transformed_data4 = pd.DataFrame()\n",
        "                        \n",
        "                        # Combine\n",
        "                        transformed_data = pd.concat([transformed_data, transformed_data3], ignore_index=True)\n",
        "                        transformed_data2 = pd.concat([transformed_data2, transformed_data4], ignore_index=True)\n",
        "\n",
        "                        # Create master df's\n",
        "                        master_df = pd.concat([master_df, transformed_data])\n",
        "                        master_df2 = pd.concat([master_df2, transformed_data2])\n",
        "\n",
        "\n",
        "                    # This is for most cases  \n",
        "                    else:\n",
        "                        # Get index of nth 2 hours grouped value\n",
        "                        try:\n",
        "                            index_value = new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index][new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index]['hours_grouped'] == 2].index.values[0]\n",
        "                            new_df2 = new_df.iloc[:index_value+1]\n",
        "                        except:\n",
        "                            # If fails look at nth 1 hours grouped  \n",
        "                            try:\n",
        "                                index_value = new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index][new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index]['hours_grouped'] == 1].index.values[0]\n",
        "                                new_df2 = new_df.iloc[:index_value+1]\n",
        "                            except:\n",
        "                                continue\n",
        "\n",
        "                        new_df2_2 = new_df2.tail(4).reset_index(drop=True).dropna()\n",
        "                        new_df2_3 = new_df2.reset_index(drop=True).dropna()\n",
        "                    \n",
        "                        # C22 for latest day\n",
        "                        if len(new_df2_2) <= 2: # c22 only works with 3 or more timepoints\n",
        "                            transformed_data = pd.DataFrame()\n",
        "                            np_data = new_df2_2.to_numpy()\n",
        "                            if not np_data.size == 0:\n",
        "                                transformed_data['22'] = np.mean(np_data)\n",
        "                                transformed_data['23'] = np.std(np_data) \n",
        "                        else: \n",
        "                            transformed_data = c22.fit_transform(new_df2_2)                        \n",
        "                        \n",
        "                        transformed_data = transformed_data.add_prefix(column_name)           \n",
        "                        transformed_data.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                        transformed_data.insert(1, 'date', new_df2.reset_index().iloc[-1]['date'])\n",
        "\n",
        "                        # C22 for all data to date for stay\n",
        "                        if len(new_df2_3) <= 2: # c22 only works with 3 or more timepoints\n",
        "                            transformed_data2 = pd.DataFrame()\n",
        "                            np_data = new_df2_3.to_numpy()\n",
        "                            if not np_data.size == 0:\n",
        "                                transformed_data2['22'] = np.mean(np_data)\n",
        "                                transformed_data2['23'] = np.std(np_data)\n",
        "                        else: \n",
        "                            transformed_data2 = c22.fit_transform(new_df2_3)                        \n",
        "\n",
        "                        transformed_data2 = transformed_data2.add_prefix(column_name)  \n",
        "                        transformed_data2 = transformed_data2.add_suffix('_current_stay') # Indicate different as temporal over whole of current stay             \n",
        "                        transformed_data2.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                        transformed_data2.insert(1, 'date', new_df2.reset_index().iloc[-1]['date'])\n",
        "\n",
        "                        # Create master df's\n",
        "                        master_df = pd.concat([master_df, transformed_data])\n",
        "                        master_df2 = pd.concat([master_df2, transformed_data2])\n",
        "\n",
        "            master_df.reset_index(inplace=True, drop=True)\n",
        "            master_df2.reset_index(inplace=True, drop=True)\n",
        "\n",
        "            if master_df.empty:\n",
        "                if master_df2.empty:\n",
        "                    continue\n",
        "                else:\n",
        "                    master_df = master_df2\n",
        "            else:\n",
        "                master_df = master_df.merge(master_df2, how='left', on=['SPELL_IDENTIFIER', 'date'])\n",
        "\n",
        "        if x == 0:\n",
        "            overlord_df = master_df.copy()\n",
        "        elif master_df.empty:\n",
        "            continue\n",
        "        else:\n",
        "            overlord_df = overlord_df.merge(master_df, how='outer', on=['SPELL_IDENTIFIER', 'date'])\n",
        "            overlord_df.dropna(axis=0, how='all', inplace=True)\n",
        "        \n",
        "        # Save as go through\n",
        "        overlord_df.to_csv('switch_data/new_c22_other_days.csv', index=False)\n",
        "\n",
        "    return overlord_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "gather": {
          "logged": 1687787332447
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "column number: 0\n",
            "column number: 1\n",
            "column number: 2\n",
            "column number: 3\n",
            "column number: 4\n",
            "column number: 5\n",
            "column number: 6\n",
            "column number: 7\n",
            "column number: 8\n",
            "column number: 9\n"
          ]
        }
      ],
      "source": [
        "c22_other_days_df = c22_other_fun(c22_other)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "gather": {
          "logged": 1687787336753
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save\n",
        "c22_other_days_df.to_csv('switch_data/c22_other_days_2023.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "gather": {
          "logged": 1687787833580
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "c22_other_days_df.drop(columns=['22', '23'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "gather": {
          "logged": 1687787849620
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save\n",
        "c22_other_days_df.to_csv('switch_data/c22_other_days_final_2023.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Combine and work out difference "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1687872281098
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/c22_24_hour_2023.csv'\n",
        "c22_24_hour = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1687872282514
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/c22_48_hour_2023.csv'\n",
        "c22_48_hour = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1687872286208
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/c22_other_days_final_2023.csv'\n",
        "c22_other_days_df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1687874513098
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Combine\n",
        "c22_combined = pd.concat([c22_24_hour, c22_48_hour, c22_other_days_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1687874515033
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_6070/1142685746.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  c22_combined.insert(3, col.name, col)\n"
          ]
        }
      ],
      "source": [
        "# Move column\n",
        "col = c22_combined.pop(\"48_hour_flag\")\n",
        "c22_combined.insert(3, col.name, col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1687874517523
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Reset index\n",
        "c22_combined2 = c22_combined.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1687874523775
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Order\n",
        "c22_combined2 = c22_combined2.sort_values(by=['SPELL_IDENTIFIER', 'date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1687874553445
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Reset index\n",
        "c22_combined2 = c22_combined2.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1687874639281
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Difference\n",
        "c22_combined3 = c22_combined2.drop(columns=['date', '24_hour_flag', '48_hour_flag'])\n",
        "\n",
        "c22_combined_diff = pd.DataFrame()\n",
        "c22_combined3.set_index('SPELL_IDENTIFIER', inplace=True)\n",
        "for stay_id, new_df in c22_combined3.groupby(level=0):\n",
        "    diff_df = new_df.diff()\n",
        "    diff_df = diff_df.add_suffix('_difference')\n",
        "    c22_combined_diff = pd.concat([c22_combined_diff, diff_df], ignore_index=True)\n",
        "\n",
        "c22_combined3.reset_index(inplace=True)\n",
        "c22_combined_diff = pd.concat([c22_combined3, c22_combined_diff], axis=1)\n",
        "c22_combined_diff = pd.concat([c22_combined2[['date', '24_hour_flag', '48_hour_flag']], c22_combined_diff], axis=1)\n",
        "col = c22_combined_diff.pop(\"SPELL_IDENTIFIER\")\n",
        "c22_combined_diff.insert(0, col.name, col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1687874673286
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3427"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c22_combined_diff['SPELL_IDENTIFIER'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1687874698475
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save\n",
        "#c22_combined_diff.to_csv('switch_data/c22_all_with_diff_2023.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
