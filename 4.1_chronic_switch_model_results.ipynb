{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1711636464916
        }
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 40)\n",
        "pd.set_option('display.width', 2000)\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import gc\n",
        "\n",
        "import pickle\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "# Remove printing error\n",
        "pd.options.mode.chained_assignment = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1710838328315
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0f6ccab990>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU not available, CPU used\n"
          ]
        }
      ],
      "source": [
        "# Set the random seeds for deterministic results.\n",
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Set device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1710838329053
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "class StratifiedKFold3(StratifiedKFold):\n",
        "\n",
        "    def split(self, X, y, groups=None):\n",
        "        s = super().split(X, y, groups)\n",
        "        for train_indxs, test_indxs in s:\n",
        "            y_train = y[train_indxs]\n",
        "            train_indxs, cv_indxs = train_test_split(train_indxs,stratify=y_train, test_size=(1 / (self.n_splits - 1)), random_state=0)\n",
        "            yield train_indxs, cv_indxs, test_indxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1710838329663
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Function to split data so even distribution between val and test\n",
        "def cv_data_fun(data, n_cv=10):\n",
        "    X = data.iloc[:, 2:]\n",
        "    y = data['po_flag']\n",
        "    g = StratifiedKFold3(n_cv).split(X,y)\n",
        "    return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1710838330559
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define how long an epoch takes\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "# Calculate the number of trainable parameters in the model.\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1710838331653
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from typing import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "def smote_fun(train_data):\n",
        "    # Oversampling train set\n",
        "    train_data_X = train_data.drop(columns=['stay_id', 'po_flag'])\n",
        "    train_data_y = train_data['po_flag']\n",
        "    Counter(train_data_y)\n",
        "    oversample = SMOTE()\n",
        "    train_data_X, train_data_y = oversample.fit_resample(train_data_X, train_data_y)\n",
        "    Counter(train_data_y)\n",
        "    train_data_y = pd.DataFrame(train_data_y, columns=['po_flag'])\n",
        "    train_data_y['stay_id'] = 'x'\n",
        "    train_data = pd.concat([train_data_y, train_data_X], axis=1)\n",
        "    train_data = train_data.sample(frac=1, random_state=0).reset_index(drop=True)\n",
        "    return train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1710838332215
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def set_transformer_processing_fun(patient_df, snomed_embedding):\n",
        "    # Str\n",
        "    patient_df.columns = patient_df.columns.astype(str)\n",
        "    snomed_embedding['snomed_code'] = snomed_embedding['snomed_code'].astype(str)\n",
        "    # Filter\n",
        "    snomed_embedding = snomed_embedding[snomed_embedding['snomed_code'].isin(patient_df.columns.tolist())]\n",
        "    snomed_embedding.set_index('snomed_code', inplace=True)\n",
        "    # Get lengths of each patients co-morbidities\n",
        "    comorbidity_len = np.array(patient_df.sum(axis=1))\n",
        "    # Add padding embedding \n",
        "    padding_df = pd.DataFrame(np.random.choice([0], size=len(snomed_embedding.columns))) # Changed to 0\n",
        "    padding_df = padding_df.T\n",
        "    padding_df.index = ['9999999999']\n",
        "    padding_df.columns = snomed_embedding.columns\n",
        "    snomed_embedding2 = pd.concat([snomed_embedding, padding_df])\n",
        "    snomed_embedding2.index = snomed_embedding2.index.astype(str)\n",
        "    # Get max number of co-morbidities\n",
        "    max_len = 22 # Define for same for all splits (train val etr)\n",
        "    # Format patients embeddings into set and pad / create array\n",
        "    feature_array = np.zeros(shape=(len(patient_df), max_len , 128))\n",
        "    n = -1\n",
        "    for index, row in patient_df.iterrows():\n",
        "        n += 1\n",
        "        n2 = -1\n",
        "        code_list = row[row ==1].index.tolist()\n",
        "        while len(code_list) < max_len:\n",
        "            code_list.append('9999999999')\n",
        "        for code in code_list:\n",
        "            n2 += 1\n",
        "            feature_array[n, n2] = np.array(snomed_embedding2.loc[code])\n",
        "    \n",
        "    # Create mask tensor based on lengths\n",
        "    comorbidity_len2 = torch.as_tensor(comorbidity_len, dtype=torch.long)\n",
        "    mask = torch.arange(max_len)[None, :] < comorbidity_len2[:, None]\n",
        "\n",
        "    return feature_array, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1710838335347
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def new_threshold_fun(predictions, bound=0.5):\n",
        "    new_predictions = [1 if a_ >= bound else 0 for a_ in predictions]\n",
        "    return new_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1710838338281
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Function to train and eval model \n",
        "def cv_run_fun(data, model):\n",
        "    overall_best_test_auroc = 0\n",
        "\n",
        "    actual_test_auroc_results = []\n",
        "\n",
        "    test_auroc_results = []\n",
        "    test_accuracy_results = []\n",
        "    test_balanced_accuracy_results = []\n",
        "    test_recall_results = []\n",
        "    test_precision_results = []\n",
        "    test_f1_results = []\n",
        "    test_auprc_results = []\n",
        "    test_cm_results = []\n",
        "    test_true_positive_rate_results = []\n",
        "    test_fasle_positive_rate_results = []\n",
        "\n",
        "    final_threshold = 0\n",
        "\n",
        "    # Define batch size \n",
        "    batch_size = 512\n",
        "\n",
        "    # Define optimizer and learning_rate\n",
        "    learning_rate = 0.0001\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Define loss\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Define epochs and clip\n",
        "    N_EPOCHS = 10 \n",
        "    CLIP = 1\n",
        "\n",
        "    # Split into folds\n",
        "    split_generator = cv_data_fun(data)\n",
        "\n",
        "    # Iterate through folds\n",
        "    for x in range(N_EPOCHS): # Note this only works as number of splits and epocs are the same\n",
        "        train_idx, val_idx, test_idx = next(split_generator)\n",
        "\n",
        "        # Get train val and test\n",
        "        train_data = data.loc[train_idx]\n",
        "        valid_data = data.loc[val_idx]\n",
        "        test_data = data.loc[test_idx]\n",
        "\n",
        "        #Apply smote - crashes with these features\n",
        "        #train_data = smote_fun(train_data)\n",
        "\n",
        "        # Split up dfs\n",
        "        vitals_train_data = train_data.iloc[:,2:255]\n",
        "        demographics_train_data = train_data.iloc[:,255:267]\n",
        "        comorbidity_train_data = train_data.iloc[:, 267:]\n",
        "\n",
        "        vitals_valid_data = valid_data.iloc[:,2:255]\n",
        "        demographics_valid_data = valid_data.iloc[:,255:267]\n",
        "        comorbidity_valid_data = valid_data.iloc[:, 267:]\n",
        "\n",
        "        vitals_test_data = test_data.iloc[:,2:255]\n",
        "        demographics_test_data = test_data.iloc[:,255:267]\n",
        "        comorbidity_test_data = test_data.iloc[:, 267:]\n",
        "\n",
        "        # Initializing the weights of our model each fold\n",
        "        model.apply(init_weights)\n",
        "\n",
        "        # Get labels\n",
        "        train_labels = train_data[['po_flag']]\n",
        "        valid_labels = valid_data[['po_flag']]\n",
        "        test_labels = test_data[['po_flag']]\n",
        "\n",
        "        # Preprocess comorbidity data\n",
        "        print('Working on set_transformer_processing_fun...')\n",
        "        comorbidity_train_data, comorbidity_train_mask = set_transformer_processing_fun(comorbidity_train_data, embedding)\n",
        "        comorbidity_valid_data, comorbidity_valid_mask = set_transformer_processing_fun(comorbidity_valid_data, embedding)\n",
        "        comorbidity_test_data, comorbidity_test_mask = set_transformer_processing_fun(comorbidity_test_data, embedding)\n",
        "        print('Done!')\n",
        "\n",
        "        # Define dataloaders\n",
        "        train_dataset =  MultiInputDataset([vitals_train_data, demographics_train_data], train_labels, comorbidity_train_data, comorbidity_train_mask)\n",
        "        train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size)#, shuffle=True)#, collate_fn=train_dataset.collate_fn_padd)\n",
        "\n",
        "        valid_dataset = MultiInputDataset([vitals_valid_data, demographics_valid_data], valid_labels, comorbidity_valid_data, comorbidity_valid_mask)\n",
        "        valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=batch_size)#, collate_fn=valid_dataset.collate_fn_padd)\n",
        "\n",
        "        test_dataset = MultiInputDataset([vitals_test_data, demographics_test_data], test_labels, comorbidity_test_data, comorbidity_test_mask)\n",
        "        test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size)#, collate_fn=test_dataset.collate_fn_padd)\n",
        "\n",
        "        # Run\n",
        "        best_valid_loss = float('inf')\n",
        "        best_valid_auroc = 0\n",
        "\n",
        "        optimal_threshold = 0\n",
        "\n",
        "        for epoch in range(N_EPOCHS):\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss, train_auroc, train_predictions, train_labels_out = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
        "\n",
        "            valid_loss, valid_auroc, valid_predictions, valid_labels_out = evaluate(model, valid_dataloader, criterion)\n",
        "\n",
        "            end_time = time.time()\n",
        "            \n",
        "            fpr, tpr, thresholds = roc_curve(valid_labels_out, valid_predictions)\n",
        "            optimal_idx = np.argmax(tpr - fpr)\n",
        "            current_threshold = thresholds[optimal_idx]\n",
        "\n",
        "            epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "            print('Train AUROC:', train_auroc)\n",
        "            print('Valid AUROC:', valid_auroc)\n",
        "            print(train_predictions)\n",
        "            print(train_labels_out)\n",
        "            print('Train loss:', train_loss)\n",
        "            print('Valid loss:', valid_loss)\n",
        "            print(current_threshold)\n",
        "\n",
        "            if valid_loss < best_valid_loss:\n",
        "                best_valid_loss = valid_loss\n",
        "                print('BEST VALID LOSS')\n",
        "\n",
        "            if valid_auroc > best_valid_auroc:\n",
        "                best_valid_auroc = valid_auroc\n",
        "                print('UPDATED BEST INTERMEDIATE MODEL')\n",
        "                torch.save(model.state_dict(), f'chronic_switch_model_intermediate2.pt')\n",
        "                optimal_threshold = current_threshold\n",
        "\n",
        "        # -----------------------------\n",
        "        # Evaluate best model on test set\n",
        "        # -----------------------------\n",
        "\n",
        "        model.load_state_dict(torch.load(f'chronic_switch_model_intermediate2.pt'))\n",
        "\n",
        "        test_loss, test_auroc, test_predictions, test_labels_out = evaluate(model, test_dataloader, criterion)\n",
        "\n",
        "        print('Test AUROC result:', test_auroc)\n",
        "        \n",
        "        new_test_predictions = new_threshold_fun(test_predictions, optimal_threshold)\n",
        "\n",
        "        test_accuracy = accuracy_score(test_labels_out, new_test_predictions)\n",
        "        test_balanced_accuracy = balanced_accuracy_score(test_labels_out, new_test_predictions)\n",
        "        test_recall = recall_score(test_labels_out, new_test_predictions)\n",
        "        test_precision = precision_score(test_labels_out, new_test_predictions)\n",
        "        test_f1 = f1_score(test_labels_out, new_test_predictions)\n",
        "        test_auprc = average_precision_score(test_labels_out, test_predictions)\n",
        "        test_cm = confusion_matrix(test_labels_out, new_test_predictions)\n",
        "        tn, fp, fn, tp = test_cm.ravel()\n",
        "        test_true_positive_rate = (tp / (tp + fn))\n",
        "        test_false_positive_rate = (fp / (fp + tn))\n",
        "\n",
        "        if test_auroc > overall_best_test_auroc:\n",
        "            overall_best_test_auroc = test_auroc\n",
        "            print('UPDATED BEST OVERALL MODEL')\n",
        "            torch.save(model.state_dict(), f'chronic_switch_model.pt') # Hastag out when dont want to change\n",
        "            final_threshold = optimal_threshold\n",
        "        \n",
        "        actual_test_auroc_results.append(test_auroc)\n",
        "        \n",
        "        test_auroc_results.append(test_auroc)\n",
        "        test_accuracy_results.append(test_accuracy)\n",
        "        test_balanced_accuracy_results.append(test_balanced_accuracy)\n",
        "        test_recall_results.append(test_recall)\n",
        "        test_precision_results.append(test_precision)\n",
        "        test_f1_results.append(test_f1)\n",
        "        test_auprc_results.append(test_auprc)\n",
        "        test_cm_results.append(test_cm)\n",
        "        test_true_positive_rate_results.append(test_true_positive_rate)\n",
        "        test_fasle_positive_rate_results.append(test_false_positive_rate)\n",
        "\n",
        "    test_results = [test_auroc_results, test_accuracy_results,\n",
        "        test_balanced_accuracy_results,\n",
        "        test_recall_results,\n",
        "        test_precision_results,\n",
        "        test_f1_results,\n",
        "        test_auprc_results,\n",
        "        test_cm_results,\n",
        "        test_true_positive_rate_results,\n",
        "        test_fasle_positive_rate_results\n",
        "        ]\n",
        "    \n",
        "    return test_results, actual_test_auroc_results, final_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1710838342971
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def analyze_results_fun(cv_test_results):\n",
        "    # Assign results\n",
        "    test_auroc_results, test_accuracy_results,test_balanced_accuracy_results,test_recall_results,test_precision_results,test_f1_results,test_auprc_results,test_cm_results, test_tpr_results, test_fpr_results = [cv_test_results[i] for i in range(len(cv_test_results))]\n",
        "    print('mean test_auroc:', np.array(test_auroc_results).mean())\n",
        "    print('std test_auroc:', np.array(test_auroc_results).std())\n",
        "    print('test_auroc 2.5th percentile:', max(0, np.percentile(test_auroc_results, 2.5)))\n",
        "    print('test_auroc 97.5th percentile:', min(1, np.percentile(test_auroc_results, 97.5)))\n",
        "    print('mean test_accuracy:', np.array(test_accuracy_results).mean())\n",
        "    print('std test_accuracy:', np.array(test_accuracy_results).std())\n",
        "    print('test_accuracy 2.5th percentile:', max(0, np.percentile(test_accuracy_results, 2.5)))\n",
        "    print('test_accuracy 97.5th percentile:', min(1, np.percentile(test_accuracy_results, 97.5)))\n",
        "    print('mean test_balanced_accuracy:', np.array(test_balanced_accuracy_results).mean())\n",
        "    print('std test_balanced_accuracy:', np.array(test_balanced_accuracy_results).std())\n",
        "    print('test_balanced_accuracy 2.5th percentile:', max(0, np.percentile(test_balanced_accuracy_results, 2.5)))\n",
        "    print('test_balanced_accuracy 97.5th percentile:', min(1, np.percentile(test_balanced_accuracy_results, 97.5)))\n",
        "    print('mean test_recall:', np.array(test_recall_results).mean())\n",
        "    print('std test_recall:', np.array(test_recall_results).std())\n",
        "    print('test_recall 2.5th percentile:', max(0, np.percentile(test_recall_results, 2.5)))\n",
        "    print('test_recall 97.5th percentile:', min(1, np.percentile(test_recall_results, 97.5)))\n",
        "    print('mean test_precision:', np.array(test_precision_results).mean())\n",
        "    print('std test_precision:', np.array(test_precision_results).std())\n",
        "    print('test_precision 2.5th percentile:', max(0, np.percentile(test_precision_results, 2.5)))\n",
        "    print('test_precision 97.5th percentile:', min(1, np.percentile(test_precision_results, 97.5)))\n",
        "    print('mean test_f1:', np.array(test_f1_results).mean())\n",
        "    print('std test_f1:', np.array(test_f1_results).std())\n",
        "    print('test_f1 2.5th percentile:', max(0, np.percentile(test_f1_results, 2.5)))\n",
        "    print('test_f1 97.5th percentile:', min(1, np.percentile(test_f1_results, 97.5)))\n",
        "    print('mean test_auprc:', np.array(test_auprc_results).mean())\n",
        "    print('std test_auprc:', np.array(test_auprc_results).std())\n",
        "    print('test_auprc 2.5th percentile:', max(0, np.percentile(test_auprc_results, 2.5)))\n",
        "    print('test_auprc 97.5th percentile:', min(1, np.percentile(test_auprc_results, 97.5)))\n",
        "    print('mean test_tpr:', np.array(test_tpr_results).mean())\n",
        "    print('std test_tpr:', np.array(test_tpr_results).std())\n",
        "    print('test_tpr 2.5th percentile:', max(0, np.percentile(test_tpr_results, 2.5)))\n",
        "    print('test_tpr 97.5th percentile:', min(1, np.percentile(test_tpr_results, 97.5)))\n",
        "    print('mean test_fpr:', np.array(test_fpr_results).mean())\n",
        "    print('std test_fpr:', np.array(test_fpr_results).std())\n",
        "    print('test_fpr 2.5th percentile:', max(0, np.percentile(test_fpr_results, 2.5)))\n",
        "    print('test_fpr 97.5th percentile:', min(1, np.percentile(test_fpr_results, 97.5)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1710838345948
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "def train(model, dataloader, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    batch_prediction_list = []\n",
        "    batch_label_list = []\n",
        "\n",
        "    for batch_idx, sample in enumerate(tqdm(dataloader)):\n",
        "        labels = sample[\"labels\"]\n",
        "        features = sample[\"features\"]\n",
        "        batch_mask = sample[\"mask\"]\n",
        "        features = [data.float() for data in features]\n",
        "        features = [data.to(device=device) for data in features]\n",
        "        labels = labels.float()\n",
        "        labels = labels.to(device=device)\n",
        "        batch_mask = batch_mask.to(device)\n",
        "\n",
        "        # zero the gradients calculated from the last batch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Run model\n",
        "        output = model(features, batch_mask)\n",
        "        \n",
        "        # Generate loss\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        # calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # update the parameters of our model by doing an optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Get predictions for performance calc - masking outputs and labels\n",
        "        sig = torch.nn.Sigmoid()\n",
        "        output = sig(output)      \n",
        "        np_predictions = output.cpu().detach().numpy()\n",
        "        np_labels = labels.cpu().detach().numpy()\n",
        "\n",
        "        np_predictions = np_predictions.squeeze()\n",
        "        np_labels = np_labels.squeeze()\n",
        "\n",
        "        np_predictions = np_predictions.flatten()\n",
        "        np_labels = np_labels.flatten()\n",
        "        \n",
        "        # Create list\n",
        "        for x in np_predictions:\n",
        "            batch_prediction_list.append(x)\n",
        "        for x in np_labels:\n",
        "            batch_label_list.append(x)\n",
        "\n",
        "    final_predictions = np.array(batch_prediction_list)\n",
        "\n",
        "    final_labels = np.array(batch_label_list)\n",
        "\n",
        "    try:\n",
        "        auroc = roc_auc_score(final_labels, final_predictions)\n",
        "    except:\n",
        "        auroc = np.nan\n",
        "    \n",
        "    try:\n",
        "        final_loss = epoch_loss / len(dataloader)\n",
        "    except:\n",
        "        final_loss = np.nan\n",
        "\n",
        "    return final_loss, auroc, final_predictions, final_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1710838349819
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    batch_prediction_list = []\n",
        "    batch_label_list = []\n",
        "\n",
        "    # use the with torch.no_grad() block to ensure no gradients are calculated within the bloc\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, sample in enumerate(tqdm(dataloader)):\n",
        "            labels = sample[\"labels\"]\n",
        "            features = sample[\"features\"]\n",
        "            batch_mask = sample[\"mask\"]\n",
        "            features = [data.float() for data in features]\n",
        "            features = [data.to(device=device) for data in features]\n",
        "            labels = labels.float()\n",
        "            labels = labels.to(device=device)\n",
        "            batch_mask = batch_mask.to(device)\n",
        "\n",
        "            # Run model\n",
        "            output = model(features, batch_mask)\n",
        "\n",
        "            # Generate loss\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Get predictions for performance calc - masking outputs and labels\n",
        "            sig = torch.nn.Sigmoid()\n",
        "            output = sig(output)  \n",
        "            np_predictions = output.cpu().detach().numpy()\n",
        "            np_labels = labels.cpu().detach().numpy()\n",
        "\n",
        "            np_predictions = np_predictions.squeeze()\n",
        "            np_labels = np_labels.squeeze()\n",
        "\n",
        "            np_predictions = np_predictions.flatten()\n",
        "            np_labels = np_labels.flatten()\n",
        "            \n",
        "            # Create list\n",
        "            for x in np_predictions:\n",
        "                batch_prediction_list.append(x)\n",
        "            for x in np_labels:\n",
        "                batch_label_list.append(x)\n",
        "\n",
        "        final_predictions = np.array(batch_prediction_list)\n",
        "\n",
        "        final_labels = np.array(batch_label_list)\n",
        "\n",
        "        try:\n",
        "            auroc = roc_auc_score(final_labels, final_predictions)\n",
        "        except:\n",
        "            auroc = np.nan\n",
        "        \n",
        "        try:\n",
        "            final_loss = epoch_loss / len(dataloader)\n",
        "        except:\n",
        "            final_loss = np.nan\n",
        "\n",
        "        return final_loss, auroc, final_predictions, final_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1710838352590
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "class SetTransformer(nn.Module):\n",
        "    def __init__(self, dim_input, num_outputs, dim_output,\n",
        "            num_inds=36, dim_hidden=160, num_heads=4, ln=False):\n",
        "        super(SetTransformer, self).__init__()\n",
        "        self.enc = nn.Sequential(\n",
        "                ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),\n",
        "                ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln))\n",
        "        self.isab = ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln)\n",
        "        self.pma = PMA(dim_hidden, num_heads, num_outputs, ln=ln)\n",
        "        self.dec = nn.Sequential(\n",
        "                #SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
        "                #SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
        "                nn.Linear(dim_hidden, dim_output))\n",
        "\n",
        "    def forward(self, X, batch_mask):\n",
        "        x = self.isab(X, batch_mask)\n",
        "        x = self.pma(x, batch_mask)\n",
        "        return self.dec(x)\n",
        "\n",
        "class MAB0(nn.Module):\n",
        "    def __init__(self, dim_Q, dim_K, dim_V, num_heads, ln=False):\n",
        "        super(MAB0, self).__init__()\n",
        "        self.dim_V = dim_V\n",
        "        self.num_heads = num_heads\n",
        "        self.fc_q = nn.Linear(dim_Q, dim_V)\n",
        "        self.fc_k = nn.Linear(dim_K, dim_V)\n",
        "        self.fc_v = nn.Linear(dim_K, dim_V)\n",
        "        if ln:\n",
        "            self.ln0 = nn.LayerNorm(dim_V)\n",
        "            self.ln1 = nn.LayerNorm(dim_V)\n",
        "        self.fc_o = nn.Linear(dim_V, dim_V)\n",
        "\n",
        "    def forward(self, Q, K, mask):\n",
        "        Q = self.fc_q(Q)\n",
        "        K, V = self.fc_k(K), self.fc_v(K)\n",
        "\n",
        "        dim_split = self.dim_V // self.num_heads\n",
        "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
        "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
        "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
        "\n",
        "        # Create new variable for softmax\n",
        "        WB_ = Q_.bmm(K_.transpose(1,2))/math.sqrt(self.dim_V)\n",
        "        # Exspand mask dimensions to align\n",
        "        mask = mask.unsqueeze(1).repeat(self.num_heads, Q.shape[1], 1)\n",
        "        # Mask for softmax\n",
        "        WB_[~mask] = float('-inf')\n",
        "        A = torch.softmax(WB_, 2)\n",
        "        O = torch.cat((Q_ + A.bmm(V_)).split(Q.size(0), 0), 2)\n",
        "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
        "        O = O + F.relu(self.fc_o(O))\n",
        "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
        "        return O\n",
        "\n",
        "class MAB(nn.Module):\n",
        "    def __init__(self, dim_Q, dim_K, dim_V, num_heads, ln=False):\n",
        "        super(MAB, self).__init__()\n",
        "        self.dim_V = dim_V\n",
        "        self.num_heads = num_heads\n",
        "        self.fc_q = nn.Linear(dim_Q, dim_V)\n",
        "        self.fc_k = nn.Linear(dim_K, dim_V)\n",
        "        self.fc_v = nn.Linear(dim_K, dim_V)\n",
        "        if ln:\n",
        "            self.ln0 = nn.LayerNorm(dim_V)\n",
        "            self.ln1 = nn.LayerNorm(dim_V)\n",
        "        self.fc_o = nn.Linear(dim_V, dim_V)\n",
        "\n",
        "    def forward(self, Q, K):\n",
        "        Q = self.fc_q(Q)\n",
        "        K, V = self.fc_k(K), self.fc_v(K)\n",
        "\n",
        "        dim_split = self.dim_V // self.num_heads\n",
        "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
        "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
        "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
        "\n",
        "        A = torch.softmax(Q_.bmm(K_.transpose(1,2))/math.sqrt(self.dim_V), 2)\n",
        "        O = torch.cat((Q_ + A.bmm(V_)).split(Q.size(0), 0), 2)\n",
        "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
        "        O = O + F.relu(self.fc_o(O))\n",
        "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
        "        return O\n",
        "\n",
        "class SAB(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out, num_heads, ln=False):\n",
        "        super(SAB, self).__init__()\n",
        "        self.mab = MAB(dim_in, dim_in, dim_out, num_heads, ln=ln)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.mab(X, X)\n",
        "\n",
        "class ISAB(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out, num_heads, num_inds, ln=False):\n",
        "        super(ISAB, self).__init__()\n",
        "        self.I = nn.Parameter(torch.Tensor(1, num_inds, dim_out))\n",
        "        nn.init.xavier_uniform_(self.I)\n",
        "        self.mab0 = MAB0(dim_out, dim_in, dim_out, num_heads, ln=ln)\n",
        "        self.mab1 = MAB(dim_in, dim_out, dim_out, num_heads, ln=ln)\n",
        "\n",
        "    def forward(self, X, mask):\n",
        "        H = self.mab0(self.I.repeat(X.size(0), 1, 1), X, mask)\n",
        "        return self.mab1(X, H)\n",
        "\n",
        "class PMA(nn.Module):\n",
        "    def __init__(self, dim, num_heads, num_seeds, ln=False):\n",
        "        super(PMA, self).__init__()\n",
        "        self.S = nn.Parameter(torch.Tensor(1, num_seeds, dim))\n",
        "        nn.init.xavier_uniform_(self.S)\n",
        "        self.mab = MAB0(dim, dim, dim, num_heads, ln=ln)\n",
        "\n",
        "    def forward(self, X, mask):\n",
        "        return self.mab(self.S.repeat(X.size(0), 1, 1), X, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1710838357369
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "class Initial_vitals_model(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.BatchNorm1d(input_dim),\n",
        "            nn.Linear(input_dim, hid_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hid_dim, output_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x1 = self.layers(x)\n",
        "\n",
        "        return x1\n",
        "\n",
        "\n",
        "class Chronic_switch_model(nn.Module):\n",
        "    def __init__(self, \n",
        "    final_input_dim, \n",
        "    final_output_dim, \n",
        "    final_hid_dim, \n",
        "    final_hid_dim2,\n",
        "    demographics_input_dim,\n",
        "    demographics_output_dim,\n",
        "    vital_input_dim, \n",
        "    vital_hid_dim, \n",
        "    vital_output_dim, \n",
        "    dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.final_layers = nn.Sequential(\n",
        "            nn.Linear(final_input_dim, final_hid_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(final_hid_dim, final_hid_dim2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(final_hid_dim2, final_output_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout))\n",
        "\n",
        "        self.vital_model = Initial_vitals_model(vital_input_dim, vital_output_dim, vital_hid_dim, dropout)\n",
        "\n",
        "        self.set_transformer = SetTransformer(dim_input=128, num_outputs=1, dim_output=128, num_inds=32, dim_hidden=160, num_heads=4, ln=False)\n",
        "\n",
        "        # Embedding for demographics (passing feature directly)\n",
        "        self.demographics = nn.Linear(demographics_input_dim, demographics_output_dim)\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor, batch_mask: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        # Directly pass demographics feature to embedding\n",
        "        demographics = self.demographics(inputs[1])\n",
        "\n",
        "        # Pass other inputs through initial models\n",
        "        vital_embeddings = self.vital_model(inputs[0])\n",
        "        comorbidity_embeddings = self.set_transformer(inputs[2], batch_mask)\n",
        "        comorbidity_embeddings = torch.squeeze(comorbidity_embeddings)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        concatenated_embeddings = torch.cat([demographics, vital_embeddings, comorbidity_embeddings], dim=1)\n",
        "\n",
        "        # Pass through final layers\n",
        "        output = self.final_layers(concatenated_embeddings)\n",
        "\n",
        "        return output\n",
        "    \n",
        "    def latent_representation(self, inputs: torch.Tensor, batch_mask: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        # Directly pass demographics feature to embedding\n",
        "        demographics = self.demographics(inputs[1])\n",
        "\n",
        "        # Pass other inputs through initial models\n",
        "        vital_embeddings = self.vital_model(inputs[0])\n",
        "        comorbidity_embeddings = self.set_transformer(inputs[2], batch_mask)\n",
        "        comorbidity_embeddings = torch.squeeze(comorbidity_embeddings)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        concatenated_embeddings = torch.cat([demographics, vital_embeddings, comorbidity_embeddings], dim=1)\n",
        "        \n",
        "        return concatenated_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1711636546942
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "columns_to_drop = [\n",
        " 'Diastolic Blood Pressure2',\n",
        " 'Diastolic Blood Pressure3',\n",
        " 'Diastolic Blood Pressure4',\n",
        " 'Diastolic Blood Pressure5',\n",
        " 'Diastolic Blood Pressure6',\n",
        " 'Diastolic Blood Pressure7',\n",
        " 'Diastolic Blood Pressure8',\n",
        " 'Diastolic Blood Pressure9',\n",
        " 'Diastolic Blood Pressure11',\n",
        " 'Diastolic Blood Pressure12',\n",
        " 'Diastolic Blood Pressure13',\n",
        " 'Diastolic Blood Pressure14',\n",
        " 'Diastolic Blood Pressure15',\n",
        " 'Diastolic Blood Pressure16',\n",
        " 'Diastolic Blood Pressure18',\n",
        " 'Diastolic Blood Pressure19',\n",
        " 'Diastolic Blood Pressure20',\n",
        " 'Diastolic Blood Pressure21',\n",
        " 'Diastolic Blood Pressure2_current_stay',\n",
        " 'Diastolic Blood Pressure3_current_stay',\n",
        " 'Diastolic Blood Pressure4_current_stay',\n",
        " 'Diastolic Blood Pressure5_current_stay',\n",
        " 'Diastolic Blood Pressure6_current_stay',\n",
        " 'Diastolic Blood Pressure8_current_stay',\n",
        " 'Diastolic Blood Pressure12_current_stay',\n",
        " 'Diastolic Blood Pressure13_current_stay',\n",
        " 'Diastolic Blood Pressure14_current_stay',\n",
        " 'Diastolic Blood Pressure16_current_stay',\n",
        " 'Diastolic Blood Pressure18_current_stay',\n",
        " 'Diastolic Blood Pressure19_current_stay',\n",
        " 'Diastolic Blood Pressure20_current_stay',\n",
        " 'Diastolic Blood Pressure21_current_stay',\n",
        " 'Glasgow Coma Score0',\n",
        " 'Glasgow Coma Score1',\n",
        " 'Glasgow Coma Score2',\n",
        " 'Glasgow Coma Score3',\n",
        " 'Glasgow Coma Score4',\n",
        " 'Glasgow Coma Score5',\n",
        " 'Glasgow Coma Score6',\n",
        " 'Glasgow Coma Score7',\n",
        " 'Glasgow Coma Score8',\n",
        " 'Glasgow Coma Score9',\n",
        " 'Glasgow Coma Score10',\n",
        " 'Glasgow Coma Score11',\n",
        " 'Glasgow Coma Score12',\n",
        " 'Glasgow Coma Score13',\n",
        " 'Glasgow Coma Score14',\n",
        " 'Glasgow Coma Score15',\n",
        " 'Glasgow Coma Score16',\n",
        " 'Glasgow Coma Score17',\n",
        " 'Glasgow Coma Score18',\n",
        " 'Glasgow Coma Score19',\n",
        " 'Glasgow Coma Score20',\n",
        " 'Glasgow Coma Score21',\n",
        " 'Glasgow Coma Score0_current_stay',\n",
        " 'Glasgow Coma Score1_current_stay',\n",
        " 'Glasgow Coma Score2_current_stay',\n",
        " 'Glasgow Coma Score3_current_stay',\n",
        " 'Glasgow Coma Score4_current_stay',\n",
        " 'Glasgow Coma Score5_current_stay',\n",
        " 'Glasgow Coma Score6_current_stay',\n",
        " 'Glasgow Coma Score7_current_stay',\n",
        " 'Glasgow Coma Score8_current_stay',\n",
        " 'Glasgow Coma Score10_current_stay',\n",
        " 'Glasgow Coma Score11_current_stay',\n",
        " 'Glasgow Coma Score12_current_stay',\n",
        " 'Glasgow Coma Score13_current_stay',\n",
        " 'Glasgow Coma Score14_current_stay',\n",
        " 'Glasgow Coma Score15_current_stay',\n",
        " 'Glasgow Coma Score16_current_stay',\n",
        " 'Glasgow Coma Score17_current_stay',\n",
        " 'Glasgow Coma Score18_current_stay',\n",
        " 'Glasgow Coma Score19_current_stay',\n",
        " 'Glasgow Coma Score20_current_stay',\n",
        " 'Glasgow Coma Score21_current_stay',\n",
        " 'Heart Rate2',\n",
        " 'Heart Rate3',\n",
        " 'Heart Rate4',\n",
        " 'Heart Rate5',\n",
        " 'Heart Rate6',\n",
        " 'Heart Rate7',\n",
        " 'Heart Rate8',\n",
        " 'Heart Rate9',\n",
        " 'Heart Rate11',\n",
        " 'Heart Rate12',\n",
        " 'Heart Rate13',\n",
        " 'Heart Rate14',\n",
        " 'Heart Rate15',\n",
        " 'Heart Rate16',\n",
        " 'Heart Rate18',\n",
        " 'Heart Rate19',\n",
        " 'Heart Rate20',\n",
        " 'Heart Rate21',\n",
        " 'Heart Rate2_current_stay',\n",
        " 'Heart Rate3_current_stay',\n",
        " 'Heart Rate4_current_stay',\n",
        " 'Heart Rate5_current_stay',\n",
        " 'Heart Rate6_current_stay',\n",
        " 'Heart Rate8_current_stay',\n",
        " 'Heart Rate12_current_stay',\n",
        " 'Heart Rate13_current_stay',\n",
        " 'Heart Rate14_current_stay',\n",
        " 'Heart Rate16_current_stay',\n",
        " 'Heart Rate18_current_stay',\n",
        " 'Heart Rate19_current_stay',\n",
        " 'Heart Rate20_current_stay',\n",
        " 'Heart Rate21_current_stay',\n",
        " 'Mean Arterial Pressure2',\n",
        " 'Mean Arterial Pressure3',\n",
        " 'Mean Arterial Pressure4',\n",
        " 'Mean Arterial Pressure5',\n",
        " 'Mean Arterial Pressure6',\n",
        " 'Mean Arterial Pressure7',\n",
        " 'Mean Arterial Pressure8',\n",
        " 'Mean Arterial Pressure9',\n",
        " 'Mean Arterial Pressure11',\n",
        " 'Mean Arterial Pressure12',\n",
        " 'Mean Arterial Pressure13',\n",
        " 'Mean Arterial Pressure14',\n",
        " 'Mean Arterial Pressure15',\n",
        " 'Mean Arterial Pressure16',\n",
        " 'Mean Arterial Pressure18',\n",
        " 'Mean Arterial Pressure19',\n",
        " 'Mean Arterial Pressure20',\n",
        " 'Mean Arterial Pressure21',\n",
        " 'Mean Arterial Pressure2_current_stay',\n",
        " 'Mean Arterial Pressure3_current_stay',\n",
        " 'Mean Arterial Pressure4_current_stay',\n",
        " 'Mean Arterial Pressure5_current_stay',\n",
        " 'Mean Arterial Pressure6_current_stay',\n",
        " 'Mean Arterial Pressure8_current_stay',\n",
        " 'Mean Arterial Pressure12_current_stay',\n",
        " 'Mean Arterial Pressure13_current_stay',\n",
        " 'Mean Arterial Pressure14_current_stay',\n",
        " 'Mean Arterial Pressure16_current_stay',\n",
        " 'Mean Arterial Pressure18_current_stay',\n",
        " 'Mean Arterial Pressure19_current_stay',\n",
        " 'Mean Arterial Pressure20_current_stay',\n",
        " 'Mean Arterial Pressure21_current_stay',\n",
        " 'NEWS Conscious Level Score0',\n",
        " 'NEWS Conscious Level Score1',\n",
        " 'NEWS Conscious Level Score2',\n",
        " 'NEWS Conscious Level Score3',\n",
        " 'NEWS Conscious Level Score4',\n",
        " 'NEWS Conscious Level Score5',\n",
        " 'NEWS Conscious Level Score6',\n",
        " 'NEWS Conscious Level Score7',\n",
        " 'NEWS Conscious Level Score8',\n",
        " 'NEWS Conscious Level Score9',\n",
        " 'NEWS Conscious Level Score10',\n",
        " 'NEWS Conscious Level Score11',\n",
        " 'NEWS Conscious Level Score12',\n",
        " 'NEWS Conscious Level Score13',\n",
        " 'NEWS Conscious Level Score14',\n",
        " 'NEWS Conscious Level Score15',\n",
        " 'NEWS Conscious Level Score16',\n",
        " 'NEWS Conscious Level Score17',\n",
        " 'NEWS Conscious Level Score18',\n",
        " 'NEWS Conscious Level Score19',\n",
        " 'NEWS Conscious Level Score20',\n",
        " 'NEWS Conscious Level Score21',\n",
        " 'NEWS Conscious Level Score0_current_stay',\n",
        " 'NEWS Conscious Level Score1_current_stay',\n",
        " 'NEWS Conscious Level Score2_current_stay',\n",
        " 'NEWS Conscious Level Score3_current_stay',\n",
        " 'NEWS Conscious Level Score4_current_stay',\n",
        " 'NEWS Conscious Level Score5_current_stay',\n",
        " 'NEWS Conscious Level Score6_current_stay',\n",
        " 'NEWS Conscious Level Score7_current_stay',\n",
        " 'NEWS Conscious Level Score8_current_stay',\n",
        " 'NEWS Conscious Level Score9_current_stay',\n",
        " 'NEWS Conscious Level Score10_current_stay',\n",
        " 'NEWS Conscious Level Score11_current_stay',\n",
        " 'NEWS Conscious Level Score12_current_stay',\n",
        " 'NEWS Conscious Level Score13_current_stay',\n",
        " 'NEWS Conscious Level Score14_current_stay',\n",
        " 'NEWS Conscious Level Score15_current_stay',\n",
        " 'NEWS Conscious Level Score16_current_stay',\n",
        " 'NEWS Conscious Level Score17_current_stay',\n",
        " 'NEWS Conscious Level Score18_current_stay',\n",
        " 'NEWS Conscious Level Score19_current_stay',\n",
        " 'NEWS Conscious Level Score20_current_stay',\n",
        " 'NEWS Conscious Level Score21_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc0',\n",
        " 'NEWS Supplemental Oxygen Calc1',\n",
        " 'NEWS Supplemental Oxygen Calc2',\n",
        " 'NEWS Supplemental Oxygen Calc3',\n",
        " 'NEWS Supplemental Oxygen Calc4',\n",
        " 'NEWS Supplemental Oxygen Calc5',\n",
        " 'NEWS Supplemental Oxygen Calc6',\n",
        " 'NEWS Supplemental Oxygen Calc7',\n",
        " 'NEWS Supplemental Oxygen Calc8',\n",
        " 'NEWS Supplemental Oxygen Calc9',\n",
        " 'NEWS Supplemental Oxygen Calc10',\n",
        " 'NEWS Supplemental Oxygen Calc11',\n",
        " 'NEWS Supplemental Oxygen Calc12',\n",
        " 'NEWS Supplemental Oxygen Calc13',\n",
        " 'NEWS Supplemental Oxygen Calc14',\n",
        " 'NEWS Supplemental Oxygen Calc15',\n",
        " 'NEWS Supplemental Oxygen Calc16',\n",
        " 'NEWS Supplemental Oxygen Calc17',\n",
        " 'NEWS Supplemental Oxygen Calc18',\n",
        " 'NEWS Supplemental Oxygen Calc19',\n",
        " 'NEWS Supplemental Oxygen Calc20',\n",
        " 'NEWS Supplemental Oxygen Calc21',\n",
        " 'NEWS Supplemental Oxygen Calc0_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc1_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc2_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc3_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc4_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc5_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc6_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc7_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc8_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc9_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc10_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc11_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc12_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc13_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc14_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc15_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc16_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc17_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc18_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc19_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc20_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc21_current_stay',\n",
        " 'Respiratory Rate0',\n",
        " 'Respiratory Rate2',\n",
        " 'Respiratory Rate3',\n",
        " 'Respiratory Rate4',\n",
        " 'Respiratory Rate5',\n",
        " 'Respiratory Rate6',\n",
        " 'Respiratory Rate7',\n",
        " 'Respiratory Rate8',\n",
        " 'Respiratory Rate9',\n",
        " 'Respiratory Rate11',\n",
        " 'Respiratory Rate12',\n",
        " 'Respiratory Rate13',\n",
        " 'Respiratory Rate14',\n",
        " 'Respiratory Rate15',\n",
        " 'Respiratory Rate16',\n",
        " 'Respiratory Rate18',\n",
        " 'Respiratory Rate19',\n",
        " 'Respiratory Rate20',\n",
        " 'Respiratory Rate21',\n",
        " 'Respiratory Rate0_current_stay',\n",
        " 'Respiratory Rate2_current_stay',\n",
        " 'Respiratory Rate3_current_stay',\n",
        " 'Respiratory Rate4_current_stay',\n",
        " 'Respiratory Rate5_current_stay',\n",
        " 'Respiratory Rate6_current_stay',\n",
        " 'Respiratory Rate8_current_stay',\n",
        " 'Respiratory Rate12_current_stay',\n",
        " 'Respiratory Rate13_current_stay',\n",
        " 'Respiratory Rate14_current_stay',\n",
        " 'Respiratory Rate16_current_stay',\n",
        " 'Respiratory Rate18_current_stay',\n",
        " 'Respiratory Rate19_current_stay',\n",
        " 'Respiratory Rate20_current_stay',\n",
        " 'Respiratory Rate21_current_stay',\n",
        " 'SpO20',\n",
        " 'SpO22',\n",
        " 'SpO23',\n",
        " 'SpO24',\n",
        " 'SpO25',\n",
        " 'SpO26',\n",
        " 'SpO27',\n",
        " 'SpO28',\n",
        " 'SpO29',\n",
        " 'SpO211',\n",
        " 'SpO212',\n",
        " 'SpO213',\n",
        " 'SpO214',\n",
        " 'SpO215',\n",
        " 'SpO216',\n",
        " 'SpO218',\n",
        " 'SpO219',\n",
        " 'SpO220',\n",
        " 'SpO221',\n",
        " 'SpO20_current_stay',\n",
        " 'SpO22_current_stay',\n",
        " 'SpO23_current_stay',\n",
        " 'SpO24_current_stay',\n",
        " 'SpO25_current_stay',\n",
        " 'SpO26_current_stay',\n",
        " 'SpO28_current_stay',\n",
        " 'SpO212_current_stay',\n",
        " 'SpO213_current_stay',\n",
        " 'SpO214_current_stay',\n",
        " 'SpO216_current_stay',\n",
        " 'SpO218_current_stay',\n",
        " 'SpO219_current_stay',\n",
        " 'SpO220_current_stay',\n",
        " 'SpO221_current_stay',\n",
        " 'Systolic Blood Pressure2',\n",
        " 'Systolic Blood Pressure3',\n",
        " 'Systolic Blood Pressure4',\n",
        " 'Systolic Blood Pressure5',\n",
        " 'Systolic Blood Pressure6',\n",
        " 'Systolic Blood Pressure7',\n",
        " 'Systolic Blood Pressure8',\n",
        " 'Systolic Blood Pressure9',\n",
        " 'Systolic Blood Pressure11',\n",
        " 'Systolic Blood Pressure12',\n",
        " 'Systolic Blood Pressure13',\n",
        " 'Systolic Blood Pressure14',\n",
        " 'Systolic Blood Pressure15',\n",
        " 'Systolic Blood Pressure16',\n",
        " 'Systolic Blood Pressure18',\n",
        " 'Systolic Blood Pressure19',\n",
        " 'Systolic Blood Pressure20',\n",
        " 'Systolic Blood Pressure21',\n",
        " 'Systolic Blood Pressure2_current_stay',\n",
        " 'Systolic Blood Pressure3_current_stay',\n",
        " 'Systolic Blood Pressure4_current_stay',\n",
        " 'Systolic Blood Pressure5_current_stay',\n",
        " 'Systolic Blood Pressure6_current_stay',\n",
        " 'Systolic Blood Pressure8_current_stay',\n",
        " 'Systolic Blood Pressure12_current_stay',\n",
        " 'Systolic Blood Pressure13_current_stay',\n",
        " 'Systolic Blood Pressure14_current_stay',\n",
        " 'Systolic Blood Pressure16_current_stay',\n",
        " 'Systolic Blood Pressure18_current_stay',\n",
        " 'Systolic Blood Pressure19_current_stay',\n",
        " 'Systolic Blood Pressure20_current_stay',\n",
        " 'Systolic Blood Pressure21_current_stay',\n",
        " 'Temperature0',\n",
        " 'Temperature2',\n",
        " 'Temperature3',\n",
        " 'Temperature4',\n",
        " 'Temperature5',\n",
        " 'Temperature6',\n",
        " 'Temperature7',\n",
        " 'Temperature8',\n",
        " 'Temperature9',\n",
        " 'Temperature11',\n",
        " 'Temperature12',\n",
        " 'Temperature13',\n",
        " 'Temperature14',\n",
        " 'Temperature15',\n",
        " 'Temperature16',\n",
        " 'Temperature18',\n",
        " 'Temperature19',\n",
        " 'Temperature20',\n",
        " 'Temperature21',\n",
        " 'Temperature0_current_stay',\n",
        " 'Temperature2_current_stay',\n",
        " 'Temperature3_current_stay',\n",
        " 'Temperature4_current_stay',\n",
        " 'Temperature5_current_stay',\n",
        " 'Temperature6_current_stay',\n",
        " 'Temperature8_current_stay',\n",
        " 'Temperature12_current_stay',\n",
        " 'Temperature13_current_stay',\n",
        " 'Temperature14_current_stay',\n",
        " 'Temperature16_current_stay',\n",
        " 'Temperature18_current_stay',\n",
        " 'Temperature19_current_stay',\n",
        " 'Temperature20_current_stay',\n",
        " 'Temperature21_current_stay',\n",
        " 'Diastolic Blood Pressure2_difference',\n",
        " 'Diastolic Blood Pressure3_difference',\n",
        " 'Diastolic Blood Pressure4_difference',\n",
        " 'Diastolic Blood Pressure5_difference',\n",
        " 'Diastolic Blood Pressure6_difference',\n",
        " 'Diastolic Blood Pressure7_difference',\n",
        " 'Diastolic Blood Pressure8_difference',\n",
        " 'Diastolic Blood Pressure9_difference',\n",
        " 'Diastolic Blood Pressure11_difference',\n",
        " 'Diastolic Blood Pressure12_difference',\n",
        " 'Diastolic Blood Pressure13_difference',\n",
        " 'Diastolic Blood Pressure14_difference',\n",
        " 'Diastolic Blood Pressure15_difference',\n",
        " 'Diastolic Blood Pressure16_difference',\n",
        " 'Diastolic Blood Pressure18_difference',\n",
        " 'Diastolic Blood Pressure19_difference',\n",
        " 'Diastolic Blood Pressure20_difference',\n",
        " 'Diastolic Blood Pressure21_difference',\n",
        " 'Diastolic Blood Pressure2_current_stay_difference',\n",
        " 'Diastolic Blood Pressure3_current_stay_difference',\n",
        " 'Diastolic Blood Pressure4_current_stay_difference',\n",
        " 'Diastolic Blood Pressure5_current_stay_difference',\n",
        " 'Diastolic Blood Pressure6_current_stay_difference',\n",
        " 'Diastolic Blood Pressure8_current_stay_difference',\n",
        " 'Diastolic Blood Pressure12_current_stay_difference',\n",
        " 'Diastolic Blood Pressure13_current_stay_difference',\n",
        " 'Diastolic Blood Pressure14_current_stay_difference',\n",
        " 'Diastolic Blood Pressure16_current_stay_difference',\n",
        " 'Diastolic Blood Pressure18_current_stay_difference',\n",
        " 'Diastolic Blood Pressure19_current_stay_difference',\n",
        " 'Diastolic Blood Pressure21_current_stay_difference',\n",
        " 'Glasgow Coma Score0_difference',\n",
        " 'Glasgow Coma Score1_difference',\n",
        " 'Glasgow Coma Score2_difference',\n",
        " 'Glasgow Coma Score3_difference',\n",
        " 'Glasgow Coma Score4_difference',\n",
        " 'Glasgow Coma Score5_difference',\n",
        " 'Glasgow Coma Score6_difference',\n",
        " 'Glasgow Coma Score7_difference',\n",
        " 'Glasgow Coma Score8_difference',\n",
        " 'Glasgow Coma Score9_difference',\n",
        " 'Glasgow Coma Score10_difference',\n",
        " 'Glasgow Coma Score11_difference',\n",
        " 'Glasgow Coma Score12_difference',\n",
        " 'Glasgow Coma Score13_difference',\n",
        " 'Glasgow Coma Score14_difference',\n",
        " 'Glasgow Coma Score15_difference',\n",
        " 'Glasgow Coma Score16_difference',\n",
        " 'Glasgow Coma Score17_difference',\n",
        " 'Glasgow Coma Score18_difference',\n",
        " 'Glasgow Coma Score19_difference',\n",
        " 'Glasgow Coma Score20_difference',\n",
        " 'Glasgow Coma Score21_difference',\n",
        " 'Glasgow Coma Score0_current_stay_difference',\n",
        " 'Glasgow Coma Score1_current_stay_difference',\n",
        " 'Glasgow Coma Score2_current_stay_difference',\n",
        " 'Glasgow Coma Score3_current_stay_difference',\n",
        " 'Glasgow Coma Score4_current_stay_difference',\n",
        " 'Glasgow Coma Score5_current_stay_difference',\n",
        " 'Glasgow Coma Score6_current_stay_difference',\n",
        " 'Glasgow Coma Score7_current_stay_difference',\n",
        " 'Glasgow Coma Score8_current_stay_difference',\n",
        " 'Glasgow Coma Score10_current_stay_difference',\n",
        " 'Glasgow Coma Score11_current_stay_difference',\n",
        " 'Glasgow Coma Score12_current_stay_difference',\n",
        " 'Glasgow Coma Score13_current_stay_difference',\n",
        " 'Glasgow Coma Score14_current_stay_difference',\n",
        " 'Glasgow Coma Score15_current_stay_difference',\n",
        " 'Glasgow Coma Score16_current_stay_difference',\n",
        " 'Glasgow Coma Score17_current_stay_difference',\n",
        " 'Glasgow Coma Score18_current_stay_difference',\n",
        " 'Glasgow Coma Score19_current_stay_difference',\n",
        " 'Glasgow Coma Score20_current_stay_difference',\n",
        " 'Glasgow Coma Score21_current_stay_difference',\n",
        " 'Heart Rate2_difference',\n",
        " 'Heart Rate3_difference',\n",
        " 'Heart Rate4_difference',\n",
        " 'Heart Rate5_difference',\n",
        " 'Heart Rate6_difference',\n",
        " 'Heart Rate7_difference',\n",
        " 'Heart Rate8_difference',\n",
        " 'Heart Rate9_difference',\n",
        " 'Heart Rate11_difference',\n",
        " 'Heart Rate12_difference',\n",
        " 'Heart Rate13_difference',\n",
        " 'Heart Rate14_difference',\n",
        " 'Heart Rate15_difference',\n",
        " 'Heart Rate16_difference',\n",
        " 'Heart Rate18_difference',\n",
        " 'Heart Rate19_difference',\n",
        " 'Heart Rate20_difference',\n",
        " 'Heart Rate21_difference',\n",
        " 'Heart Rate2_current_stay_difference',\n",
        " 'Heart Rate3_current_stay_difference',\n",
        " 'Heart Rate4_current_stay_difference',\n",
        " 'Heart Rate5_current_stay_difference',\n",
        " 'Heart Rate6_current_stay_difference',\n",
        " 'Heart Rate8_current_stay_difference',\n",
        " 'Heart Rate12_current_stay_difference',\n",
        " 'Heart Rate13_current_stay_difference',\n",
        " 'Heart Rate14_current_stay_difference',\n",
        " 'Heart Rate16_current_stay_difference',\n",
        " 'Heart Rate18_current_stay_difference',\n",
        " 'Heart Rate19_current_stay_difference',\n",
        " 'Heart Rate21_current_stay_difference',\n",
        " 'Mean Arterial Pressure2_difference',\n",
        " 'Mean Arterial Pressure3_difference',\n",
        " 'Mean Arterial Pressure4_difference',\n",
        " 'Mean Arterial Pressure5_difference',\n",
        " 'Mean Arterial Pressure6_difference',\n",
        " 'Mean Arterial Pressure7_difference',\n",
        " 'Mean Arterial Pressure8_difference',\n",
        " 'Mean Arterial Pressure9_difference',\n",
        " 'Mean Arterial Pressure11_difference',\n",
        " 'Mean Arterial Pressure12_difference',\n",
        " 'Mean Arterial Pressure13_difference',\n",
        " 'Mean Arterial Pressure14_difference',\n",
        " 'Mean Arterial Pressure15_difference',\n",
        " 'Mean Arterial Pressure16_difference',\n",
        " 'Mean Arterial Pressure18_difference',\n",
        " 'Mean Arterial Pressure19_difference',\n",
        " 'Mean Arterial Pressure20_difference',\n",
        " 'Mean Arterial Pressure21_difference',\n",
        " 'Mean Arterial Pressure2_current_stay_difference',\n",
        " 'Mean Arterial Pressure3_current_stay_difference',\n",
        " 'Mean Arterial Pressure4_current_stay_difference',\n",
        " 'Mean Arterial Pressure5_current_stay_difference',\n",
        " 'Mean Arterial Pressure6_current_stay_difference',\n",
        " 'Mean Arterial Pressure8_current_stay_difference',\n",
        " 'Mean Arterial Pressure12_current_stay_difference',\n",
        " 'Mean Arterial Pressure13_current_stay_difference',\n",
        " 'Mean Arterial Pressure14_current_stay_difference',\n",
        " 'Mean Arterial Pressure16_current_stay_difference',\n",
        " 'Mean Arterial Pressure18_current_stay_difference',\n",
        " 'Mean Arterial Pressure19_current_stay_difference',\n",
        " 'Mean Arterial Pressure21_current_stay_difference',\n",
        " 'NEWS Conscious Level Score0_difference',\n",
        " 'NEWS Conscious Level Score1_difference',\n",
        " 'NEWS Conscious Level Score2_difference',\n",
        " 'NEWS Conscious Level Score3_difference',\n",
        " 'NEWS Conscious Level Score4_difference',\n",
        " 'NEWS Conscious Level Score5_difference',\n",
        " 'NEWS Conscious Level Score6_difference',\n",
        " 'NEWS Conscious Level Score7_difference',\n",
        " 'NEWS Conscious Level Score8_difference',\n",
        " 'NEWS Conscious Level Score9_difference',\n",
        " 'NEWS Conscious Level Score10_difference',\n",
        " 'NEWS Conscious Level Score11_difference',\n",
        " 'NEWS Conscious Level Score12_difference',\n",
        " 'NEWS Conscious Level Score13_difference',\n",
        " 'NEWS Conscious Level Score14_difference',\n",
        " 'NEWS Conscious Level Score15_difference',\n",
        " 'NEWS Conscious Level Score16_difference',\n",
        " 'NEWS Conscious Level Score17_difference',\n",
        " 'NEWS Conscious Level Score18_difference',\n",
        " 'NEWS Conscious Level Score19_difference',\n",
        " 'NEWS Conscious Level Score20_difference',\n",
        " 'NEWS Conscious Level Score21_difference',\n",
        " 'NEWS Conscious Level Score0_current_stay_difference',\n",
        " 'NEWS Conscious Level Score1_current_stay_difference',\n",
        " 'NEWS Conscious Level Score2_current_stay_difference',\n",
        " 'NEWS Conscious Level Score3_current_stay_difference',\n",
        " 'NEWS Conscious Level Score4_current_stay_difference',\n",
        " 'NEWS Conscious Level Score5_current_stay_difference',\n",
        " 'NEWS Conscious Level Score6_current_stay_difference',\n",
        " 'NEWS Conscious Level Score7_current_stay_difference',\n",
        " 'NEWS Conscious Level Score8_current_stay_difference',\n",
        " 'NEWS Conscious Level Score9_current_stay_difference',\n",
        " 'NEWS Conscious Level Score10_current_stay_difference',\n",
        " 'NEWS Conscious Level Score11_current_stay_difference',\n",
        " 'NEWS Conscious Level Score12_current_stay_difference',\n",
        " 'NEWS Conscious Level Score13_current_stay_difference',\n",
        " 'NEWS Conscious Level Score14_current_stay_difference',\n",
        " 'NEWS Conscious Level Score15_current_stay_difference',\n",
        " 'NEWS Conscious Level Score16_current_stay_difference',\n",
        " 'NEWS Conscious Level Score17_current_stay_difference',\n",
        " 'NEWS Conscious Level Score18_current_stay_difference',\n",
        " 'NEWS Conscious Level Score19_current_stay_difference',\n",
        " 'NEWS Conscious Level Score20_current_stay_difference',\n",
        " 'NEWS Conscious Level Score21_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc0_difference',\n",
        " 'NEWS Supplemental Oxygen Calc1_difference',\n",
        " 'NEWS Supplemental Oxygen Calc2_difference',\n",
        " 'NEWS Supplemental Oxygen Calc3_difference',\n",
        " 'NEWS Supplemental Oxygen Calc4_difference',\n",
        " 'NEWS Supplemental Oxygen Calc5_difference',\n",
        " 'NEWS Supplemental Oxygen Calc6_difference',\n",
        " 'NEWS Supplemental Oxygen Calc7_difference',\n",
        " 'NEWS Supplemental Oxygen Calc8_difference',\n",
        " 'NEWS Supplemental Oxygen Calc9_difference',\n",
        " 'NEWS Supplemental Oxygen Calc10_difference',\n",
        " 'NEWS Supplemental Oxygen Calc11_difference',\n",
        " 'NEWS Supplemental Oxygen Calc12_difference',\n",
        " 'NEWS Supplemental Oxygen Calc13_difference',\n",
        " 'NEWS Supplemental Oxygen Calc14_difference',\n",
        " 'NEWS Supplemental Oxygen Calc15_difference',\n",
        " 'NEWS Supplemental Oxygen Calc16_difference',\n",
        " 'NEWS Supplemental Oxygen Calc17_difference',\n",
        " 'NEWS Supplemental Oxygen Calc18_difference',\n",
        " 'NEWS Supplemental Oxygen Calc19_difference',\n",
        " 'NEWS Supplemental Oxygen Calc20_difference',\n",
        " 'NEWS Supplemental Oxygen Calc21_difference',\n",
        " 'NEWS Supplemental Oxygen Calc0_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc1_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc2_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc3_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc4_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc5_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc6_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc7_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc8_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc10_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc12_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc13_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc14_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc15_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc16_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc18_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc19_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc20_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc21_current_stay_difference',\n",
        " 'Respiratory Rate2_difference',\n",
        " 'Respiratory Rate3_difference',\n",
        " 'Respiratory Rate4_difference',\n",
        " 'Respiratory Rate5_difference',\n",
        " 'Respiratory Rate6_difference',\n",
        " 'Respiratory Rate7_difference',\n",
        " 'Respiratory Rate8_difference',\n",
        " 'Respiratory Rate9_difference',\n",
        " 'Respiratory Rate11_difference',\n",
        " 'Respiratory Rate12_difference',\n",
        " 'Respiratory Rate13_difference',\n",
        " 'Respiratory Rate14_difference',\n",
        " 'Respiratory Rate15_difference',\n",
        " 'Respiratory Rate16_difference',\n",
        " 'Respiratory Rate18_difference',\n",
        " 'Respiratory Rate19_difference',\n",
        " 'Respiratory Rate20_difference',\n",
        " 'Respiratory Rate21_difference',\n",
        " 'Respiratory Rate0_current_stay_difference',\n",
        " 'Respiratory Rate2_current_stay_difference',\n",
        " 'Respiratory Rate3_current_stay_difference',\n",
        " 'Respiratory Rate4_current_stay_difference',\n",
        " 'Respiratory Rate5_current_stay_difference',\n",
        " 'Respiratory Rate6_current_stay_difference',\n",
        " 'Respiratory Rate8_current_stay_difference',\n",
        " 'Respiratory Rate12_current_stay_difference',\n",
        " 'Respiratory Rate13_current_stay_difference',\n",
        " 'Respiratory Rate14_current_stay_difference',\n",
        " 'Respiratory Rate16_current_stay_difference',\n",
        " 'Respiratory Rate18_current_stay_difference',\n",
        " 'Respiratory Rate19_current_stay_difference',\n",
        " 'Respiratory Rate21_current_stay_difference',\n",
        " 'SpO22_difference',\n",
        " 'SpO23_difference',\n",
        " 'SpO24_difference',\n",
        " 'SpO25_difference',\n",
        " 'SpO26_difference',\n",
        " 'SpO27_difference',\n",
        " 'SpO28_difference',\n",
        " 'SpO29_difference',\n",
        " 'SpO211_difference',\n",
        " 'SpO212_difference',\n",
        " 'SpO213_difference',\n",
        " 'SpO214_difference',\n",
        " 'SpO215_difference',\n",
        " 'SpO216_difference',\n",
        " 'SpO218_difference',\n",
        " 'SpO219_difference',\n",
        " 'SpO220_difference',\n",
        " 'SpO221_difference',\n",
        " 'SpO22_current_stay_difference',\n",
        " 'SpO23_current_stay_difference',\n",
        " 'SpO24_current_stay_difference',\n",
        " 'SpO25_current_stay_difference',\n",
        " 'SpO26_current_stay_difference',\n",
        " 'SpO28_current_stay_difference',\n",
        " 'SpO212_current_stay_difference',\n",
        " 'SpO213_current_stay_difference',\n",
        " 'SpO214_current_stay_difference',\n",
        " 'SpO216_current_stay_difference',\n",
        " 'SpO218_current_stay_difference',\n",
        " 'SpO219_current_stay_difference',\n",
        " 'SpO221_current_stay_difference',\n",
        " 'Systolic Blood Pressure2_difference',\n",
        " 'Systolic Blood Pressure3_difference',\n",
        " 'Systolic Blood Pressure4_difference',\n",
        " 'Systolic Blood Pressure5_difference',\n",
        " 'Systolic Blood Pressure6_difference',\n",
        " 'Systolic Blood Pressure7_difference',\n",
        " 'Systolic Blood Pressure8_difference',\n",
        " 'Systolic Blood Pressure9_difference',\n",
        " 'Systolic Blood Pressure11_difference',\n",
        " 'Systolic Blood Pressure12_difference',\n",
        " 'Systolic Blood Pressure13_difference',\n",
        " 'Systolic Blood Pressure14_difference',\n",
        " 'Systolic Blood Pressure15_difference',\n",
        " 'Systolic Blood Pressure16_difference',\n",
        " 'Systolic Blood Pressure18_difference',\n",
        " 'Systolic Blood Pressure19_difference',\n",
        " 'Systolic Blood Pressure20_difference',\n",
        " 'Systolic Blood Pressure21_difference',\n",
        " 'Systolic Blood Pressure2_current_stay_difference',\n",
        " 'Systolic Blood Pressure3_current_stay_difference',\n",
        " 'Systolic Blood Pressure4_current_stay_difference',\n",
        " 'Systolic Blood Pressure5_current_stay_difference',\n",
        " 'Systolic Blood Pressure6_current_stay_difference',\n",
        " 'Systolic Blood Pressure8_current_stay_difference',\n",
        " 'Systolic Blood Pressure12_current_stay_difference',\n",
        " 'Systolic Blood Pressure13_current_stay_difference',\n",
        " 'Systolic Blood Pressure14_current_stay_difference',\n",
        " 'Systolic Blood Pressure16_current_stay_difference',\n",
        " 'Systolic Blood Pressure18_current_stay_difference',\n",
        " 'Systolic Blood Pressure19_current_stay_difference',\n",
        " 'Systolic Blood Pressure21_current_stay_difference',\n",
        " 'Temperature2_difference',\n",
        " 'Temperature3_difference',\n",
        " 'Temperature4_difference',\n",
        " 'Temperature5_difference',\n",
        " 'Temperature6_difference',\n",
        " 'Temperature7_difference',\n",
        " 'Temperature8_difference',\n",
        " 'Temperature9_difference',\n",
        " 'Temperature11_difference',\n",
        " 'Temperature12_difference',\n",
        " 'Temperature13_difference',\n",
        " 'Temperature14_difference',\n",
        " 'Temperature15_difference',\n",
        " 'Temperature16_difference',\n",
        " 'Temperature18_difference',\n",
        " 'Temperature19_difference',\n",
        " 'Temperature20_difference',\n",
        " 'Temperature21_difference',\n",
        " 'Temperature2_current_stay_difference',\n",
        " 'Temperature3_current_stay_difference',\n",
        " 'Temperature4_current_stay_difference',\n",
        " 'Temperature5_current_stay_difference',\n",
        " 'Temperature6_current_stay_difference',\n",
        " 'Temperature8_current_stay_difference',\n",
        " 'Temperature12_current_stay_difference',\n",
        " 'Temperature13_current_stay_difference',\n",
        " 'Temperature14_current_stay_difference',\n",
        " 'Temperature16_current_stay_difference',\n",
        " 'Temperature18_current_stay_difference',\n",
        " 'Temperature19_current_stay_difference',\n",
        " 'Temperature21_current_stay_difference']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1710838372057
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "class MultiInputDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dfs_list, labels, comorbidites, padding_mask):\n",
        "        self.dfs_list = dfs_list\n",
        "        self.labels = labels\n",
        "        self.padding_mask = padding_mask\n",
        "        self.comorbidites = comorbidites\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = [torch.tensor(df.iloc[idx].values) for df in self.dfs_list]\n",
        "        labels = torch.tensor(self.labels[['po_flag']].iloc[idx].to_numpy())\n",
        "        features.append(self.comorbidites[idx])\n",
        "        sample = {\"labels\": labels, \"features\": features, \"mask\":self.padding_mask[idx]}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Main run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1710770587961
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4087/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Chronic_switch_model(\n",
              "  (final_layers): Sequential(\n",
              "    (0): Linear(in_features=268, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.1, inplace=False)\n",
              "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (vital_model): Initial_vitals_model(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(253, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Linear(in_features=253, out_features=512, bias=True)\n",
              "      (2): ReLU()\n",
              "      (3): Dropout(p=0.1, inplace=False)\n",
              "      (4): Linear(in_features=512, out_features=128, bias=True)\n",
              "      (5): ReLU()\n",
              "      (6): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (set_transformer): SetTransformer(\n",
              "    (enc): Sequential(\n",
              "      (0): ISAB(\n",
              "        (mab0): MAB0(\n",
              "          (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_k): Linear(in_features=128, out_features=160, bias=True)\n",
              "          (fc_v): Linear(in_features=128, out_features=160, bias=True)\n",
              "          (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "        )\n",
              "        (mab1): MAB(\n",
              "          (fc_q): Linear(in_features=128, out_features=160, bias=True)\n",
              "          (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (1): ISAB(\n",
              "        (mab0): MAB0(\n",
              "          (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "        )\n",
              "        (mab1): MAB(\n",
              "          (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (isab): ISAB(\n",
              "      (mab0): MAB0(\n",
              "        (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_k): Linear(in_features=128, out_features=160, bias=True)\n",
              "        (fc_v): Linear(in_features=128, out_features=160, bias=True)\n",
              "        (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "      )\n",
              "      (mab1): MAB(\n",
              "        (fc_q): Linear(in_features=128, out_features=160, bias=True)\n",
              "        (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (pma): PMA(\n",
              "      (mab): MAB0(\n",
              "        (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (dec): Sequential(\n",
              "      (0): Linear(in_features=160, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (demographics): Linear(in_features=12, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 1,126,583 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "final_input_dim = 268\n",
        "final_output_dim = 1\n",
        "final_hid_dim = 512\n",
        "final_hid_dim2 = 128\n",
        "demographics_input_dim = 12\n",
        "demographics_output_dim = 12\n",
        "vital_input_dim = 253\n",
        "vital_hid_dim = 512\n",
        "vital_output_dim = 128\n",
        "dropout = 0.1\n",
        "\n",
        "# Define model\n",
        "model = Chronic_switch_model(\n",
        "    final_input_dim, \n",
        "    final_output_dim, \n",
        "    final_hid_dim, \n",
        "    final_hid_dim2,\n",
        "    demographics_input_dim,\n",
        "    demographics_output_dim,\n",
        "    vital_input_dim, \n",
        "    vital_hid_dim, \n",
        "    vital_output_dim, \n",
        "    dropout).to(device)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1711636476281
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/chronic_switch_icare_df_preprocessed.csv'\n",
        "icare_df_preprocessed = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_episodes.csv'\n",
        "episodes = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_disease.csv'\n",
        "disease = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_demographics.csv'\n",
        "demographics = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1711636479901
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "#path = r'switch_data/final_trimmed_snomed_embedding_128d-copy.csv'\n",
        "path = r'switch_data/snomed_embedding_128d-copy.csv'\n",
        "embedding = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_problem_dummies.csv'\n",
        "problem_dummies = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1711636488441
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Merge\n",
        "problem_dummies2 = pd.merge(problem_dummies, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "problem_dummies2 = pd.merge(icare_df_preprocessed[['SPELL_IDENTIFIER', 'date']], problem_dummies2)\n",
        "\n",
        "# Strip name \n",
        "problem_dummies2.columns = problem_dummies2.columns.str.removeprefix('PROBLEM_')\n",
        "\n",
        "# Convert the date columns to datetime objects if they are not already\n",
        "problem_dummies2['date'] = pd.to_datetime(problem_dummies2['date'])\n",
        "problem_dummies2['DT_TM'] = pd.to_datetime(problem_dummies2['DT_TM'])\n",
        "\n",
        "# Calculate the absolute time difference between 'date' and 'DT_TM'\n",
        "problem_dummies2['time_diff'] = (problem_dummies2['date'] - problem_dummies2['DT_TM']).abs()\n",
        "\n",
        "# Filter rows where 'time_diff' is not negative\n",
        "problem_dummies2 = problem_dummies2[problem_dummies2['time_diff'] >= pd.Timedelta(0)]\n",
        "\n",
        "# Sort the DataFrame by 'SPELL_IDENTIFIER' and 'time_diff'\n",
        "problem_dummies2.sort_values(by=['SPELL_IDENTIFIER', 'time_diff'], inplace=True)\n",
        "\n",
        "# Convert to str\n",
        "problem_dummies2['date'] = problem_dummies2['date'].astype(str)\n",
        "\n",
        "# Keep only the rows with the smallest time difference for each 'SPELL_IDENTIFIER'\n",
        "problem_dummies2 = problem_dummies2.groupby(['SPELL_IDENTIFIER', 'date']).first().reset_index()\n",
        "\n",
        "### REASON the problem_dummies2 is shorter is not because it is missing some dates! \n",
        "### It is because in the final data we have some dates repeated for a spesfic spell \n",
        "### if they were admited in between 6am and 12pm the 12hour prediction is done at 6am \n",
        "### of the first day, then 48 done at 6am the next day, then the next prediction done \n",
        "### at 12pm that day causing there to be two prediction for that day...phew\n",
        "### So just get a set of co-morbidities for each spell and merge \n",
        "\n",
        "# Drop the 'time_diff' column as it's no longer needed\n",
        "problem_dummies2.drop(columns=['time_diff', 'SUBJECT', 'DT_TM', 'new_subject', 'date'], inplace=True)\n",
        "\n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(inplace=True)\n",
        "\n",
        "# Some still got through by having their co-morbidid diagnosis updated during their stay \n",
        "# In this case we just use the frst one throughout and remove the others \n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(subset=['SPELL_IDENTIFIER'], keep='first', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1706203218935
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Filter for features\n",
        "X_data = icare_df_preprocessed.drop(columns=['SPELL_IDENTIFIER', 'po_flag'])\n",
        "X_data = X_data.drop(columns=columns_to_drop)\n",
        "model_data = pd.concat([icare_df_preprocessed[['SPELL_IDENTIFIER', 'po_flag']], X_data], axis=1)\n",
        "# Merge\n",
        "demographics = pd.merge(demographics, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "demographics.drop(columns=['SUBJECT'], inplace=True)\n",
        "model_data = pd.merge(model_data, demographics, how='left')\n",
        "model_data = pd.merge(model_data, disease, how='left')\n",
        "# Drop \n",
        "model_data = model_data.drop(columns=['date', 'ROUTE', '24_hour_flag', '48_hour_flag', 'iv_treatment_length'])\n",
        "# fillna\n",
        "model_data['AGE'] = model_data['AGE'].fillna(-1)\n",
        "model_data['IMDDECIL'] = model_data['IMDDECIL'].fillna(-1)\n",
        "model_data = model_data.fillna(0)\n",
        "# Merge co-morbidites\n",
        "model_data = pd.merge(model_data, problem_dummies2, how='left')\n",
        "# Rename\n",
        "model_data.rename(columns={'SPELL_IDENTIFIER': 'stay_id'}, inplace=True)\n",
        "# Random shuffle\n",
        "stays = model_data['stay_id'].unique()\n",
        "random.Random(5).shuffle(stays)\n",
        "model_data = model_data.set_index(\"stay_id\").loc[stays].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1706203219707
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "del icare_df_preprocessed\n",
        "del episodes\n",
        "del disease\n",
        "del demographics\n",
        "del problem_dummies\n",
        "del problem_dummies2\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1706203238473
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5610"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_data.stay_id.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1706213078128
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_17800/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.10it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.10it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.09it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.09it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "/tmp/ipykernel_17800/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:41<00:00,  1.21it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.14it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.12it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.12it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.15it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.14it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.13it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.12it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.15it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.12it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "/tmp/ipykernel_17800/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.12it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.88it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.12it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.09it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.10it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "/tmp/ipykernel_17800/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.10it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.10it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.84it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.86it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.10it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.00it/s]\n",
            "/tmp/ipykernel_17800/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.09it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.09it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.85it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.15it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.12it/s]\n",
            "/tmp/ipykernel_17800/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.13it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.10it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.09it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.12it/s]\n",
            "/tmp/ipykernel_17800/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.09it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.14it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.10it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.14it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.10it/s]\n",
            "/tmp/ipykernel_17800/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.12it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.21it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.09it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.22it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.12it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "/tmp/ipykernel_17800/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:41<00:00,  1.19it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.21it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.21it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.98it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.22it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.21it/s]\n",
            "100%|| 50/50 [00:37<00:00,  1.32it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:37<00:00,  1.32it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.26it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.31it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.25it/s]\n",
            "100%|| 50/50 [00:37<00:00,  1.33it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.26it/s]\n",
            "100%|| 50/50 [00:37<00:00,  1.33it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "/tmp/ipykernel_17800/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:37<00:00,  1.33it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.28it/s]\n",
            "100%|| 50/50 [00:37<00:00,  1.32it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.26it/s]\n",
            "100%|| 50/50 [00:37<00:00,  1.33it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.27it/s]\n",
            "100%|| 50/50 [00:37<00:00,  1.33it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.27it/s]\n",
            "100%|| 50/50 [00:37<00:00,  1.32it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.26it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.31it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.26it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.31it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.31it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.25it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.31it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7102476321303325\n",
            "Valid AUROC: 0.778616851152624\n",
            "[0.5        0.5        0.5        ... 0.86794424 0.5        0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.598932808637619\n",
            "Valid loss: 0.5662686228752136\n",
            "0.5620702\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7458534206320141\n",
            "Valid AUROC: 0.7878072601606165\n",
            "[0.5        0.58845484 0.831464   ... 0.80337477 0.5        0.56270546]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5758065342903137\n",
            "Valid loss: 0.5596466660499573\n",
            "0.5959925\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.752970163893215\n",
            "Valid AUROC: 0.8024226646477796\n",
            "[0.5        0.5925653  0.91250485 ... 0.86598134 0.504705   0.6156773 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5700426602363586\n",
            "Valid loss: 0.5612680230821881\n",
            "0.6250865\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7589915532832406\n",
            "Valid AUROC: 0.8043064130779892\n",
            "[0.5       0.6452573 0.871832  ... 0.707107  0.5       0.5      ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5643570399284363\n",
            "Valid loss: 0.5547951970781598\n",
            "0.6660442\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7626802078393472\n",
            "Valid AUROC: 0.803763080197433\n",
            "[0.5       0.6817009 0.5       ... 0.7641285 0.5       0.5843422]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5609034228324891\n",
            "Valid loss: 0.5513503466333661\n",
            "0.65598524\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7689596758890138\n",
            "Valid AUROC: 0.817163694030255\n",
            "[0.5        0.5        0.8803211  ... 0.62497526 0.5        0.58559775]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5542721831798554\n",
            "Valid loss: 0.5660107391221183\n",
            "0.69089735\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7749382523814939\n",
            "Valid AUROC: 0.8174034854970954\n",
            "[0.5521686  0.63835967 0.8749657  ... 0.6343879  0.5755546  0.6452592 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5493821865320205\n",
            "Valid loss: 0.554999087538038\n",
            "0.74068075\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7811227904568291\n",
            "Valid AUROC: 0.8093357838868469\n",
            "[0.5        0.67029434 0.7291733  ... 0.5884236  0.5        0.6065504 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5428238922357559\n",
            "Valid loss: 0.5465213230678013\n",
            "0.67106265\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.786049460795467\n",
            "Valid AUROC: 0.821531607056994\n",
            "[0.5        0.51316744 0.79258764 ... 0.5        0.5        0.75023586]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.539125245809555\n",
            "Valid loss: 0.5702447465487889\n",
            "0.79016715\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7893808485417978\n",
            "Valid AUROC: 0.8235230637307802\n",
            "[0.5        0.79473895 0.83219486 ... 0.5        0.5        0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.535552316904068\n",
            "Valid loss: 0.5517011966024127\n",
            "0.7373848\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.8034804064465081\n",
            "UPDATED BEST OVERALL MODEL\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7128368683467425\n",
            "Valid AUROC: 0.7943518094365553\n",
            "[0.5       0.5       0.5       ... 0.6732183 0.853048  0.8560554]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.6060090231895446\n",
            "Valid loss: 0.5635625123977661\n",
            "0.64618343\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7363679264975074\n",
            "Valid AUROC: 0.7782226294090702\n",
            "[0.5        0.76578027 0.5        ... 0.6619462  0.8924201  0.8073445 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5823247754573821\n",
            "Valid loss: 0.564713750566755\n",
            "0.5617223\n",
            "Train AUROC: 0.7433147681768555\n",
            "Valid AUROC: 0.7771348852704785\n",
            "[0.5        0.5        0.5        ... 0.6321425  0.90900135 0.81072575]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5757528579235077\n",
            "Valid loss: 0.5625667912619454\n",
            "0.5381148\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7485293471164396\n",
            "Valid AUROC: 0.7961797776204558\n",
            "[0.5        0.75015724 0.5        ... 0.5387246  0.85959154 0.81655115]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5699187505245209\n",
            "Valid loss: 0.5505787645067487\n",
            "0.6126472\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.752595430074728\n",
            "Valid AUROC: 0.7894877774538792\n",
            "[0.5        0.5        0.5        ... 0.58227104 0.8163895  0.91245466]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5666528916358948\n",
            "Valid loss: 0.555240878037044\n",
            "0.5195066\n",
            "Train AUROC: 0.7553461586511131\n",
            "Valid AUROC: 0.7991129804689128\n",
            "[0.5       0.7031171 0.5       ... 0.5       0.9067975 0.8172202]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5626952636241913\n",
            "Valid loss: 0.5482324276651654\n",
            "0.53883696\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7642709768446011\n",
            "Valid AUROC: 0.8041315120976139\n",
            "[0.5        0.7304494  0.5        ... 0.5659992  0.8814304  0.80768484]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5555823653936386\n",
            "Valid loss: 0.5423668452671596\n",
            "0.58505243\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7649266226706003\n",
            "Valid AUROC: 0.8064996043809604\n",
            "[0.5        0.72587615 0.5        ... 0.5        0.8972433  0.74687856]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5554031723737717\n",
            "Valid loss: 0.5410329444067818\n",
            "0.60238355\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7699338884463436\n",
            "Valid AUROC: 0.8029488193894974\n",
            "[0.5        0.6917095  0.5        ... 0.51064193 0.8908416  0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5512214887142182\n",
            "Valid loss: 0.543673208781651\n",
            "0.5616686\n",
            "Train AUROC: 0.7753264396967048\n",
            "Valid AUROC: 0.822266272435764\n",
            "[0.5        0.6782597  0.5        ... 0.5        0.90632296 0.82210755]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5436370182037353\n",
            "Valid loss: 0.5458559904779706\n",
            "0.7091726\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7950992935881138\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.6693408392615551\n",
            "Valid AUROC: 0.7942372881355932\n",
            "[0.51240826 0.5        0.5        ... 0.5        0.8772166  0.8664808 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.6189681088924408\n",
            "Valid loss: 0.5563890933990479\n",
            "0.57686055\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7390097589376606\n",
            "Valid AUROC: 0.7992554033232\n",
            "[0.5        0.72068787 0.5        ... 0.5        0.8616705  0.8541332 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5811461985111237\n",
            "Valid loss: 0.5520397594996861\n",
            "0.580395\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7462510476178769\n",
            "Valid AUROC: 0.7944921500853703\n",
            "[0.5        0.65787524 0.5        ... 0.5        0.8101261  0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5745512056350708\n",
            "Valid loss: 0.5530832154410226\n",
            "0.5342852\n",
            "Train AUROC: 0.7487331997979989\n",
            "Valid AUROC: 0.8063003373172865\n",
            "[0.5        0.6043453  0.5        ... 0.5        0.852927   0.74969596]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.569168918132782\n",
            "Valid loss: 0.5464488693646022\n",
            "0.5731542\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7542148088223846\n",
            "Valid AUROC: 0.8049406571440471\n",
            "[0.5       0.672905  0.5       ... 0.5       0.8815904 0.6297368]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5656807076931\n",
            "Valid loss: 0.5452412452016558\n",
            "0.5873919\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7588403635445308\n",
            "Valid AUROC: 0.8181268479573565\n",
            "[0.5       0.6550277 0.5       ... 0.5       0.9076254 0.8040656]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5615859651565551\n",
            "Valid loss: 0.5391502465520587\n",
            "0.6631702\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7633371577250974\n",
            "Valid AUROC: 0.817257110731687\n",
            "[0.5       0.5       0.5       ... 0.5       0.908522  0.8129097]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5577030837535858\n",
            "Valid loss: 0.5363485813140869\n",
            "0.643828\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7698495444807333\n",
            "Valid AUROC: 0.8192678965560323\n",
            "[0.5        0.59150463 0.5        ... 0.5        0.8794432  0.85183847]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5521527111530304\n",
            "Valid loss: 0.5342108947890145\n",
            "0.598559\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7719781056881161\n",
            "Valid AUROC: 0.820051222254612\n",
            "[0.5        0.698094   0.5        ... 0.5        0.8609403  0.87100226]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5480662059783935\n",
            "Valid loss: 0.5317278334072658\n",
            "0.6316506\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7730509268141657\n",
            "Valid AUROC: 0.8222866780493898\n",
            "[0.5       0.6843577 0.5       ... 0.5       0.8819833 0.7247415]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5442727279663085\n",
            "Valid loss: 0.5305529577391488\n",
            "0.6150371\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7792717080997729\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7143771215230487\n",
            "Valid AUROC: 0.7858961812351641\n",
            "[0.5313007  0.5        0.5        ... 0.5        0.8615899  0.83844596]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.604556280374527\n",
            "Valid loss: 0.5653895565441677\n",
            "0.56651527\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.738663977651652\n",
            "Valid AUROC: 0.776576021321784\n",
            "[0.5        0.62015736 0.5        ... 0.5        0.5        0.7652899 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5797569298744202\n",
            "Valid loss: 0.5659952333995274\n",
            "0.5300405\n",
            "Train AUROC: 0.7456527325100974\n",
            "Valid AUROC: 0.7891577478865613\n",
            "[0.5        0.62109876 0.5        ... 0.5        0.94653344 0.84593457]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5709160923957824\n",
            "Valid loss: 0.5536400250026158\n",
            "0.5597711\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7487140287912646\n",
            "Valid AUROC: 0.7993057926956233\n",
            "[0.5       0.5542775 0.5       ... 0.5       0.877838  0.736048 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5699011528491974\n",
            "Valid loss: 0.5516963686261859\n",
            "0.5522616\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7577345945904699\n",
            "Valid AUROC: 0.8085853496022987\n",
            "[0.5        0.58777195 0.5        ... 0.5        0.8606543  0.70169234]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.562557944059372\n",
            "Valid loss: 0.5465055108070374\n",
            "0.5982833\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7633480112038631\n",
            "Valid AUROC: 0.8120159913380254\n",
            "[0.5        0.55147314 0.5        ... 0.5        0.8431644  0.7465229 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5584756982326508\n",
            "Valid loss: 0.5435887149402073\n",
            "0.60083145\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7648624263294901\n",
            "Valid AUROC: 0.8135384999791779\n",
            "[0.5        0.635077   0.5        ... 0.5        0.89386755 0.8559689 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5540144789218903\n",
            "Valid loss: 0.5406657712800162\n",
            "0.6231055\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7688808080207248\n",
            "Valid AUROC: 0.8160875359180444\n",
            "[0.5        0.5        0.5        ... 0.5        0.82590127 0.82219756]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5511613696813583\n",
            "Valid loss: 0.5468336173466274\n",
            "0.7034452\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7701920378202652\n",
            "Valid AUROC: 0.8190147003706325\n",
            "[0.5        0.57724655 0.5        ... 0.5        0.92810947 0.7807771 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.547626467347145\n",
            "Valid loss: 0.539441066128867\n",
            "0.6876261\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7766477449361912\n",
            "Valid AUROC: 0.8227660017490526\n",
            "[0.5        0.61201966 0.5        ... 0.5        0.8975566  0.7458855 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.541917712688446\n",
            "Valid loss: 0.5476494857243129\n",
            "0.7856564\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7945418741794995\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7180513968981534\n",
            "Valid AUROC: 0.760042893432724\n",
            "[0.5       0.5       0.5       ... 0.5       0.9231542 0.6126231]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5995261967182159\n",
            "Valid loss: 0.5744533623967852\n",
            "0.50257665\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7396921560267234\n",
            "Valid AUROC: 0.768396285345438\n",
            "[0.67300314 0.82274187 0.919545   ... 0.5        0.9584543  0.76083356]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5764963328838348\n",
            "Valid loss: 0.5706283535276141\n",
            "0.60733753\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7483487409521496\n",
            "Valid AUROC: 0.7721523757964435\n",
            "[0.6780259  0.7973859  0.919588   ... 0.5        0.92773217 0.66339695]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5698540389537812\n",
            "Valid loss: 0.5675906964710781\n",
            "0.5510102\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7511297431984677\n",
            "Valid AUROC: 0.7803169116728439\n",
            "[0.7091162  0.7096933  0.97424877 ... 0.5        0.9725457  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5659326815605163\n",
            "Valid loss: 0.5664581911904472\n",
            "0.63808465\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7577146832742467\n",
            "Valid AUROC: 0.787435139299546\n",
            "[0.63935447 0.7956134  0.5        ... 0.5        0.9663975  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.561767578125\n",
            "Valid loss: 0.5643385393278939\n",
            "0.6595526\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7602956912437093\n",
            "Valid AUROC: 0.7845333777537168\n",
            "[0.749715   0.8168521  0.96580005 ... 0.5        0.9726096  0.5199056 ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5578957414627075\n",
            "Valid loss: 0.5597183789525714\n",
            "0.6460059\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7653857023413358\n",
            "Valid AUROC: 0.7813609294965228\n",
            "[0.696762  0.7010083 0.9508952 ... 0.5       0.5       0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5533936774730682\n",
            "Valid loss: 0.5583557741982597\n",
            "0.6175166\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7709435951550424\n",
            "Valid AUROC: 0.7894715362511973\n",
            "[0.589461   0.6551861  0.98372215 ... 0.5        0.96891093 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5481167626380921\n",
            "Valid loss: 0.5567501527922494\n",
            "0.6381152\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7745760372328642\n",
            "Valid AUROC: 0.7852346645566984\n",
            "[0.7087678  0.74462914 0.9861666  ... 0.5        0.99102306 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.544620469212532\n",
            "Valid loss: 0.5556078638349261\n",
            "0.5116205\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7793573077963456\n",
            "Valid AUROC: 0.8119172947986508\n",
            "[0.5        0.5        0.9712114  ... 0.5        0.99041957 0.51194036]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5393104380369187\n",
            "Valid loss: 0.5674829993929181\n",
            "0.7205916\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.780609141159049\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.6492853019784012\n",
            "Valid AUROC: 0.7678863532253363\n",
            "[0.5        0.5        0.5        ... 0.5        0.94932383 0.5257747 ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6290356373786926\n",
            "Valid loss: 0.5768625395638602\n",
            "0.6090278\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7387641764618004\n",
            "Valid AUROC: 0.7713680089951277\n",
            "[0.5        0.81760216 0.9262055  ... 0.5        0.8902597  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5797240030765534\n",
            "Valid loss: 0.5691051312855312\n",
            "0.6267627\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7445304887503585\n",
            "Valid AUROC: 0.7777961937283971\n",
            "[0.5        0.7697545  0.9580618  ... 0.5        0.96577823 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5721189785003662\n",
            "Valid loss: 0.5666944129126412\n",
            "0.6585237\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.749266504801728\n",
            "Valid AUROC: 0.7820251530421022\n",
            "[0.5        0.735236   0.9236679  ... 0.5        0.93455607 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5677148044109345\n",
            "Valid loss: 0.5660834312438965\n",
            "0.6377439\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7547480694886111\n",
            "Valid AUROC: 0.7841454628742764\n",
            "[0.5       0.7823435 0.9758327 ... 0.5       0.9871292 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5632910072803498\n",
            "Valid loss: 0.5632550375802177\n",
            "0.6673193\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7567220985879037\n",
            "Valid AUROC: 0.7873924540873694\n",
            "[0.5        0.8540077  0.9802797  ... 0.5        0.97882915 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5597932732105255\n",
            "Valid loss: 0.5604345883641925\n",
            "0.6442465\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.762785194010205\n",
            "Valid AUROC: 0.7911722816807563\n",
            "[0.5        0.5        0.5        ... 0.5        0.95160216 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5542418086528778\n",
            "Valid loss: 0.5617444770676749\n",
            "0.65164936\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7655585360977577\n",
            "Valid AUROC: 0.7897189022612751\n",
            "[0.5       0.8750989 0.9885083 ... 0.5       0.9819972 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5515223926305771\n",
            "Valid loss: 0.5566642369542804\n",
            "0.62544835\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7704320899253808\n",
            "Valid AUROC: 0.8000420605505352\n",
            "[0.5       0.8072707 0.9806113 ... 0.5       0.9889685 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5471962082386017\n",
            "Valid loss: 0.5588728700365339\n",
            "0.67749584\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7736563396245494\n",
            "Valid AUROC: 0.8034547953192023\n",
            "[0.5       0.8478004 0.9788947 ... 0.5       0.9835813 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.54286277115345\n",
            "Valid loss: 0.5650384511266436\n",
            "0.7235037\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.790367258027285\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.6928662468239885\n",
            "Valid AUROC: 0.7695941781535002\n",
            "[0.5       0.5       0.5       ... 0.5       0.9504503 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6103882372379303\n",
            "Valid loss: 0.5765124900000436\n",
            "0.679788\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7382272133309291\n",
            "Valid AUROC: 0.7606987881564152\n",
            "[0.5       0.6484602 0.9454602 ... 0.5       0.9749961 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5791207230091096\n",
            "Valid loss: 0.5721842306000846\n",
            "0.6382629\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7465265021472046\n",
            "Valid AUROC: 0.7803722983384\n",
            "[0.5        0.77034503 0.9554333  ... 0.5        0.9683335  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5715723311901093\n",
            "Valid loss: 0.5735095313617161\n",
            "0.650086\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7514022599389095\n",
            "Valid AUROC: 0.7814862782659392\n",
            "[0.5        0.8757601  0.96557784 ... 0.5        0.957562   0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5683250951766968\n",
            "Valid loss: 0.5657630137034825\n",
            "0.5951837\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7577490384189354\n",
            "Valid AUROC: 0.7889967934035731\n",
            "[0.5        0.82682717 0.9016928  ... 0.5        0.5        0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5626566326618194\n",
            "Valid loss: 0.5688970599855695\n",
            "0.65809786\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7609459290130189\n",
            "Valid AUROC: 0.7865485362095531\n",
            "[0.5        0.7626331  0.9667391  ... 0.5        0.98646855 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5589034569263458\n",
            "Valid loss: 0.5627228702817645\n",
            "0.6338976\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7681935297930205\n",
            "Valid AUROC: 0.7901499187939867\n",
            "[0.5        0.86670077 0.9877159  ... 0.5        0.9807741  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5541158628463745\n",
            "Valid loss: 0.5623808928898403\n",
            "0.6657958\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7731934941454477\n",
            "Valid AUROC: 0.7964406779661017\n",
            "[0.5        0.8264758  0.97493374 ... 0.5        0.9923535  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5494397085905075\n",
            "Valid loss: 0.5636559639658246\n",
            "0.6824634\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7725554970038297\n",
            "Valid AUROC: 0.7953331528755259\n",
            "[0.5       0.8339366 0.5       ... 0.5       0.9808811 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5464319336414337\n",
            "Valid loss: 0.5684480496815273\n",
            "0.68367\n",
            "Train AUROC: 0.7793134075664464\n",
            "Valid AUROC: 0.797733727564236\n",
            "[0.5        0.5        0.9954527  ... 0.5        0.99757785 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5411327999830245\n",
            "Valid loss: 0.5608621154512677\n",
            "0.6580127\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7967705860245117\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7119531259486691\n",
            "Valid AUROC: 0.7709852996293675\n",
            "[0.50166196 0.5        0.5        ... 0.5        0.8721577  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6063509225845337\n",
            "Valid loss: 0.570337576525552\n",
            "0.5713679\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7432924925007436\n",
            "Valid AUROC: 0.7763840419772623\n",
            "[0.5        0.7743652  0.8864049  ... 0.5        0.94294196 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5760660743713379\n",
            "Valid loss: 0.5713128021785191\n",
            "0.63308215\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7480622353879869\n",
            "Valid AUROC: 0.7742485320451423\n",
            "[0.5        0.72191006 0.9144408  ... 0.5        0.9547151  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5709785699844361\n",
            "Valid loss: 0.5647846204893929\n",
            "0.5628439\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7546631533894868\n",
            "Valid AUROC: 0.7835268396285346\n",
            "[0.5       0.8335452 0.9455669 ... 0.5       0.9626375 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5644343149662018\n",
            "Valid loss: 0.565489683832441\n",
            "0.65350366\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7606574701572033\n",
            "Valid AUROC: 0.7885915962187149\n",
            "[0.5       0.7827004 0.5       ... 0.5       0.9703456 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5593073964118958\n",
            "Valid loss: 0.5668639455522809\n",
            "0.6417116\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.759607487995639\n",
            "Valid AUROC: 0.7937421396743429\n",
            "[0.5       0.5       0.9874721 ... 0.5       0.9827979 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5575839287042618\n",
            "Valid loss: 0.5681647743497577\n",
            "0.6576403\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7646494936954092\n",
            "Valid AUROC: 0.7967503019197933\n",
            "[0.5        0.8710183  0.98329514 ... 0.5        0.5        0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5529444909095764\n",
            "Valid loss: 0.5680697475160871\n",
            "0.6902461\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7708953781505902\n",
            "Valid AUROC: 0.7956373630949902\n",
            "[0.5        0.910012   0.968937   ... 0.5        0.99529606 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5471772861480713\n",
            "Valid loss: 0.5643286875316075\n",
            "0.6564387\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7740586656172715\n",
            "Valid AUROC: 0.797788906009245\n",
            "[0.5        0.7979804  0.9967458  ... 0.5        0.98418695 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5435577690601349\n",
            "Valid loss: 0.563375745500837\n",
            "0.6689893\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7772146738170597\n",
            "Valid AUROC: 0.8057335609877981\n",
            "[0.5        0.7416675  0.98737085 ... 0.5        0.9804347  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5403964257240296\n",
            "Valid loss: 0.5765339732170105\n",
            "0.7360045\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.776434769637692\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.720134891717161\n",
            "Valid AUROC: 0.777348103110815\n",
            "[0.5        0.5        0.5        ... 0.5        0.94621813 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5993203234672546\n",
            "Valid loss: 0.5736896055085319\n",
            "0.6748119\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7465188484994112\n",
            "Valid AUROC: 0.7673689251655353\n",
            "[0.5       0.9038155 0.9333646 ... 0.5       0.9682183 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5745779573917389\n",
            "Valid loss: 0.5685941747256688\n",
            "0.5972432\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7501230199360432\n",
            "Valid AUROC: 0.7789122558614084\n",
            "[0.5        0.5        0.89060986 ... 0.5        0.95473564 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5705423867702484\n",
            "Valid loss: 0.5665239947182792\n",
            "0.67789155\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7607195913427379\n",
            "Valid AUROC: 0.7733923291550411\n",
            "[0.5       0.5       0.5       ... 0.5       0.9574324 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5633273327350616\n",
            "Valid loss: 0.5638940164021083\n",
            "0.60516006\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7613031437350172\n",
            "Valid AUROC: 0.7908395452463248\n",
            "[0.5        0.81483465 0.9594826  ... 0.5        0.99205947 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5607051110267639\n",
            "Valid loss: 0.566388726234436\n",
            "0.7256616\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7667161869507162\n",
            "Valid AUROC: 0.7893345271311373\n",
            "[0.5       0.8434053 0.9841876 ... 0.5       0.5       0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5553553295135498\n",
            "Valid loss: 0.5618149212428502\n",
            "0.6516689\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7726696148131651\n",
            "Valid AUROC: 0.7963215758131014\n",
            "[0.5        0.8375654  0.98612946 ... 0.5        0.99473697 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5499179917573929\n",
            "Valid loss: 0.5650310175759452\n",
            "0.67288494\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7742770761789279\n",
            "Valid AUROC: 0.7956175821430058\n",
            "[0.5       0.9106801 0.9886497 ... 0.5       0.9947443 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5470740777254105\n",
            "Valid loss: 0.5595673322677612\n",
            "0.67606336\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7804727708050874\n",
            "Valid AUROC: 0.7939299546079208\n",
            "[0.5       0.5       0.9899144 ... 0.5       0.5       0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5429439300298691\n",
            "Valid loss: 0.5526057226317269\n",
            "0.61934507\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7824433458336403\n",
            "Valid AUROC: 0.8081774455503269\n",
            "[0.5        0.8428458  0.9955082  ... 0.5        0.99486476 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5393404108285904\n",
            "Valid loss: 0.5583691767283848\n",
            "0.6969982\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7814351821373482\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7202814634673096\n",
            "Valid AUROC: 0.7723362345396245\n",
            "[0.5       0.5       0.5       ... 0.5       0.9761297 0.5050334]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5990045464038849\n",
            "Valid loss: 0.5695606895855495\n",
            "0.5618368\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7425616521513767\n",
            "Valid AUROC: 0.7890530129513179\n",
            "[0.5       0.5       0.9304949 ... 0.5       0.929972  0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5768613600730896\n",
            "Valid loss: 0.5676920328821454\n",
            "0.6490469\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.748001299199388\n",
            "Valid AUROC: 0.7892345812684797\n",
            "[0.5        0.6319441  0.95334893 ... 0.5        0.97404927 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5720210003852845\n",
            "Valid loss: 0.5605789848736354\n",
            "0.6233338\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7547835705644026\n",
            "Valid AUROC: 0.8002885936784241\n",
            "[0.5        0.57407576 0.9813887  ... 0.5        0.96858674 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5653847879171372\n",
            "Valid loss: 0.5606262939316886\n",
            "0.67069286\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7604426959735073\n",
            "Valid AUROC: 0.8033319451963519\n",
            "[0.5       0.5       0.9839221 ... 0.5       0.9893243 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5610308158397674\n",
            "Valid loss: 0.5576965979167393\n",
            "0.7084289\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7642898438698172\n",
            "Valid AUROC: 0.7772194228126431\n",
            "[0.5        0.5        0.9789907  ... 0.5        0.97882336 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5563774937391281\n",
            "Valid loss: 0.5559352125440326\n",
            "0.5473036\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7701353133026094\n",
            "Valid AUROC: 0.8033490192812228\n",
            "[0.5       0.5       0.5       ... 0.5       0.9866019 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5516106748580932\n",
            "Valid loss: 0.5516830512455532\n",
            "0.6587193\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7750704251166742\n",
            "Valid AUROC: 0.8053614708699455\n",
            "[0.5       0.5882208 0.9891055 ... 0.5       0.9924223 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5472146052122117\n",
            "Valid loss: 0.5488069653511047\n",
            "0.6736379\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7779113803947921\n",
            "Valid AUROC: 0.80817348935993\n",
            "[0.5       0.6307447 0.9808601 ... 0.5       0.9922024 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.543291152715683\n",
            "Valid loss: 0.5464836614472526\n",
            "0.66748965\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7812358274447829\n",
            "Valid AUROC: 0.8156448590346894\n",
            "[0.5        0.6884184  0.99474204 ... 0.5        0.9965917  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5408435267210007\n",
            "Valid loss: 0.5523586613791329\n",
            "0.7027667\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7892943422547147\n"
          ]
        }
      ],
      "source": [
        "# Run model\n",
        "test_results, actual_test_auroc_results, final_threshold = cv_run_fun(model_data, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1706213078400
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save \n",
        "with open(\"chronic_switch_test_results2\", \"wb\") as fp:   #Pickling\n",
        "    pickle.dump(test_results, fp)\n",
        "with open(\"chronic_switch_actual_test_auroc_results2\", \"wb\") as fp:   #Pickling\n",
        "    pickle.dump(actual_test_auroc_results, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1706213078693
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test_auroc: 0.7887304561554493\n",
            "std test_auroc: 0.00848153925586805\n",
            "test_auroc 2.5th percentile: 0.7770730807916602\n",
            "test_auroc 97.5th percentile: 0.8019706968515589\n",
            "mean test_accuracy: 0.714149111979744\n",
            "std test_accuracy: 0.010261895210975614\n",
            "test_accuracy 2.5th percentile: 0.7007785192246584\n",
            "test_accuracy 97.5th percentile: 0.7272835174299236\n",
            "mean test_balanced_accuracy: 0.7250045101475263\n",
            "std test_balanced_accuracy: 0.007651250956321561\n",
            "test_balanced_accuracy 2.5th percentile: 0.7149176229853141\n",
            "test_balanced_accuracy 97.5th percentile: 0.7377945644166918\n",
            "mean test_recall: 0.6630789469837604\n",
            "std test_recall: 0.03288060821998765\n",
            "test_recall 2.5th percentile: 0.6089282446318681\n",
            "test_recall 97.5th percentile: 0.7121939470568459\n",
            "mean test_precision: 0.8168230014441862\n",
            "std test_precision: 0.014807882763269083\n",
            "test_precision 2.5th percentile: 0.7963875853432116\n",
            "test_precision 97.5th percentile: 0.8411588528002462\n",
            "mean test_f1: 0.7312154925229343\n",
            "std test_f1: 0.01619931452783098\n",
            "test_f1 2.5th percentile: 0.7052526462172513\n",
            "test_f1 97.5th percentile: 0.7520912644194732\n",
            "mean test_auprc: 0.8418513364693387\n",
            "std test_auprc: 0.007871961401071208\n",
            "test_auprc 2.5th percentile: 0.8314308273192318\n",
            "test_auprc 97.5th percentile: 0.8560504686525662\n",
            "mean test_tpr: 0.6630789469837604\n",
            "std test_tpr: 0.03288060821998765\n",
            "test_tpr 2.5th percentile: 0.6089282446318681\n",
            "test_tpr 97.5th percentile: 0.7121939470568459\n",
            "mean test_fpr: 0.213069926688708\n",
            "std test_fpr: 0.029479492666519037\n",
            "test_fpr 2.5th percentile: 0.1651184046864104\n",
            "test_fpr 97.5th percentile: 0.2597303187514627\n"
          ]
        }
      ],
      "source": [
        "analyze_results_fun(test_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1706213079321
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7373848"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1706213078970
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.8034804064465081,\n",
              "  0.7950992935881138,\n",
              "  0.7792717080997729,\n",
              "  0.7945418741794995,\n",
              "  0.780609141159049,\n",
              "  0.790367258027285,\n",
              "  0.7967705860245117,\n",
              "  0.776434769637692,\n",
              "  0.7814351821373482,\n",
              "  0.7892943422547147],\n",
              " [0.727445997458704,\n",
              "  0.7222751827136956,\n",
              "  0.722910708611376,\n",
              "  0.7003495392437242,\n",
              "  0.7028916428344455,\n",
              "  0.7159199237368923,\n",
              "  0.7267238639974579,\n",
              "  0.703844931680966,\n",
              "  0.7022561169367652,\n",
              "  0.7168732125834127],\n",
              " [0.7397184858201807,\n",
              "  0.7303657088082686,\n",
              "  0.7247988080601805,\n",
              "  0.721281543687095,\n",
              "  0.7178887767593527,\n",
              "  0.73081251598957,\n",
              "  0.7311677240268967,\n",
              "  0.7149119042400798,\n",
              "  0.7149373208855659,\n",
              "  0.7241623131980723],\n",
              " [0.6697297297297298,\n",
              "  0.6843243243243243,\n",
              "  0.7140540540540541,\n",
              "  0.6021621621621621,\n",
              "  0.6322336398053001,\n",
              "  0.6457544618712818,\n",
              "  0.7057869118442401,\n",
              "  0.6517036235803136,\n",
              "  0.6425094645754462,\n",
              "  0.6825310978907517],\n",
              " [0.8337819650067295,\n",
              "  0.8136246786632391,\n",
              "  0.7938701923076923,\n",
              "  0.8433005299015897,\n",
              "  0.8209269662921348,\n",
              "  0.8332170272156315,\n",
              "  0.8050586057988895,\n",
              "  0.8070997990622907,\n",
              "  0.8114754098360656,\n",
              "  0.8058748403575989],\n",
              " [0.7428057553956836,\n",
              "  0.7433940105695831,\n",
              "  0.7518497438816164,\n",
              "  0.7026174708293914,\n",
              "  0.7143293614421019,\n",
              "  0.7276051188299819,\n",
              "  0.7521613832853026,\n",
              "  0.7211250748055057,\n",
              "  0.7171747660730456,\n",
              "  0.7390922401171303],\n",
              " [0.8580802386097641,\n",
              "  0.8448571398861945,\n",
              "  0.8334101901042076,\n",
              "  0.8461606105864523,\n",
              "  0.8377245966705358,\n",
              "  0.8404034324841184,\n",
              "  0.8490590387999957,\n",
              "  0.8308561736074647,\n",
              "  0.8340315337463294,\n",
              "  0.8439304101983237],\n",
              " [array([[1051,  247],\n",
              "         [ 611, 1239]]),\n",
              "  array([[1007,  290],\n",
              "         [ 584, 1266]]),\n",
              "  array([[ 954,  343],\n",
              "         [ 529, 1321]]),\n",
              "  array([[1090,  207],\n",
              "         [ 736, 1114]]),\n",
              "  array([[1043,  255],\n",
              "         [ 680, 1169]]),\n",
              "  array([[1059,  239],\n",
              "         [ 655, 1194]]),\n",
              "  array([[ 982,  316],\n",
              "         [ 544, 1305]]),\n",
              "  array([[1010,  288],\n",
              "         [ 644, 1205]]),\n",
              "  array([[1022,  276],\n",
              "         [ 661, 1188]]),\n",
              "  array([[ 994,  304],\n",
              "         [ 587, 1262]])],\n",
              " [0.6697297297297298,\n",
              "  0.6843243243243243,\n",
              "  0.7140540540540541,\n",
              "  0.6021621621621621,\n",
              "  0.6322336398053001,\n",
              "  0.6457544618712818,\n",
              "  0.7057869118442401,\n",
              "  0.6517036235803136,\n",
              "  0.6425094645754462,\n",
              "  0.6825310978907517],\n",
              " [0.19029275808936827,\n",
              "  0.2235929067077872,\n",
              "  0.2644564379336931,\n",
              "  0.15959907478797225,\n",
              "  0.19645608628659475,\n",
              "  0.18412942989214176,\n",
              "  0.24345146379044685,\n",
              "  0.2218798151001541,\n",
              "  0.21263482280431434,\n",
              "  0.23420647149460708]]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Treatment day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1710770642450
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 1,126,583 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "# Load model\n",
        "\n",
        "# Hyperparameters\n",
        "final_input_dim = 268\n",
        "final_output_dim = 1\n",
        "final_hid_dim = 512\n",
        "final_hid_dim2 = 128\n",
        "demographics_input_dim = 12\n",
        "demographics_output_dim = 12\n",
        "vital_input_dim = 253\n",
        "vital_hid_dim = 512\n",
        "vital_output_dim = 128\n",
        "dropout = 0.1\n",
        "\n",
        "# Define model\n",
        "model = Chronic_switch_model(\n",
        "    final_input_dim, \n",
        "    final_output_dim, \n",
        "    final_hid_dim, \n",
        "    final_hid_dim2,\n",
        "    demographics_input_dim,\n",
        "    demographics_output_dim,\n",
        "    vital_input_dim, \n",
        "    vital_hid_dim, \n",
        "    vital_output_dim, \n",
        "    dropout).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load('chronic_switch_model.pt'))\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1710770769541
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/chronic_switch_icare_df_preprocessed.csv'\n",
        "icare_df_preprocessed = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_episodes.csv'\n",
        "episodes = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_disease.csv'\n",
        "disease = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_demographics.csv'\n",
        "demographics = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/snomed_embedding_128d-copy.csv'\n",
        "embedding = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_problem_dummies.csv'\n",
        "problem_dummies = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1710770787924
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Merge\n",
        "problem_dummies2 = pd.merge(problem_dummies, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "problem_dummies2 = pd.merge(icare_df_preprocessed[['SPELL_IDENTIFIER', 'date']], problem_dummies2)\n",
        "\n",
        "# Strip name \n",
        "problem_dummies2.columns = problem_dummies2.columns.str.removeprefix('PROBLEM_')\n",
        "\n",
        "# Convert the date columns to datetime objects if they are not already\n",
        "problem_dummies2['date'] = pd.to_datetime(problem_dummies2['date'])\n",
        "problem_dummies2['DT_TM'] = pd.to_datetime(problem_dummies2['DT_TM'])\n",
        "\n",
        "# Calculate the absolute time difference between 'date' and 'DT_TM'\n",
        "problem_dummies2['time_diff'] = (problem_dummies2['date'] - problem_dummies2['DT_TM']).abs()\n",
        "\n",
        "# Filter rows where 'time_diff' is not negative\n",
        "problem_dummies2 = problem_dummies2[problem_dummies2['time_diff'] >= pd.Timedelta(0)]\n",
        "\n",
        "# Sort the DataFrame by 'SPELL_IDENTIFIER' and 'time_diff'\n",
        "problem_dummies2.sort_values(by=['SPELL_IDENTIFIER', 'time_diff'], inplace=True)\n",
        "\n",
        "# Convert to str\n",
        "problem_dummies2['date'] = problem_dummies2['date'].astype(str)\n",
        "\n",
        "# Keep only the rows with the smallest time difference for each 'SPELL_IDENTIFIER'\n",
        "problem_dummies2 = problem_dummies2.groupby(['SPELL_IDENTIFIER', 'date']).first().reset_index()\n",
        "\n",
        "### REASON the problem_dummies2 is shorter is not because it is missing some dates! \n",
        "### It is because in the final data we have some dates repeated for a spesfic spell \n",
        "### if they were admited in between 6am and 12pm the 12hour prediction is done at 6am \n",
        "### of the first day, then 48 done at 6am the next day, then the next prediction done \n",
        "### at 12pm that day causing there to be two prediction for that day...phew\n",
        "### So just get a set of co-morbidities for each spell and merge \n",
        "\n",
        "# Drop the 'time_diff' column as it's no longer needed\n",
        "problem_dummies2.drop(columns=['time_diff', 'SUBJECT', 'DT_TM', 'new_subject', 'date'], inplace=True)\n",
        "\n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(inplace=True)\n",
        "\n",
        "# Some still got through by having their co-morbidid diagnosis updated during their stay \n",
        "# In this case we just use the frst one throughout and remove the others \n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(subset=['SPELL_IDENTIFIER'], keep='first', inplace=True)\n",
        "\n",
        "# Filter for features\n",
        "X_data = icare_df_preprocessed.drop(columns=['SPELL_IDENTIFIER', 'po_flag'])\n",
        "X_data = X_data.drop(columns=columns_to_drop)\n",
        "model_data = pd.concat([icare_df_preprocessed[['SPELL_IDENTIFIER', 'po_flag']], X_data], axis=1)\n",
        "# Merge\n",
        "demographics = pd.merge(demographics, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "demographics.drop(columns=['SUBJECT'], inplace=True)\n",
        "model_data = pd.merge(model_data, demographics, how='left')\n",
        "model_data = pd.merge(model_data, disease, how='left')\n",
        "# Drop \n",
        "model_data = model_data.drop(columns=['date', 'ROUTE', '24_hour_flag', '48_hour_flag', 'iv_treatment_length'])\n",
        "# fillna\n",
        "model_data['AGE'] = model_data['AGE'].fillna(-1)\n",
        "model_data['IMDDECIL'] = model_data['IMDDECIL'].fillna(-1)\n",
        "model_data = model_data.fillna(0)\n",
        "# Merge co-morbidites\n",
        "model_data = pd.merge(model_data, problem_dummies2, how='left')\n",
        "# Rename\n",
        "model_data.rename(columns={'SPELL_IDENTIFIER': 'stay_id'}, inplace=True)\n",
        "# Random shuffle\n",
        "stays = model_data['stay_id'].unique()\n",
        "random.Random(5).shuffle(stays)\n",
        "model_data = model_data.set_index(\"stay_id\").loc[stays].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1710771532232
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define batch size \n",
        "batch_size = 512\n",
        "\n",
        "# Define optimizer and learning_rate\n",
        "learning_rate = 0.0001\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Define loss\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Define epochs and clip\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "# Split into folds\n",
        "split_generator = cv_data_fun(model_data)\n",
        "\n",
        "# Iterate through folds\n",
        "for x in range(N_EPOCHS):\n",
        "    train_idx, val_idx, test_idx = next(split_generator)\n",
        "    if x == 0: # Change to best cv split \n",
        "\n",
        "        # Get train val and test\n",
        "        train_data = model_data.loc[train_idx]\n",
        "        valid_data = model_data.loc[val_idx]\n",
        "        test_data = model_data.loc[test_idx]\n",
        "\n",
        "        # Get iv_treatment_length\n",
        "        icare_df_preprocessed_2 = icare_df_preprocessed.rename(columns={'SPELL_IDENTIFIER':'stay_id'})\n",
        "        icare_df_preprocessed_2 = icare_df_preprocessed_2.drop(columns=columns_to_drop)\n",
        "        icare_df_preprocessed_2 = icare_df_preprocessed_2.drop(columns=['date', 'ROUTE', '24_hour_flag', '48_hour_flag'])\n",
        "\n",
        "        # Merge \n",
        "        test_data = pd.merge(test_data, icare_df_preprocessed_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1710772002090
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def final_threshold_fun(predictions, bound=0.7373848): # Set to threshold for 2nd model\n",
        "    new_predictions = [1 if a_ >= bound else 0 for a_ in predictions]\n",
        "    return new_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1710772483350
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "999\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "0\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "2\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "3\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "4\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "5\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "6\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "7\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "8\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 2/2 [00:02<00:00,  1.21s/it]\n",
            "100%|| 3/3 [00:01<00:00,  1.73it/s]\n",
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/tmp/ipykernel_4087/4279474204.py:60: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  test_false_positive_rate = (fp / (fp + tn))\n",
            "100%|| 1/1 [00:00<00:00,  4.43it/s]\n",
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n",
            "100%|| 1/1 [00:00<00:00,  1.73it/s]\n",
            "100%|| 1/1 [00:00<00:00,  3.29it/s]\n",
            "100%|| 1/1 [00:00<00:00,  4.87it/s]\n",
            "100%|| 1/1 [00:00<00:00,  7.98it/s]\n",
            "100%|| 1/1 [00:00<00:00, 13.79it/s]\n",
            "100%|| 1/1 [00:00<00:00, 21.77it/s]\n",
            "100%|| 1/1 [00:00<00:00, 52.03it/s]\n"
          ]
        }
      ],
      "source": [
        "treatment_length_df = pd.DataFrame()\n",
        "\n",
        "for i in test_data.iv_treatment_length.unique():\n",
        "    print(i)\n",
        "    # Filter for iv_treatment_length\n",
        "    temp_test_data = test_data[test_data['iv_treatment_length'] == i]\n",
        "    temp_test_data = temp_test_data.drop(columns=['iv_treatment_length'])\n",
        "    \n",
        "    # Split up dfs\n",
        "    vitals_test_data = temp_test_data.iloc[:,2:255]\n",
        "    demographics_test_data = temp_test_data.iloc[:,255:267]\n",
        "    comorbidity_test_data = temp_test_data.iloc[:, 267:]\n",
        "\n",
        "    # Get labels\n",
        "    test_labels = temp_test_data[['po_flag']]\n",
        "\n",
        "    # Preprocess comorbidity data\n",
        "    print('Working on set_transformer_processing_fun...')\n",
        "    comorbidity_test_data, comorbidity_test_mask = set_transformer_processing_fun(comorbidity_test_data, embedding)\n",
        "    print('Done!')\n",
        "\n",
        "    test_dataset = MultiInputDataset([vitals_test_data, demographics_test_data], test_labels, comorbidity_test_data, comorbidity_test_mask)\n",
        "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "    test_loss, test_auroc, test_predictions, test_labels_out = evaluate(model, test_dataloader, criterion)\n",
        "\n",
        "    new_test_predictions = final_threshold_fun(test_predictions)\n",
        "\n",
        "    label_values, label_counts = np.unique(test_labels, return_counts=True)\n",
        "    prediction_values, prediction_counts = np.unique(new_test_predictions, return_counts=True)\n",
        "\n",
        "    label_0 = 0\n",
        "    label_1 = 0\n",
        "    for x in range(len(label_values)):\n",
        "        if label_values[x] == 0:\n",
        "            label_0 = label_counts[x]\n",
        "        elif label_values[x] == 1:\n",
        "            label_1 = label_counts[x]\n",
        "    prediction_0 = 0\n",
        "    prediction_1 = 0\n",
        "    for x in range(len(prediction_values)):\n",
        "        if prediction_values[x] == 0:\n",
        "            prediction_0 = prediction_counts[x]\n",
        "        elif prediction_values[x] == 1:\n",
        "            prediction_1 = prediction_counts[x]\n",
        "\n",
        "    # Lower bound\n",
        "    test_accuracy2 = accuracy_score(test_labels, new_test_predictions)\n",
        "    test_balanced_accuracy = balanced_accuracy_score(test_labels, new_test_predictions)\n",
        "    test_recall = recall_score(test_labels, new_test_predictions)\n",
        "    test_precision = precision_score(test_labels, new_test_predictions)\n",
        "    test_f1 = f1_score(test_labels, new_test_predictions)\n",
        "    test_auprc = average_precision_score(test_labels, new_test_predictions)\n",
        "    test_cm = confusion_matrix(test_labels, new_test_predictions)\n",
        "    if test_cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = test_cm.ravel()\n",
        "        test_true_positive_rate = (tp / (tp + fn))\n",
        "        test_false_positive_rate = (fp / (fp + tn))\n",
        "    else:\n",
        "        test_true_positive_rate = np.nan\n",
        "        test_false_positive_rate = np.nan\n",
        "\n",
        "    \n",
        "    sub_df = pd.DataFrame([[i, label_0, label_1, prediction_0, prediction_1, test_auroc, test_balanced_accuracy, test_accuracy2, test_recall, test_precision, test_f1, test_auprc, test_cm, test_true_positive_rate, test_false_positive_rate]])\n",
        "    treatment_length_df = pd.concat([treatment_length_df, sub_df], axis=0, ignore_index=True)\n",
        "treatment_length_df.columns = ['iv_treatment_length', 'label_0', 'label_1', 'prediction_0', 'prediction_1', 'auroc', 'balanced_accuracy', 'accuracy', 'recall', 'precision', 'f1', 'auprc', 'cm', 'tpr', 'fpr']\n",
        "treatment_length_df.sort_values(by=['iv_treatment_length'], inplace=True)\n",
        "# Set to string\n",
        "treatment_length_df['iv_treatment_length']= treatment_length_df['iv_treatment_length'].astype(str)\n",
        "# Change 999\n",
        "treatment_length_df['iv_treatment_length'] = treatment_length_df['iv_treatment_length'].replace(['999'], 'PO')\n",
        "# Rename\n",
        "treatment_length_df.rename(columns={'iv_treatment_length': 'Proir days cumulative IV treatment length', 'label_0': 'Continue with IV', 'label_1': 'Switch to PO'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1710772491391
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Proir days cumulative IV treatment length</th>\n",
              "      <th>Continue with IV</th>\n",
              "      <th>Switch to PO</th>\n",
              "      <th>prediction_0</th>\n",
              "      <th>prediction_1</th>\n",
              "      <th>auroc</th>\n",
              "      <th>balanced_accuracy</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>f1</th>\n",
              "      <th>auprc</th>\n",
              "      <th>cm</th>\n",
              "      <th>tpr</th>\n",
              "      <th>fpr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>192</td>\n",
              "      <td>0</td>\n",
              "      <td>192</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>[[192]]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>384</td>\n",
              "      <td>181</td>\n",
              "      <td>545</td>\n",
              "      <td>20</td>\n",
              "      <td>0.500705</td>\n",
              "      <td>0.502410</td>\n",
              "      <td>0.669027</td>\n",
              "      <td>0.038674</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.069652</td>\n",
              "      <td>0.321501</td>\n",
              "      <td>[[371, 13], [174, 7]]</td>\n",
              "      <td>0.038674</td>\n",
              "      <td>0.033854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>337</td>\n",
              "      <td>150</td>\n",
              "      <td>395</td>\n",
              "      <td>92</td>\n",
              "      <td>0.650049</td>\n",
              "      <td>0.599535</td>\n",
              "      <td>0.704312</td>\n",
              "      <td>0.326667</td>\n",
              "      <td>0.532609</td>\n",
              "      <td>0.404959</td>\n",
              "      <td>0.381378</td>\n",
              "      <td>[[294, 43], [101, 49]]</td>\n",
              "      <td>0.326667</td>\n",
              "      <td>0.127596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>172</td>\n",
              "      <td>91</td>\n",
              "      <td>169</td>\n",
              "      <td>94</td>\n",
              "      <td>0.620368</td>\n",
              "      <td>0.571205</td>\n",
              "      <td>0.608365</td>\n",
              "      <td>0.450549</td>\n",
              "      <td>0.436170</td>\n",
              "      <td>0.443243</td>\n",
              "      <td>0.386630</td>\n",
              "      <td>[[119, 53], [50, 41]]</td>\n",
              "      <td>0.450549</td>\n",
              "      <td>0.308140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>105</td>\n",
              "      <td>61</td>\n",
              "      <td>71</td>\n",
              "      <td>95</td>\n",
              "      <td>0.604528</td>\n",
              "      <td>0.591881</td>\n",
              "      <td>0.566265</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.442105</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.418858</td>\n",
              "      <td>[[52, 53], [19, 42]]</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.504762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>65</td>\n",
              "      <td>36</td>\n",
              "      <td>26</td>\n",
              "      <td>75</td>\n",
              "      <td>0.597009</td>\n",
              "      <td>0.527350</td>\n",
              "      <td>0.455446</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.373333</td>\n",
              "      <td>0.504505</td>\n",
              "      <td>0.369578</td>\n",
              "      <td>[[18, 47], [8, 28]]</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.723077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>32</td>\n",
              "      <td>31</td>\n",
              "      <td>11</td>\n",
              "      <td>52</td>\n",
              "      <td>0.508065</td>\n",
              "      <td>0.481351</td>\n",
              "      <td>0.476190</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.480769</td>\n",
              "      <td>0.602410</td>\n",
              "      <td>0.482955</td>\n",
              "      <td>[[5, 27], [6, 25]]</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.843750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.645161</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.645161</td>\n",
              "      <td>0.784314</td>\n",
              "      <td>0.645161</td>\n",
              "      <td>[[0, 11], [0, 20]]</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>[[11]]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PO</td>\n",
              "      <td>0</td>\n",
              "      <td>1269</td>\n",
              "      <td>253</td>\n",
              "      <td>1016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.800630</td>\n",
              "      <td>0.800630</td>\n",
              "      <td>0.800630</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.889278</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>[[0, 0], [253, 1016]]</td>\n",
              "      <td>0.800630</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Proir days cumulative IV treatment length  Continue with IV  Switch to PO  prediction_0  prediction_1     auroc  balanced_accuracy  accuracy    recall  precision        f1     auprc                      cm       tpr       fpr\n",
              "2                                         0               192             0           192             0       NaN           1.000000  1.000000  0.000000   0.000000  0.000000 -0.000000                 [[192]]       NaN       NaN\n",
              "0                                         1               384           181           545            20  0.500705           0.502410  0.669027  0.038674   0.350000  0.069652  0.321501   [[371, 13], [174, 7]]  0.038674  0.033854\n",
              "3                                         2               337           150           395            92  0.650049           0.599535  0.704312  0.326667   0.532609  0.404959  0.381378  [[294, 43], [101, 49]]  0.326667  0.127596\n",
              "4                                         3               172            91           169            94  0.620368           0.571205  0.608365  0.450549   0.436170  0.443243  0.386630   [[119, 53], [50, 41]]  0.450549  0.308140\n",
              "5                                         4               105            61            71            95  0.604528           0.591881  0.566265  0.688525   0.442105  0.538462  0.418858    [[52, 53], [19, 42]]  0.688525  0.504762\n",
              "6                                         5                65            36            26            75  0.597009           0.527350  0.455446  0.777778   0.373333  0.504505  0.369578     [[18, 47], [8, 28]]  0.777778  0.723077\n",
              "7                                         6                32            31            11            52  0.508065           0.481351  0.476190  0.806452   0.480769  0.602410  0.482955      [[5, 27], [6, 25]]  0.806452  0.843750\n",
              "8                                         7                11            20             0            31  0.472727           0.500000  0.645161  1.000000   0.645161  0.784314  0.645161      [[0, 11], [0, 20]]  1.000000  1.000000\n",
              "9                                         8                 0            11             0            11       NaN           1.000000  1.000000  1.000000   1.000000  1.000000  1.000000                  [[11]]       NaN       NaN\n",
              "1                                        PO                 0          1269           253          1016       NaN           0.800630  0.800630  0.800630   1.000000  0.889278  1.000000   [[0, 0], [253, 1016]]  0.800630       NaN"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "treatment_length_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "gather": {
          "logged": 1710775219416
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def plot_clustered_stacked(dfall, labels=None, title=\"multiple stacked bar plot\",  H=\"/\", **kwargs):\n",
        "    \"\"\"Given a list of dataframes, with identical columns and index, create a clustered stacked bar plot. \n",
        "labels is a list of the names of the dataframe, used for the legend\n",
        "title is a string for the title of the plot\n",
        "H is the hatch used for identification of the different dataframe\"\"\"\n",
        "\n",
        "    n_df = len(dfall)\n",
        "    n_col = len(dfall[0].columns) \n",
        "    n_ind = len(dfall[0].index)\n",
        "    axe = plt.subplot(111)\n",
        "\n",
        "    for df in dfall : # for each data frame\n",
        "        axe = df.plot(kind=\"bar\",\n",
        "                      linewidth=0,\n",
        "                      stacked=True,\n",
        "                      ax=axe,\n",
        "                      legend=False,\n",
        "                      grid=False,\n",
        "                      **kwargs)  # make bar plots\n",
        "\n",
        "    h,l = axe.get_legend_handles_labels() # get the handles we want to modify\n",
        "    for i in range(0, n_df * n_col, n_col): \n",
        "        for j, pa in enumerate(h[i:i+n_col]):\n",
        "            for rect in pa.patches: # for each index\n",
        "                rect.set_x(rect.get_x() + 1 / float(n_df + 1) * i / float(n_col))\n",
        "                rect.set_hatch(H * int(i / n_col))   \n",
        "                rect.set_width(1 / float(n_df + 1))\n",
        "\n",
        "    axe.set_xticks((np.arange(0, 2 * n_ind, 2) + 1 / float(n_df + 1)) / 2.)\n",
        "    axe.set_xticklabels(df.index, rotation = 0)\n",
        "    axe.set_title(title)\n",
        "    axe.set_ylabel('Count')\n",
        "\n",
        "    # Add invisible data to add another legend\n",
        "    n=[]        \n",
        "    for i in range(n_df):\n",
        "        n.append(axe.bar(0, 0, color=\"gray\", hatch=H * i))\n",
        "\n",
        "    l1 = axe.legend(h[:n_col], l[:n_col], loc=[1.01, 0.5])\n",
        "    if labels is not None:\n",
        "        l2 = plt.legend(n, labels, loc=[1.01, 0.1]) \n",
        "    axe.add_artist(l1)\n",
        "    \n",
        "    return axe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "gather": {
          "logged": 1710775230277
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def plot_clustered_stacked(dfall, labels=None, title=\"multiple stacked bar plot\", H=\"/\", figsize=(10, 6), fontsize=None, **kwargs):\n",
        "    \"\"\"Given a list of dataframes, with identical columns and index, create a clustered stacked bar plot.\n",
        "    \n",
        "    dfall: list of pandas DataFrames\n",
        "        List of DataFrames to plot.\n",
        "    labels: list of str, optional\n",
        "        List of names of the dataframes used for the legend.\n",
        "    title: str, optional\n",
        "        Title of the plot.\n",
        "    H: str, optional\n",
        "        Hatch used for identification of the different dataframes.\n",
        "    figsize: tuple of int, optional\n",
        "        Size of the figure (width, height) in inches.\n",
        "    fontsize: int or None, optional\n",
        "        Size of the font for x tick labels and y label. If None, default font size is used.\n",
        "    **kwargs: keyword arguments\n",
        "        Additional keyword arguments passed to DataFrame.plot().\n",
        "\n",
        "    Returns:\n",
        "    axe: matplotlib Axes object\n",
        "        The Axes object containing the plot.\n",
        "    \"\"\"\n",
        "    n_df = len(dfall)\n",
        "    n_col = len(dfall[0].columns)\n",
        "    n_ind = len(dfall[0].index)\n",
        "    \n",
        "    fig, axe = plt.subplots(figsize=figsize)\n",
        "    \n",
        "    for df in dfall:\n",
        "        axe = df.plot(kind=\"bar\",\n",
        "                      linewidth=0,\n",
        "                      stacked=True,\n",
        "                      ax=axe,\n",
        "                      legend=False, grid=False,\n",
        "                      **kwargs)\n",
        "        \n",
        "    h, _ = axe.get_legend_handles_labels()\n",
        "    \n",
        "    for i in range(0, n_df * n_col, n_col):\n",
        "        for j, pa in enumerate(h[i:i+n_col]):\n",
        "            for rect in pa.patches:\n",
        "                rect.set_x(rect.get_x() + 1 / float(n_df + 1) * i / float(n_col))\n",
        "                rect.set_hatch(H * int(i / n_col))\n",
        "                rect.set_width(1 / float(n_df + 1))\n",
        "    \n",
        "    axe.set_xticks((np.arange(0, 2 * n_ind, 2) + 1 / float(n_df + 1)) / 2.)\n",
        "    axe.set_xticklabels(dfall[0].index, rotation=0, fontsize=fontsize)\n",
        "    axe.set_title(title)\n",
        "    axe.set_ylabel('Count', fontsize=fontsize)\n",
        "    \n",
        "    # Add invisible data to add another legend\n",
        "    n = []\n",
        "    for i in range(n_df):\n",
        "        n.append(axe.bar(0, 0, color=\"gray\", hatch=H * i))\n",
        "    \n",
        "    leg1 = axe.legend(h[:n_col], dfall[0].columns, loc=[1.01, 0.5])\n",
        "    if labels is not None:\n",
        "        leg2 = plt.legend(n, labels, loc=[1.01, 0.1])\n",
        "        axe.add_artist(leg1)\n",
        "    \n",
        "    return axe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "gather": {
          "logged": 1710774113436
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "df1 = treatment_length_df[['Proir days cumulative IV treatment length', 'Continue with IV', 'Switch to PO']].set_index(['Proir days cumulative IV treatment length'])\n",
        "df2 = treatment_length_df[['Proir days cumulative IV treatment length', 'prediction_0', 'prediction_1']].set_index(['Proir days cumulative IV treatment length'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "gather": {
          "logged": 1710775228190
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Labels and predictions by IV treatment duration'}, xlabel='Proir days cumulative IV treatment length', ylabel='Count'>"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_clustered_stacked([df1, df2],[\"Labels\", \"Predictions\"], title=\"Labels and predictions by IV treatment duration\",  H=\"//\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "gather": {
          "logged": 1710775234871
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Labels and predictions by IV treatment duration'}, xlabel='Proir days cumulative IV treatment length', ylabel='Count'>"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_clustered_stacked([df1, df2],[\"Labels\", \"Predictions\"], title=\"Labels and predictions by IV treatment duration\",  H=\"//\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "24 & 48 hours version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "gather": {
          "logged": 1710774276759
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Get iv_treatment_length\n",
        "icare_df_preprocessed_2 = icare_df_preprocessed.rename(columns={'SPELL_IDENTIFIER':'stay_id'})\n",
        "icare_df_preprocessed_2 = icare_df_preprocessed_2.drop(columns=columns_to_drop)\n",
        "icare_df_preprocessed_2 = icare_df_preprocessed_2.drop(columns=['date', 'ROUTE', 'iv_treatment_length'])\n",
        "\n",
        "# Merge \n",
        "test_data = pd.merge(test_data, icare_df_preprocessed_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "gather": {
          "logged": 1710774300037
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def label_race (row):\n",
        "    if row['24_hour_flag'] == 1 :\n",
        "        return '24'\n",
        "    if row['48_hour_flag'] == 1 :\n",
        "        return '48'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "test_data['flag'] = test_data.apply(lambda row: label_race(row), axis=1)\n",
        "test_data.drop(columns=['24_hour_flag', '48_hour_flag'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "gather": {
          "logged": 1710774437384
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "48\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Other\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 2/2 [00:00<00:00,  2.77it/s]\n",
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|| 1/1 [00:00<00:00,  1.67it/s]\n",
            "100%|| 5/5 [00:02<00:00,  2.10it/s]\n"
          ]
        }
      ],
      "source": [
        "treatment_length_df = pd.DataFrame()\n",
        "\n",
        "for i in test_data.flag.unique():\n",
        "    print(i)\n",
        "    temp_test_data = test_data[test_data['flag'] == i]\n",
        "    temp_test_data = temp_test_data.drop(columns=['flag'])\n",
        "    temp_test_data = temp_test_data.drop(columns=['iv_treatment_length'])\n",
        "    \n",
        "    # Split up dfs\n",
        "    vitals_test_data = temp_test_data.iloc[:,2:255]\n",
        "    demographics_test_data = temp_test_data.iloc[:,255:267]\n",
        "    comorbidity_test_data = temp_test_data.iloc[:, 267:]\n",
        "\n",
        "    # Get labels\n",
        "    test_labels = temp_test_data[['po_flag']]\n",
        "\n",
        "    # Preprocess comorbidity data\n",
        "    print('Working on set_transformer_processing_fun...')\n",
        "    comorbidity_test_data, comorbidity_test_mask = set_transformer_processing_fun(comorbidity_test_data, embedding)\n",
        "    print('Done!')\n",
        "\n",
        "    test_dataset = MultiInputDataset([vitals_test_data, demographics_test_data], test_labels, comorbidity_test_data, comorbidity_test_mask)\n",
        "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size)#, collate_fn=test_dataset.collate_fn_padd)\n",
        "\n",
        "\n",
        "    test_loss, test_auroc, test_predictions, test_labels_out = evaluate(model, test_dataloader, criterion)\n",
        "\n",
        "    new_test_predictions = final_threshold_fun(test_predictions)\n",
        "\n",
        "    label_values, label_counts = np.unique(test_labels, return_counts=True)\n",
        "    prediction_values, prediction_counts = np.unique(new_test_predictions, return_counts=True)\n",
        "\n",
        "    label_0 = 0\n",
        "    label_1 = 0\n",
        "    for x in range(len(label_values)):\n",
        "        if label_values[x] == 0:\n",
        "            label_0 = label_counts[x]\n",
        "        elif label_values[x] == 1:\n",
        "            label_1 = label_counts[x]\n",
        "    prediction_0 = 0\n",
        "    prediction_1 = 0\n",
        "    for x in range(len(prediction_values)):\n",
        "        if prediction_values[x] == 0:\n",
        "            prediction_0 = prediction_counts[x]\n",
        "        elif prediction_values[x] == 1:\n",
        "            prediction_1 = prediction_counts[x]\n",
        "\n",
        "    # Lower bound\n",
        "    test_accuracy2 = accuracy_score(test_labels, new_test_predictions)\n",
        "    test_balanced_accuracy = balanced_accuracy_score(test_labels, new_test_predictions)\n",
        "    test_recall = recall_score(test_labels, new_test_predictions)\n",
        "    test_precision = precision_score(test_labels, new_test_predictions)\n",
        "    test_f1 = f1_score(test_labels, new_test_predictions)\n",
        "    test_auprc = average_precision_score(test_labels, new_test_predictions)\n",
        "    test_cm = confusion_matrix(test_labels, new_test_predictions)\n",
        "    if test_cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = test_cm.ravel()\n",
        "        test_true_positive_rate = (tp / (tp + fn))\n",
        "        test_false_positive_rate = (fp / (fp + tn))\n",
        "    else:\n",
        "        test_true_positive_rate = np.nan\n",
        "        test_false_positive_rate = np.nan\n",
        "\n",
        "    \n",
        "    sub_df = pd.DataFrame([[i, label_0, label_1, prediction_0, prediction_1, test_auroc, test_balanced_accuracy, test_accuracy2, test_recall, test_precision, test_f1, test_auprc, test_cm, test_true_positive_rate, test_false_positive_rate]])\n",
        "    treatment_length_df = pd.concat([treatment_length_df, sub_df], axis=0, ignore_index=True)\n",
        "treatment_length_df.columns = ['flag', 'label_0', 'label_1', 'prediction_0', 'prediction_1', 'auroc', 'balanced_accuracy', 'accuracy', 'recall', 'precision', 'f1', 'auprc', 'cm', 'tpr', 'fpr']\n",
        "treatment_length_df.sort_values(by=['flag'], inplace=True)\n",
        "# Set to string\n",
        "treatment_length_df['flag']= treatment_length_df['flag'].astype(str)\n",
        "# Rename\n",
        "treatment_length_df.rename(columns={'flag': 'Prediction timeframe', 'label_0': 'Continue with IV', 'label_1': 'Switch to PO'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "gather": {
          "logged": 1710774442289
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediction timeframe</th>\n",
              "      <th>Continue with IV</th>\n",
              "      <th>Switch to PO</th>\n",
              "      <th>prediction_0</th>\n",
              "      <th>prediction_1</th>\n",
              "      <th>auroc</th>\n",
              "      <th>balanced_accuracy</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>f1</th>\n",
              "      <th>auprc</th>\n",
              "      <th>cm</th>\n",
              "      <th>tpr</th>\n",
              "      <th>fpr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24</td>\n",
              "      <td>440</td>\n",
              "      <td>133</td>\n",
              "      <td>573</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.767888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.232112</td>\n",
              "      <td>[[440, 0], [133, 0]]</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48</td>\n",
              "      <td>312</td>\n",
              "      <td>199</td>\n",
              "      <td>456</td>\n",
              "      <td>55</td>\n",
              "      <td>0.580966</td>\n",
              "      <td>0.551773</td>\n",
              "      <td>0.636008</td>\n",
              "      <td>0.170854</td>\n",
              "      <td>0.618182</td>\n",
              "      <td>0.267717</td>\n",
              "      <td>0.428515</td>\n",
              "      <td>[[291, 21], [165, 34]]</td>\n",
              "      <td>0.170854</td>\n",
              "      <td>0.067308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Other</td>\n",
              "      <td>546</td>\n",
              "      <td>1518</td>\n",
              "      <td>633</td>\n",
              "      <td>1431</td>\n",
              "      <td>0.784916</td>\n",
              "      <td>0.689944</td>\n",
              "      <td>0.738857</td>\n",
              "      <td>0.793808</td>\n",
              "      <td>0.842068</td>\n",
              "      <td>0.817226</td>\n",
              "      <td>0.820088</td>\n",
              "      <td>[[320, 226], [313, 1205]]</td>\n",
              "      <td>0.793808</td>\n",
              "      <td>0.413919</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Prediction timeframe  Continue with IV  Switch to PO  prediction_0  prediction_1     auroc  balanced_accuracy  accuracy    recall  precision        f1     auprc                         cm       tpr       fpr\n",
              "0                   24               440           133           573             0  0.500000           0.500000  0.767888  0.000000   0.000000  0.000000  0.232112       [[440, 0], [133, 0]]  0.000000  0.000000\n",
              "1                   48               312           199           456            55  0.580966           0.551773  0.636008  0.170854   0.618182  0.267717  0.428515     [[291, 21], [165, 34]]  0.170854  0.067308\n",
              "2                Other               546          1518           633          1431  0.784916           0.689944  0.738857  0.793808   0.842068  0.817226  0.820088  [[320, 226], [313, 1205]]  0.793808  0.413919"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "treatment_length_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "gather": {
          "logged": 1710774472528
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "df1_2 = treatment_length_df[['Prediction timeframe', 'Continue with IV', 'Switch to PO']].set_index(['Prediction timeframe'])\n",
        "df2_2 = treatment_length_df[['Prediction timeframe', 'prediction_0', 'prediction_1']].set_index(['Prediction timeframe'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "gather": {
          "logged": 1710775287352
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Labels and predictions by timeframes'}, xlabel='Prediction timeframe', ylabel='Count'>"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_clustered_stacked([df1_2, df2_2],[\"Labels\", \"Predictions\"], title=\"Labels and predictions by timeframes\",  H=\"//\",  figsize=(8, 6), fontsize=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Label distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/chronic_switch_icare_df_preprocessed.csv'\n",
        "icare_df_preprocessed = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "gather": {
          "logged": 1710775501680
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Group mimic\n",
        "grouped_mimic = icare_df_preprocessed.groupby('iv_treatment_length').po_flag.value_counts()\n",
        "grouped_mimic2 = pd.pivot(pd.DataFrame(grouped_mimic).rename(columns={'po_flag': 'count'}).reset_index(level=1), columns=['po_flag'])\n",
        "grouped_mimic2 = grouped_mimic2.droplevel('po_flag', axis=1)\n",
        "grouped_mimic2.reset_index(inplace=True)\n",
        "grouped_mimic2.columns = ['iv_treatment_length', 'label_0', 'label_1']\n",
        "# Set to string\n",
        "grouped_mimic2['iv_treatment_length']= grouped_mimic2['iv_treatment_length'].astype(str)\n",
        "# Change 999\n",
        "grouped_mimic2['iv_treatment_length'] = grouped_mimic2['iv_treatment_length'].replace(['999'], 'PO')\n",
        "grouped_mimic2.rename(columns={'iv_treatment_length': 'Proir days cumulative IV treatment length'}, inplace=True)\n",
        "# Change to %\n",
        "grouped_mimic2.fillna(0, inplace=True)\n",
        "grouped_mimic2['Continue with IV'] = grouped_mimic2['label_0']/(grouped_mimic2['label_0']+grouped_mimic2['label_1'])*100\n",
        "grouped_mimic2['Switch to PO'] = grouped_mimic2['label_1']/(grouped_mimic2['label_0']+grouped_mimic2['label_1'])*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "gather": {
          "logged": 1710775514429
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def plot_clustered_stacked_2(dfall, labels=None, title=\"multiple stacked bar plot\",  H=\"/\", **kwargs):\n",
        "    \"\"\"Given a list of dataframes, with identical columns and index, create a clustered stacked bar plot. \n",
        "labels is a list of the names of the dataframe, used for the legend\n",
        "title is a string for the title of the plot\n",
        "H is the hatch used for identification of the different dataframe\"\"\"\n",
        "\n",
        "    n_df = len(dfall)\n",
        "    n_col = len(dfall[0].columns) \n",
        "    n_ind = len(dfall[0].index)\n",
        "    axe = plt.subplot(111)\n",
        "\n",
        "    for df in dfall : # for each data frame\n",
        "        axe = df.plot(kind=\"bar\",\n",
        "                      linewidth=0,\n",
        "                      stacked=True,\n",
        "                      ax=axe,\n",
        "                      legend=False,\n",
        "                      grid=False,\n",
        "                      **kwargs)  # make bar plots\n",
        "\n",
        "    h,l = axe.get_legend_handles_labels() # get the handles we want to modify\n",
        "    for i in range(0, n_df * n_col, n_col):\n",
        "        for j, pa in enumerate(h[i:i+n_col]):\n",
        "            for rect in pa.patches: # for each index\n",
        "                rect.set_x(rect.get_x() + 1 / float(n_df + 1) * i / float(n_col))\n",
        "                rect.set_hatch(H * int(i / n_col))    \n",
        "                rect.set_width(1 / float(n_df + 1))\n",
        "\n",
        "    axe.set_xticklabels(df.index, rotation = 0)\n",
        "    axe.set_title(title)\n",
        "    axe.set_ylabel('Percentage')\n",
        "    axe.set_ylim(0, 100)\n",
        "\n",
        "    # Add invisible data to add another legend\n",
        "    n=[]        \n",
        "    for i in range(n_df):\n",
        "        n.append(axe.bar(0, 0, color=\"gray\", hatch=H * i))\n",
        "\n",
        "    l1 = axe.legend(h[:n_col], l[:n_col], loc=[1.01, 0.5])\n",
        "    if labels is not None:\n",
        "        l2 = plt.legend(n, labels, loc=[1.01, 0.1]) \n",
        "    axe.add_artist(l1)\n",
        "    \n",
        "    return axe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "gather": {
          "logged": 1710775530255
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'ICHT labels by IV treatment duration'}, xlabel='Proir days cumulative IV treatment length', ylabel='Percentage'>"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df1 = grouped_mimic2[['Proir days cumulative IV treatment length', 'Continue with IV', 'Switch to PO']].set_index(['Proir days cumulative IV treatment length'])\n",
        "plot_clustered_stacked_2([df1],[\"ICHT\"], title=\"ICHT labels by IV treatment duration\",  H=\"/\", )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "gather": {
          "logged": 1710775590149
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def label_race (row):\n",
        "    if row['24_hour_flag'] == 1 :\n",
        "        return '24'\n",
        "    if row['48_hour_flag'] == 1 :\n",
        "        return '48'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "icare_df_preprocessed['flag'] = icare_df_preprocessed.apply(lambda row: label_race(row), axis=1)\n",
        "icare_df_preprocessed.drop(columns=['24_hour_flag', '48_hour_flag'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "gather": {
          "logged": 1710775600248
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Group mimic\n",
        "grouped_mimic = icare_df_preprocessed.groupby('flag').po_flag.value_counts()\n",
        "grouped_mimic2 = pd.pivot(pd.DataFrame(grouped_mimic).rename(columns={'po_flag': 'count'}).reset_index(level=1), columns=['po_flag'])\n",
        "grouped_mimic2 = grouped_mimic2.droplevel('po_flag', axis=1)\n",
        "grouped_mimic2.reset_index(inplace=True)\n",
        "grouped_mimic2.columns = ['flag', 'label_0', 'label_1']\n",
        "# Set to string\n",
        "grouped_mimic2['flag']= grouped_mimic2['flag'].astype(str)\n",
        "# Change 999\n",
        "grouped_mimic2.rename(columns={'flag': 'Prediction timeframe'}, inplace=True)\n",
        "# Change to %\n",
        "grouped_mimic2.fillna(0, inplace=True)\n",
        "grouped_mimic2['Continue with IV'] = grouped_mimic2['label_0']/(grouped_mimic2['label_0']+grouped_mimic2['label_1'])*100\n",
        "grouped_mimic2['Switch to PO'] = grouped_mimic2['label_1']/(grouped_mimic2['label_0']+grouped_mimic2['label_1'])*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "gather": {
          "logged": 1710775611766
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'ICHT labels by prediction timeframe'}, xlabel='Prediction timeframe', ylabel='Percentage'>"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df1 = grouped_mimic2[['Prediction timeframe', 'Continue with IV', 'Switch to PO']].set_index(['Prediction timeframe'])\n",
        "plot_clustered_stacked_2([df1],[\"ICHT\"], title=\"ICHT labels by prediction timeframe\",  H=\"/\", )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Spectrum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "gather": {
          "logged": 1710775847163
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/antibiotics.csv'\n",
        "antibiotics_df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710775928343
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Filter\n",
        "antibiotics_df = antibiotics_df[antibiotics_df['SPELL_IDENTIFIER'].isin(icare_df_preprocessed['SPELL_IDENTIFIER']).to_list()]\n",
        "antibiotics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "gather": {
          "logged": 1710775949152
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create df with column for iv and po\n",
        "filtered_antibiotics_iv = antibiotics_df[antibiotics_df['ROUTE'] == 'IV']\n",
        "filtered_antibiotics_po = antibiotics_df[antibiotics_df['ROUTE'] =='PO']\n",
        "filtered_antibiotics_iv.rename(columns={'antibiotics':'iv_antibiotics'}, inplace=True)\n",
        "filtered_antibiotics_po.rename(columns={'antibiotics':'po_antibiotics'}, inplace=True)\n",
        "filtered_antibiotics_iv.drop(columns=['ADMINISTRATION_DATETIME', 'ROUTE'], inplace=True)\n",
        "filtered_antibiotics_po.drop(columns=['ADMINISTRATION_DATETIME', 'ROUTE'], inplace=True)\n",
        "filtered_antibiotics_df2 = pd.merge(filtered_antibiotics_iv, filtered_antibiotics_po, on=['SPELL_IDENTIFIER'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "gather": {
          "logged": 1710776026870
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean iv_asi: 3.380926916221034\n",
            "STD iv_asi: 2.9077134488205796\n",
            "Mean po_asi: 4.590196078431372\n",
            "STD po_asi: 2.6239587848928076\n",
            "Mean % ASI change: inf\n",
            "STD % ASI change: nan\n",
            "Percentage who decrease ASI: 22.228163992869877\n",
            "Mean iv_asi for those who decrease: 6.809141940657578\n",
            "STD iv_asi for those who decrease: 1.8578227695123513\n",
            "Mean po_asi for those who decrease: 3.6808340016038494\n",
            "STD po_asi for those who decrease: 2.3482810100064535\n",
            "Mean % ASI change for those who decrease: -49.260704767922086\n",
            "STD % ASI change for those who decrease: 30.444506952223755\n"
          ]
        }
      ],
      "source": [
        "# Import\n",
        "path = r'switch_data/ASI.csv'\n",
        "asi_df = pd.read_csv(path)\n",
        "ASI_list = asi_df['Short Drug'].to_list()\n",
        "ASI2 = asi_df.drop(columns=['Drug', 'Antibiotic Spectrum Index']).set_index('Short Drug')\n",
        "\n",
        "cumcount = []\n",
        "cumcount2 = []\n",
        "\n",
        "for x in range(len(filtered_antibiotics_df2)):\n",
        "    iv_antibiotic_list = []\n",
        "    po_antibiotic_list = []\n",
        "    iv_antibiotic_list = [string for string in ASI_list if string in filtered_antibiotics_df2.loc[x]['po_antibiotics'].lower()]\n",
        "    iv_sub_df = ASI2.loc[iv_antibiotic_list]\n",
        "    iv_total_df = iv_sub_df.any(axis=0)\n",
        "    iv_asi_score = iv_total_df.sum()\n",
        "    cumcount.append(iv_asi_score)\n",
        "    po_antibiotic_list = [string for string in ASI_list if string in filtered_antibiotics_df2.loc[x]['iv_antibiotics'].lower()]\n",
        "    po_sub_df = ASI2.loc[po_antibiotic_list]\n",
        "    po_total_df = po_sub_df.any(axis=0)\n",
        "    po_asi_score = po_total_df.sum()\n",
        "    cumcount2.append(po_asi_score)\n",
        "\n",
        "filtered_antibiotics_df2['iv_asi'] = cumcount\n",
        "filtered_antibiotics_df2['po_asi'] = cumcount2\n",
        "\n",
        "# % Change\n",
        "filtered_antibiotics_df2['%_change_asi'] = (filtered_antibiotics_df2.po_asi - filtered_antibiotics_df2.iv_asi) / filtered_antibiotics_df2.iv_asi * 100\n",
        "# Decrease\n",
        "filtered_antibiotics_df2['decrease_asi'] = np.where(filtered_antibiotics_df2['po_asi'] < filtered_antibiotics_df2['iv_asi'], True, False)\n",
        "\n",
        "# Mean iv_asi\n",
        "print('Mean iv_asi:', filtered_antibiotics_df2['iv_asi'].mean())\n",
        "print('STD iv_asi:', filtered_antibiotics_df2['iv_asi'].std())\n",
        "# Mean po_asi\n",
        "print('Mean po_asi:', filtered_antibiotics_df2['po_asi'].mean())\n",
        "print('STD po_asi:', filtered_antibiotics_df2['po_asi'].std())\n",
        "# Mean % ASI change\n",
        "print('Mean % ASI change:', filtered_antibiotics_df2['%_change_asi'].mean())\n",
        "print('STD % ASI change:', filtered_antibiotics_df2['%_change_asi'].std())\n",
        "# Percentage decreasing ASI\n",
        "print('Percentage who decrease ASI:', (len(filtered_antibiotics_df2[filtered_antibiotics_df2['decrease_asi'] == True])/len(filtered_antibiotics_df2))*100)\n",
        "#Mean iv_asi for those who decrease\n",
        "print('Mean iv_asi for those who decrease:', filtered_antibiotics_df2[filtered_antibiotics_df2['decrease_asi'] == True]['iv_asi'].mean())\n",
        "print('STD iv_asi for those who decrease:', filtered_antibiotics_df2[filtered_antibiotics_df2['decrease_asi'] == True]['iv_asi'].std())\n",
        "# Mean po_asi for those who decrease\n",
        "print('Mean po_asi for those who decrease:', filtered_antibiotics_df2[filtered_antibiotics_df2['decrease_asi'] == True]['po_asi'].mean())\n",
        "print('STD po_asi for those who decrease:', filtered_antibiotics_df2[filtered_antibiotics_df2['decrease_asi'] == True]['po_asi'].std())\n",
        "# Mean % ASI change for those who decrease \n",
        "print('Mean % ASI change for those who decrease:', filtered_antibiotics_df2[filtered_antibiotics_df2['decrease_asi'] == True]['%_change_asi'].mean())\n",
        "print('STD % ASI change for those who decrease:', filtered_antibiotics_df2[filtered_antibiotics_df2['decrease_asi'] == True]['%_change_asi'].std())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "gather": {
          "logged": 1710776035073
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Mean iv_asi\n",
        "Mean_iv_asi = filtered_antibiotics_df2['iv_asi'].mean()\n",
        "STD_iv_asi = filtered_antibiotics_df2['iv_asi'].std()\n",
        "# Mean po_asi\n",
        "Mean_po_asi = filtered_antibiotics_df2['po_asi'].mean()\n",
        "STD_po_asi = filtered_antibiotics_df2['po_asi'].std()\n",
        "# Mean % ASI change\n",
        "Mean_percentage_ASI_change = filtered_antibiotics_df2['%_change_asi'].mean()\n",
        "STD_percentage_ASI_change = filtered_antibiotics_df2['%_change_asi'].std()\n",
        "# Percentage decreasing ASI\n",
        "Percentage_of_patients_who_decrease_ASI = (len(filtered_antibiotics_df2[filtered_antibiotics_df2['decrease_asi'] == True])/len(filtered_antibiotics_df2))*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "gather": {
          "logged": 1710776036115
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create lists for the plot\n",
        "names = ['Mean IV \\n ASI', 'Mean oral \\n ASI', 'Patients who \\n decrease']\n",
        "x_pos = np.arange(len(names))\n",
        "asi_means = [Mean_iv_asi, Mean_po_asi, np.nan]\n",
        "percentage_means = [np.nan, np.nan, Percentage_of_patients_who_decrease_ASI]\n",
        "asi_error = [STD_iv_asi, STD_po_asi,np.nan]\n",
        "percentage_error = [np.nan, np.nan, np.nan]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "gather": {
          "logged": 1710776038874
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.axis.XTick at 0x7fb404390880>,\n",
              " <matplotlib.axis.XTick at 0x7fb404390c70>,\n",
              " <matplotlib.axis.XTick at 0x7fb4043926e0>]"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 0, 'Mean IV \\n ASI'),\n",
              " Text(1, 0, 'Mean oral \\n ASI'),\n",
              " Text(2, 0, 'Patients who \\n decrease')]"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'ASI')"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Percentage')"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'MIMIC dataset antibiotic spectrum index (ASI) results')"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 14.0)"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 100.0)"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<BarContainer object of 3 artists>"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build the plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "color = 'tab:blue'\n",
        "color2 = 'tab:orange'\n",
        "\n",
        "par1 = ax.twinx()\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(names)\n",
        "ax.set_ylabel('ASI', color=color)\n",
        "par1.set_ylabel(\"Percentage\", color=color2)\n",
        "ax.set_title('MIMIC dataset antibiotic spectrum index (ASI) results')\n",
        "\n",
        "ax.set_ylim(0, 14)\n",
        "par1.set_ylim(0, 100)\n",
        "\n",
        "ax.bar(x_pos, asi_means, yerr=asi_error, color=color, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
        "\n",
        "# Save the figure and show\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Type of infection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import json, snowflake.connector\n",
        "\n",
        "# establish the connection to snowflake\n",
        "ctx = snowflake.connector.connect( \n",
        "    **json.load(open('/opt/ich/python-snowflake-defaults.json')))\n",
        "    \n",
        "# verify and test if connection is working\n",
        "try: \n",
        "    cs = ctx.cursor() \n",
        "    cs.execute('SELECT current_version(), current_role(), current_warehouse()')\n",
        "    print(cs.fetchone())\n",
        "finally: \n",
        "    cs.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1710789761849
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import \n",
        "query = '''\n",
        "SELECT * from ICHT_PROD.ICHT_COVID.EPISODES_DIAGNOSIS\n",
        "'''\n",
        "cur = ctx.cursor().execute(query)\n",
        "diagnosis = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1710789773708
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/chronic_switch_icare_df_preprocessed.csv'\n",
        "icare_df_preprocessed = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "gather": {
          "logged": 1710789775366
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Filter\n",
        "spell_list = icare_df_preprocessed.SPELL_IDENTIFIER.unique().tolist()\n",
        "diagnosis = diagnosis[diagnosis['SPELL_IDENTIFIER'].isin(spell_list)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1710789776655
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"# Filter by spesfic sepsis\\nsepsis_diagnoses = diagnosis[(diagnosis['DIAGNOSIS_CODE_ICD'] == 'A410')|                                     (diagnosis['DIAGNOSIS_CODE_ICD'] == 'A4101')|                                     (diagnosis['DIAGNOSIS_CODE_ICD'] == 'A4102')|                                     (diagnosis['DIAGNOSIS_CODE_ICD'] == 'A411')|                                     (diagnosis['DIAGNOSIS_CODE_ICD'] == 'A412')|                                     (diagnosis['DIAGNOSIS_CODE_ICD'] == 'A4181')|                                     (diagnosis['DIAGNOSIS_CODE_ICD'] == 'P362')|                                     (diagnosis['DIAGNOSIS_CODE_ICD'] == 'P363')|                                     (diagnosis['DIAGNOSIS_CODE_ICD'] == 'P3630')|                                     (diagnosis['DIAGNOSIS_CODE_ICD'] == 'P3639')]\""
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "735\n",
            "1504\n",
            "1781\n"
          ]
        }
      ],
      "source": [
        "# Filter by uti\n",
        "uti_diagnoses = diagnosis[(diagnosis['DIAGNOSIS_DESCRIPTION_ICD'].str.contains(\"urinary tract infection\", case=False)) | \\\n",
        "                                  (diagnosis['DIAGNOSIS_DESCRIPTION_ICD'].str.contains(\"pyelonephritis\", case=False)) | \\\n",
        "                                  (diagnosis['DIAGNOSIS_DESCRIPTION_SNOMED'].str.contains(\"urinary tract infection\", case=False)) | \\\n",
        "                                  (diagnosis['DIAGNOSIS_DESCRIPTION_SNOMED'].str.contains(\"pyelonephritis\", case=False))]\n",
        "# Filter by pneumonia\n",
        "pneumonia_diagnoses = diagnosis[(diagnosis['DIAGNOSIS_DESCRIPTION_ICD'].str.contains(\"pneumonia\", case=False)) | \\\n",
        "                                  (diagnosis['DIAGNOSIS_DESCRIPTION_SNOMED'].str.contains(\"pneumonia\", case=False))]\n",
        "\n",
        "'''# Filter by spesfic sepsis\n",
        "sepsis_diagnoses = diagnosis[(diagnosis['DIAGNOSIS_CODE_ICD'] == 'A410')| \\\n",
        "                                    (diagnosis['DIAGNOSIS_CODE_ICD'] == 'A4101')| \\\n",
        "                                    (diagnosis['DIAGNOSIS_CODE_ICD'] == 'A4102')| \\\n",
        "                                    (diagnosis['DIAGNOSIS_CODE_ICD'] == 'A411')| \\\n",
        "                                    (diagnosis['DIAGNOSIS_CODE_ICD'] == 'A412')| \\\n",
        "                                    (diagnosis['DIAGNOSIS_CODE_ICD'] == 'A4181')| \\\n",
        "                                    (diagnosis['DIAGNOSIS_CODE_ICD'] == 'P362')| \\\n",
        "                                    (diagnosis['DIAGNOSIS_CODE_ICD'] == 'P363')| \\\n",
        "                                    (diagnosis['DIAGNOSIS_CODE_ICD'] == 'P3630')| \\\n",
        "                                    (diagnosis['DIAGNOSIS_CODE_ICD'] == 'P3639')]'''\n",
        "# Filter by sepsis\n",
        "sepsis_diagnoses = diagnosis[(diagnosis['DIAGNOSIS_DESCRIPTION_ICD'].str.contains(\"sepsis\", case=False)) | \\\n",
        "                                  (diagnosis['DIAGNOSIS_DESCRIPTION_SNOMED'].str.contains(\"sepsis\", case=False))]\n",
        "\n",
        "# Get stays\n",
        "uti_stays = uti_diagnoses.SPELL_IDENTIFIER.unique().tolist()\n",
        "pneumonia_stays = pneumonia_diagnoses.SPELL_IDENTIFIER.unique().tolist()\n",
        "sepsis_stays = sepsis_diagnoses.SPELL_IDENTIFIER.unique().tolist()\n",
        "\n",
        "print(len(uti_stays))\n",
        "print(len(pneumonia_stays))\n",
        "print(len(sepsis_stays))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "gather": {
          "logged": 1710790202056
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "del diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1710790214186
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "735\n",
            "1504\n",
            "1781\n"
          ]
        }
      ],
      "source": [
        "print(len(uti_stays))\n",
        "print(len(pneumonia_stays))\n",
        "print(len(sepsis_stays))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1710839221959
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Function to train and eval model \n",
        "def diagnosis_cv_run_fun(data, model, filter_list):\n",
        "\n",
        "    overall_best_test_auroc = 0\n",
        "\n",
        "    actual_test_auroc_results = []\n",
        "\n",
        "    test_auroc_results = []\n",
        "    test_accuracy_results = []\n",
        "    test_balanced_accuracy_results = []\n",
        "    test_recall_results = []\n",
        "    test_precision_results = []\n",
        "    test_f1_results = []\n",
        "    test_auprc_results = []\n",
        "    test_cm_results = []\n",
        "    test_true_positive_rate_results = []\n",
        "    test_fasle_positive_rate_results = []\n",
        "\n",
        "    final_threshold = 0\n",
        "\n",
        "    # Define batch size \n",
        "    batch_size = 512\n",
        "\n",
        "    # Define optimizer and learning_rate\n",
        "    learning_rate = 0.0001\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Define loss\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Define epochs and clip\n",
        "    N_EPOCHS = 10\n",
        "    CLIP = 1\n",
        "\n",
        "    # Split into folds\n",
        "    split_generator = cv_data_fun(data)\n",
        "\n",
        "    # Iterate through folds\n",
        "    for x in range(N_EPOCHS): # Note this only works as number of splits and epocs are the same\n",
        "        train_idx, val_idx, test_idx = next(split_generator)\n",
        "\n",
        "        # Get train val and test\n",
        "        train_data = data.loc[train_idx]\n",
        "        valid_data = data.loc[val_idx]\n",
        "        test_data = data.loc[test_idx]\n",
        "\n",
        "        # Filter test for only those diagnosis we care about\n",
        "        test_data = test_data[test_data['stay_id'].isin(filter_list)]\n",
        "\n",
        "        #Apply smote - crashes with these features\n",
        "        #train_data = smote_fun(train_data)\n",
        "\n",
        "        # Split up dfs\n",
        "        vitals_train_data = train_data.iloc[:,2:255]\n",
        "        demographics_train_data = train_data.iloc[:,255:267]\n",
        "        comorbidity_train_data = train_data.iloc[:, 267:]\n",
        "\n",
        "        vitals_valid_data = valid_data.iloc[:,2:255]\n",
        "        demographics_valid_data = valid_data.iloc[:,255:267]\n",
        "        comorbidity_valid_data = valid_data.iloc[:, 267:]\n",
        "\n",
        "        vitals_test_data = test_data.iloc[:,2:255]\n",
        "        demographics_test_data = test_data.iloc[:,255:267]\n",
        "        comorbidity_test_data = test_data.iloc[:, 267:]\n",
        "\n",
        "        # Initializing the weights of our model each fold\n",
        "        model.apply(init_weights)\n",
        "\n",
        "        # Get labels\n",
        "        train_labels = train_data[['po_flag']]\n",
        "        valid_labels = valid_data[['po_flag']]\n",
        "        test_labels = test_data[['po_flag']]\n",
        "\n",
        "        # Preprocess comorbidity data\n",
        "        print('Working on set_transformer_processing_fun...')\n",
        "        comorbidity_train_data, comorbidity_train_mask = set_transformer_processing_fun(comorbidity_train_data, embedding)\n",
        "        comorbidity_valid_data, comorbidity_valid_mask = set_transformer_processing_fun(comorbidity_valid_data, embedding)\n",
        "        comorbidity_test_data, comorbidity_test_mask = set_transformer_processing_fun(comorbidity_test_data, embedding)\n",
        "        print('Done!')\n",
        "\n",
        "        # Define dataloaders\n",
        "        train_dataset =  MultiInputDataset([vitals_train_data, demographics_train_data], train_labels, comorbidity_train_data, comorbidity_train_mask)\n",
        "        train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
        "\n",
        "        valid_dataset = MultiInputDataset([vitals_valid_data, demographics_valid_data], valid_labels, comorbidity_valid_data, comorbidity_valid_mask)\n",
        "        valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=batch_size)\n",
        "\n",
        "        test_dataset = MultiInputDataset([vitals_test_data, demographics_test_data], test_labels, comorbidity_test_data, comorbidity_test_mask)\n",
        "        test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
        "\n",
        "        # Run\n",
        "        best_valid_loss = float('inf')\n",
        "        best_valid_auroc = 0\n",
        "\n",
        "        optimal_threshold = 0\n",
        "\n",
        "        for epoch in range(N_EPOCHS):\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss, train_auroc, train_predictions, train_labels_out = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
        "\n",
        "            valid_loss, valid_auroc, valid_predictions, valid_labels_out = evaluate(model, valid_dataloader, criterion)\n",
        "\n",
        "            end_time = time.time()\n",
        "            \n",
        "            fpr, tpr, thresholds = roc_curve(valid_labels_out, valid_predictions)\n",
        "            optimal_idx = np.argmax(tpr - fpr)\n",
        "            current_threshold = thresholds[optimal_idx]\n",
        "\n",
        "            epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "            print('Train AUROC:', train_auroc)\n",
        "            print('Valid AUROC:', valid_auroc)\n",
        "            print(train_predictions)\n",
        "            print(train_labels_out)\n",
        "            print('Train loss:', train_loss)\n",
        "            print('Valid loss:', valid_loss)\n",
        "            print(current_threshold)\n",
        "\n",
        "            if valid_loss < best_valid_loss:\n",
        "                best_valid_loss = valid_loss\n",
        "                print('BEST VALID LOSS')\n",
        "\n",
        "            if valid_auroc > best_valid_auroc:\n",
        "                best_valid_auroc = valid_auroc\n",
        "                print('UPDATED BEST INTERMEDIATE MODEL')\n",
        "                torch.save(model.state_dict(), f'chronic_switch_model_intermediate_diagnosis.pt')\n",
        "                optimal_threshold = current_threshold\n",
        "\n",
        "        # -----------------------------\n",
        "        # Evaluate best model on test set\n",
        "        # -----------------------------\n",
        "\n",
        "        model.load_state_dict(torch.load(f'chronic_switch_model_intermediate_diagnosis.pt'))\n",
        "\n",
        "        test_loss, test_auroc, test_predictions, test_labels_out = evaluate(model, test_dataloader, criterion)\n",
        "\n",
        "        print('Test AUROC result:', test_auroc)\n",
        "        \n",
        "        new_test_predictions = new_threshold_fun(test_predictions, optimal_threshold)\n",
        "\n",
        "        test_accuracy = accuracy_score(test_labels_out, new_test_predictions)\n",
        "        test_balanced_accuracy = balanced_accuracy_score(test_labels_out, new_test_predictions)\n",
        "        test_recall = recall_score(test_labels_out, new_test_predictions)\n",
        "        test_precision = precision_score(test_labels_out, new_test_predictions)\n",
        "        test_f1 = f1_score(test_labels_out, new_test_predictions)\n",
        "        test_auprc = average_precision_score(test_labels_out, test_predictions)\n",
        "        test_cm = confusion_matrix(test_labels_out, new_test_predictions)\n",
        "        tn, fp, fn, tp = test_cm.ravel()\n",
        "        test_true_positive_rate = (tp / (tp + fn))\n",
        "        test_false_positive_rate = (fp / (fp + tn))\n",
        "        \n",
        "        actual_test_auroc_results.append(test_auroc)\n",
        "        \n",
        "        test_auroc_results.append(test_auroc)\n",
        "        test_accuracy_results.append(test_accuracy)\n",
        "        test_balanced_accuracy_results.append(test_balanced_accuracy)\n",
        "        test_recall_results.append(test_recall)\n",
        "        test_precision_results.append(test_precision)\n",
        "        test_f1_results.append(test_f1)\n",
        "        test_auprc_results.append(test_auprc)\n",
        "        test_cm_results.append(test_cm)\n",
        "        test_true_positive_rate_results.append(test_true_positive_rate)\n",
        "        test_fasle_positive_rate_results.append(test_false_positive_rate)\n",
        "\n",
        "    test_results = [test_auroc_results, test_accuracy_results,\n",
        "        test_balanced_accuracy_results,\n",
        "        test_recall_results,\n",
        "        test_precision_results,\n",
        "        test_f1_results,\n",
        "        test_auprc_results,\n",
        "        test_cm_results,\n",
        "        test_true_positive_rate_results,\n",
        "        test_fasle_positive_rate_results\n",
        "        ]\n",
        "    \n",
        "    return test_results, actual_test_auroc_results, final_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1710838909106
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/chronic_switch_episodes.csv'\n",
        "episodes = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_disease.csv'\n",
        "disease = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_demographics.csv'\n",
        "demographics = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/snomed_embedding_128d-copy.csv'\n",
        "embedding = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_problem_dummies.csv'\n",
        "problem_dummies = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "gather": {
          "logged": 1710790286025
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Merge\n",
        "problem_dummies2 = pd.merge(problem_dummies, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "problem_dummies2 = pd.merge(icare_df_preprocessed[['SPELL_IDENTIFIER', 'date']], problem_dummies2)\n",
        "\n",
        "# Strip name \n",
        "problem_dummies2.columns = problem_dummies2.columns.str.removeprefix('PROBLEM_')\n",
        "\n",
        "# Convert the date columns to datetime objects if they are not already\n",
        "problem_dummies2['date'] = pd.to_datetime(problem_dummies2['date'])\n",
        "problem_dummies2['DT_TM'] = pd.to_datetime(problem_dummies2['DT_TM'])\n",
        "\n",
        "# Calculate the absolute time difference between 'date' and 'DT_TM'\n",
        "problem_dummies2['time_diff'] = (problem_dummies2['date'] - problem_dummies2['DT_TM']).abs()\n",
        "\n",
        "# Filter rows where 'time_diff' is not negative\n",
        "problem_dummies2 = problem_dummies2[problem_dummies2['time_diff'] >= pd.Timedelta(0)]\n",
        "\n",
        "# Sort the DataFrame by 'SPELL_IDENTIFIER' and 'time_diff'\n",
        "problem_dummies2.sort_values(by=['SPELL_IDENTIFIER', 'time_diff'], inplace=True)\n",
        "\n",
        "# Convert to str\n",
        "problem_dummies2['date'] = problem_dummies2['date'].astype(str)\n",
        "\n",
        "# Keep only the rows with the smallest time difference for each 'SPELL_IDENTIFIER'\n",
        "problem_dummies2 = problem_dummies2.groupby(['SPELL_IDENTIFIER', 'date']).first().reset_index()\n",
        "\n",
        "### REASON the problem_dummies2 is shorter is not because it is missing some dates! \n",
        "### It is because in the final data we have some dates repeated for a spesfic spell \n",
        "### if they were admited in between 6am and 12pm the 12hour prediction is done at 6am \n",
        "### of the first day, then 48 done at 6am the next day, then the next prediction done \n",
        "### at 12pm that day causing there to be two prediction for that day...phew\n",
        "### So just get a set of co-morbidities for each spell and merge \n",
        "\n",
        "# Drop the 'time_diff' column as it's no longer needed\n",
        "problem_dummies2.drop(columns=['time_diff', 'SUBJECT', 'DT_TM', 'new_subject', 'date'], inplace=True)\n",
        "\n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(inplace=True)\n",
        "\n",
        "# Some still got through by having their co-morbidid diagnosis updated during their stay \n",
        "# In this case we just use the frst one throughout and remove the others \n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(subset=['SPELL_IDENTIFIER'], keep='first', inplace=True)\n",
        "\n",
        "# Filter for features\n",
        "X_data = icare_df_preprocessed.drop(columns=['SPELL_IDENTIFIER', 'po_flag'])\n",
        "X_data = X_data.drop(columns=columns_to_drop)\n",
        "model_data = pd.concat([icare_df_preprocessed[['SPELL_IDENTIFIER', 'po_flag']], X_data], axis=1)\n",
        "# Merge\n",
        "demographics = pd.merge(demographics, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "demographics.drop(columns=['SUBJECT'], inplace=True)\n",
        "model_data = pd.merge(model_data, demographics, how='left')\n",
        "model_data = pd.merge(model_data, disease, how='left')\n",
        "# Drop \n",
        "model_data = model_data.drop(columns=['date', 'ROUTE', '24_hour_flag', '48_hour_flag', 'iv_treatment_length'])\n",
        "# fillna\n",
        "model_data['AGE'] = model_data['AGE'].fillna(-1)\n",
        "model_data['IMDDECIL'] = model_data['IMDDECIL'].fillna(-1)\n",
        "model_data = model_data.fillna(0)\n",
        "# Merge co-morbidites\n",
        "model_data = pd.merge(model_data, problem_dummies2, how='left')\n",
        "# Rename\n",
        "model_data.rename(columns={'SPELL_IDENTIFIER': 'stay_id'}, inplace=True)\n",
        "# Random shuffle\n",
        "stays = model_data['stay_id'].unique()\n",
        "random.Random(5).shuffle(stays)\n",
        "model_data = model_data.set_index(\"stay_id\").loc[stays].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "gather": {
          "logged": 1710795779556
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:44<00:00,  1.12it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [01:06<00:00,  1.34s/it]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.87it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.87it/s]\n",
            "100%|| 50/50 [00:45<00:00,  1.10it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.84it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 2/2 [00:01<00:00,  1.78it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.87it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.85it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.88it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.86it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.86it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.86it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.88it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.88it/s]\n",
            "100%|| 50/50 [00:45<00:00,  1.11it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.86it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.87it/s]\n",
            "100%|| 2/2 [00:01<00:00,  1.71it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.91it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.79it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.87it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.91it/s]\n",
            "100%|| 2/2 [00:01<00:00,  1.62it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.87it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.87it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.86it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.12it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.86it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 2/2 [00:01<00:00,  1.77it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.84it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:45<00:00,  1.11it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.87it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.88it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.12it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.85it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.88it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.77it/s]\n",
            "100%|| 50/50 [00:45<00:00,  1.11it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.77it/s]\n",
            "100%|| 50/50 [00:45<00:00,  1.10it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.85it/s]\n",
            "100%|| 2/2 [00:01<00:00,  1.66it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.97it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.19it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.99it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.99it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.98it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.20it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.20it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.21it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.00it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 2/2 [00:00<00:00,  2.09it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.21it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.01it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.19it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.98it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.80it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.01it/s]\n",
            "100%|| 3/3 [00:01<00:00,  2.64it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.21it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 2/2 [00:00<00:00,  2.14it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 2/2 [00:01<00:00,  1.96it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.19it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.97it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 3/3 [00:01<00:00,  2.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7281933559500635\n",
            "Valid AUROC: 0.7595597837001802\n",
            "[0.5736541 0.5       0.6526704 ... 0.8397096 0.5       0.5      ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5952540314197541\n",
            "Valid loss: 0.5762601750237601\n",
            "0.50860393\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7451327406547285\n",
            "Valid AUROC: 0.7909062159114868\n",
            "[0.5       0.5       0.7387343 ... 0.8043113 0.5       0.5      ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5754907763004303\n",
            "Valid loss: 0.5643541898046222\n",
            "0.60242075\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7562599823376857\n",
            "Valid AUROC: 0.7945749628541978\n",
            "[0.5        0.5        0.9160872  ... 0.83982456 0.5        0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5668838667869568\n",
            "Valid loss: 0.5575987781797137\n",
            "0.58973885\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7610374277050135\n",
            "Valid AUROC: 0.7900585082845764\n",
            "[0.5      0.5      0.805607 ... 0.5      0.5      0.5     ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5643482279777526\n",
            "Valid loss: 0.5556180221693856\n",
            "0.58299875\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.765375480115019\n",
            "Valid AUROC: 0.8004303746413544\n",
            "[0.5        0.5        0.8429945  ... 0.76716447 0.5        0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5585199630260468\n",
            "Valid loss: 0.553332005228315\n",
            "0.595009\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7706520370764706\n",
            "Valid AUROC: 0.8066605777828516\n",
            "[0.5        0.556512   0.83296216 ... 0.71818197 0.5        0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.554360738992691\n",
            "Valid loss: 0.5502570356641497\n",
            "0.60716385\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7770957411437999\n",
            "Valid AUROC: 0.8107172410689658\n",
            "[0.5       0.5141214 0.7722998 ... 0.623319  0.5080136 0.5      ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5479378378391266\n",
            "Valid loss: 0.5505689467702594\n",
            "0.6518924\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7822847483178822\n",
            "Valid AUROC: 0.8154289038092466\n",
            "[0.5        0.5        0.79842633 ... 0.5        0.51250905 0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5443073165416717\n",
            "Valid loss: 0.5502927218164716\n",
            "0.65266937\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.784689162444491\n",
            "Valid AUROC: 0.8141330715557737\n",
            "[0.5759477  0.57901734 0.7459105  ... 0.5        0.5        0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.540089819431305\n",
            "Valid loss: 0.5436333588191441\n",
            "0.66541386\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7897807036205792\n",
            "Valid AUROC: 0.8211793156839036\n",
            "[0.5379616  0.5        0.80866516 ... 0.61693436 0.5838729  0.5463656 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5347722280025482\n",
            "Valid loss: 0.558006056717464\n",
            "0.68185544\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.8346082949308756\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7043901175709759\n",
            "Valid AUROC: 0.7915073085412068\n",
            "[0.5        0.5        0.5        ... 0.5        0.9302347  0.87397885]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.6096387374401092\n",
            "Valid loss: 0.564039579459599\n",
            "0.56424916\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7386328398218991\n",
            "Valid AUROC: 0.7951501270145338\n",
            "[0.5        0.7033409  0.5        ... 0.7035613  0.84213716 0.90248346]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.581603934764862\n",
            "Valid loss: 0.5588688680103847\n",
            "0.5627973\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7465737188721643\n",
            "Valid AUROC: 0.7836042976720944\n",
            "[0.5       0.6942922 0.5       ... 0.5367226 0.7873337 0.5      ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5748622822761535\n",
            "Valid loss: 0.5637052059173584\n",
            "0.536052\n",
            "Train AUROC: 0.7543185809707408\n",
            "Valid AUROC: 0.8032195061008621\n",
            "[0.5        0.64489883 0.5        ... 0.58017856 0.5        0.7406555 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5684931719303131\n",
            "Valid loss: 0.5489531414849418\n",
            "0.57216185\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7552552094940165\n",
            "Valid AUROC: 0.7946508141423396\n",
            "[0.5        0.64478636 0.5        ... 0.53080326 0.86690027 0.8919004 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.56478724360466\n",
            "Valid loss: 0.5556379897253854\n",
            "0.5194029\n",
            "Train AUROC: 0.7607269481681869\n",
            "Valid AUROC: 0.8091083996168741\n",
            "[0.5        0.5452066  0.5        ... 0.5        0.862601   0.84581083]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5587564599514008\n",
            "Valid loss: 0.5445692709514073\n",
            "0.634913\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7663028756809598\n",
            "Valid AUROC: 0.8065241744055303\n",
            "[0.5        0.67344    0.5        ... 0.57363355 0.78906524 0.7615666 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5549665296077728\n",
            "Valid loss: 0.5435877272060939\n",
            "0.6357491\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7728592460453556\n",
            "Valid AUROC: 0.8140128263857077\n",
            "[0.5        0.6385497  0.5        ... 0.6566426  0.8989946  0.90394014]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5495964151620865\n",
            "Valid loss: 0.5385680028370449\n",
            "0.59560406\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7749235816130949\n",
            "Valid AUROC: 0.8125850580935328\n",
            "[0.5        0.6542882  0.5        ... 0.5661175  0.5        0.85634357]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5483571207523346\n",
            "Valid loss: 0.53882383448737\n",
            "0.6310348\n",
            "Train AUROC: 0.781589600109402\n",
            "Valid AUROC: 0.8243588889351601\n",
            "[0.5        0.55372494 0.5        ... 0.5        0.8374031  0.85685843]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5403836637735366\n",
            "Valid loss: 0.5388553397996085\n",
            "0.68004817\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.8001819953306247\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7156785135262994\n",
            "Valid AUROC: 0.7821584141923126\n",
            "[0.66816324 0.5360074  0.58845335 ... 0.5        0.9004539  0.8094949 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.6049234592914581\n",
            "Valid loss: 0.5735090970993042\n",
            "0.518608\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7420412195460957\n",
            "Valid AUROC: 0.8029409070087037\n",
            "[0.5       0.5       0.5       ... 0.5       0.8024654 0.8932714]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5801397180557251\n",
            "Valid loss: 0.5555223737444196\n",
            "0.5408107\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7480486200430041\n",
            "Valid AUROC: 0.7980502227959854\n",
            "[0.5       0.5       0.5       ... 0.5       0.7826586 0.9180301]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5754832053184509\n",
            "Valid loss: 0.5588562658854893\n",
            "0.5004556\n",
            "Train AUROC: 0.7510493692781106\n",
            "Valid AUROC: 0.7998121850664224\n",
            "[0.5       0.5       0.5       ... 0.5       0.881509  0.9301426]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.569658716917038\n",
            "Valid loss: 0.5548764637538365\n",
            "0.5003603\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7569762736834041\n",
            "Valid AUROC: 0.8124249364927332\n",
            "[0.5        0.5        0.5        ... 0.5        0.86955255 0.918802  ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5642214262485504\n",
            "Valid loss: 0.5479133810315814\n",
            "0.5346855\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7618008338076007\n",
            "Valid AUROC: 0.8227714154832799\n",
            "[0.5       0.5       0.5       ... 0.5       0.8181701 0.9283863]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5592617547512054\n",
            "Valid loss: 0.5368902683258057\n",
            "0.5833686\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7681909708067595\n",
            "Valid AUROC: 0.8232471994336401\n",
            "[0.5        0.65917075 0.5        ... 0.5        0.7877083  0.91318375]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5548873376846314\n",
            "Valid loss: 0.5372774090085711\n",
            "0.60686773\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7696401348440889\n",
            "Valid AUROC: 0.8183971182276266\n",
            "[0.5        0.74794483 0.5        ... 0.5        0.77989143 0.9339268 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5510776317119599\n",
            "Valid loss: 0.5364909597805568\n",
            "0.5917664\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7783593164008993\n",
            "Valid AUROC: 0.8275579894223962\n",
            "[0.5        0.5        0.5        ... 0.5        0.84251404 0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5458217626810073\n",
            "Valid loss: 0.5329497711999076\n",
            "0.6384494\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.78007628856185\n",
            "Valid AUROC: 0.8282574022404532\n",
            "[0.5        0.6853507  0.5        ... 0.5        0.90420544 0.92222047]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5420603442192078\n",
            "Valid loss: 0.5316761561802456\n",
            "0.6380036\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7915861368624497\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7108454438059737\n",
            "Valid AUROC: 0.7719805938450006\n",
            "[0.5       0.5       0.5       ... 0.5       0.8412741 0.8986676]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.6043876039981843\n",
            "Valid loss: 0.5717052561896188\n",
            "0.5081341\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7404017875803233\n",
            "Valid AUROC: 0.7908828551201432\n",
            "[0.5        0.53838444 0.5        ... 0.5        0.88308567 0.9183168 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5789677786827088\n",
            "Valid loss: 0.5598246455192566\n",
            "0.6242786\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7444020302242627\n",
            "Valid AUROC: 0.7844126098363385\n",
            "[0.5        0.67618906 0.5        ... 0.5        0.91132015 0.89031625]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5749227488040924\n",
            "Valid loss: 0.5607401643480573\n",
            "0.5415425\n",
            "Train AUROC: 0.7514838242018226\n",
            "Valid AUROC: 0.8041535834756173\n",
            "[0.5       0.5       0.5       ... 0.5       0.8324961 0.9198653]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5671704518795013\n",
            "Valid loss: 0.5523943390165057\n",
            "0.6272146\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7532468992320843\n",
            "Valid AUROC: 0.8089434889434889\n",
            "[0.5       0.5       0.5       ... 0.5       0.7954598 0.8231526]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5648995041847229\n",
            "Valid loss: 0.5484288760593959\n",
            "0.6618308\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.760899796491088\n",
            "Valid AUROC: 0.8115633198684045\n",
            "[0.5       0.592878  0.5       ... 0.5       0.9210285 0.5      ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5614408123493194\n",
            "Valid loss: 0.5453953061785016\n",
            "0.6412227\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7650967299529736\n",
            "Valid AUROC: 0.8132478240952817\n",
            "[0.5       0.5       0.5       ... 0.5       0.9147837 0.9237439]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5558349072933197\n",
            "Valid loss: 0.5422610470226833\n",
            "0.61118454\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7710415813374023\n",
            "Valid AUROC: 0.822694790321909\n",
            "[0.5        0.59043473 0.5        ... 0.5        0.7350179  0.85236454]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.550711315870285\n",
            "Valid loss: 0.5435378210885184\n",
            "0.7061076\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7711013991755317\n",
            "Valid AUROC: 0.821559571898555\n",
            "[0.5        0.542878   0.5        ... 0.50058115 0.8318789  0.88476545]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5496588438749314\n",
            "Valid loss: 0.5373715673174176\n",
            "0.6769686\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7783847214843694\n",
            "Valid AUROC: 0.8220434764502562\n",
            "[0.5       0.5059431 0.5       ... 0.5       0.8412499 0.8917174]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5424841189384461\n",
            "Valid loss: 0.5370925409453255\n",
            "0.6839432\n",
            "BEST VALID LOSS\n",
            "Test AUROC result: 0.7886005803696412\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7261055769113636\n",
            "Valid AUROC: 0.76489651438804\n",
            "[0.6562569 0.5       0.5       ... 0.5       0.9713117 0.5972837]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5974092102050781\n",
            "Valid loss: 0.5759485363960266\n",
            "0.5646727\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7432978835857058\n",
            "Valid AUROC: 0.7579511098155166\n",
            "[0.5722256  0.9009541  0.9649423  ... 0.5        0.97925276 0.67050785]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5772250688076019\n",
            "Valid loss: 0.5740208625793457\n",
            "0.5216705\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.748608320390877\n",
            "Valid AUROC: 0.7752717278141007\n",
            "[0.53651035 0.86379135 0.95643836 ... 0.5        0.9566689  0.59641117]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5711092042922974\n",
            "Valid loss: 0.5680364370346069\n",
            "0.58601713\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7545246585003232\n",
            "Valid AUROC: 0.7790122017240662\n",
            "[0.6246121  0.5        0.8545459  ... 0.5        0.97070193 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5653261876106263\n",
            "Valid loss: 0.5652314509664264\n",
            "0.6898257\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7625845844464789\n",
            "Valid AUROC: 0.7875638195977179\n",
            "[0.6756727  0.7011622  0.9751788  ... 0.5        0.97835106 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5590255618095398\n",
            "Valid loss: 0.5630447864532471\n",
            "0.656435\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7647573772488857\n",
            "Valid AUROC: 0.7787944030316912\n",
            "[0.5       0.8970211 0.982976  ... 0.5       0.5       0.5557318]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5582155406475067\n",
            "Valid loss: 0.5605883598327637\n",
            "0.5220054\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7685332853431277\n",
            "Valid AUROC: 0.795597384749927\n",
            "[0.68935347 0.7804669  0.98681855 ... 0.5        0.98429894 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5533862239122391\n",
            "Valid loss: 0.5566049984523228\n",
            "0.5751541\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7741749190254805\n",
            "Valid AUROC: 0.7972764752425769\n",
            "[0.5        0.69744915 0.9927013  ... 0.5        0.9881235  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5474597948789597\n",
            "Valid loss: 0.5569326196398053\n",
            "0.5816555\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.777134761400053\n",
            "Valid AUROC: 0.7869220838712364\n",
            "[0.675523   0.70816565 0.9889177  ... 0.5        0.9931417  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5426596456766128\n",
            "Valid loss: 0.5536035895347595\n",
            "0.525062\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7793947393753874\n",
            "Valid AUROC: 0.8052038479157124\n",
            "[0.5737145  0.62703127 0.99605894 ... 0.5        0.9949173  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5392241936922073\n",
            "Valid loss: 0.557530300957816\n",
            "0.67198014\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.8020617283950616\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7193438802184262\n",
            "Valid AUROC: 0.7479717236496898\n",
            "[0.5215245 0.5       0.5193198 ... 0.5       0.9576769 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6003169703483582\n",
            "Valid loss: 0.5798013721193586\n",
            "0.5069255\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7389117964784692\n",
            "Valid AUROC: 0.7680191979344523\n",
            "[0.5       0.7720194 0.880777  ... 0.5       0.9472685 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5770684969425202\n",
            "Valid loss: 0.5738661629813058\n",
            "0.6021188\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7445257715510167\n",
            "Valid AUROC: 0.7777518427518427\n",
            "[0.5       0.8411274 0.9704422 ... 0.5       0.5       0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5737414753437042\n",
            "Valid loss: 0.574798950127193\n",
            "0.67487955\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7510278236955048\n",
            "Valid AUROC: 0.779218548286345\n",
            "[0.5       0.8133174 0.9783467 ... 0.5       0.9509993 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5664801359176636\n",
            "Valid loss: 0.5720019170216152\n",
            "0.7007423\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7568322154048365\n",
            "Valid AUROC: 0.7815764377628784\n",
            "[0.5       0.8440011 0.9767031 ... 0.5       0.9798662 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5617086899280548\n",
            "Valid loss: 0.571190357208252\n",
            "0.6587575\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7578892522047537\n",
            "Valid AUROC: 0.7879123807937367\n",
            "[0.5        0.827719   0.9752024  ... 0.5        0.98815733 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5603371357917786\n",
            "Valid loss: 0.571349024772644\n",
            "0.67327857\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7626646921926509\n",
            "Valid AUROC: 0.784141923124974\n",
            "[0.5        0.78829676 0.5        ... 0.5        0.9812088  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.556246417760849\n",
            "Valid loss: 0.5643500685691833\n",
            "0.59176964\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.769904779310761\n",
            "Valid AUROC: 0.7928719860075794\n",
            "[0.5       0.7993377 0.9931932 ... 0.5       0.5       0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5512000167369843\n",
            "Valid loss: 0.565082175391061\n",
            "0.6795705\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7715093107390445\n",
            "Valid AUROC: 0.7927501769874651\n",
            "[0.5        0.750463   0.9942009  ... 0.5        0.97864294 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5484481585025788\n",
            "Valid loss: 0.5606908457619804\n",
            "0.6236767\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7792760443526123\n",
            "Valid AUROC: 0.8016239120476408\n",
            "[0.5        0.5        0.99278945 ... 0.5        0.9801363  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5414670699834824\n",
            "Valid loss: 0.57725042956216\n",
            "0.7452064\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7923244389862677\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7241821510878257\n",
            "Valid AUROC: 0.768182651064007\n",
            "[0.5       0.5578243 0.5       ... 0.5       0.9093068 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5982517802715301\n",
            "Valid loss: 0.5779265505926949\n",
            "0.6250937\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7418998085741627\n",
            "Valid AUROC: 0.763934535459959\n",
            "[0.5        0.8924559  0.95101255 ... 0.5        0.92758536 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5778366327285767\n",
            "Valid loss: 0.571705528667995\n",
            "0.55889076\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7489698681648587\n",
            "Valid AUROC: 0.7747828259692667\n",
            "[0.5       0.8197503 0.9096088 ... 0.5       0.9612363 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5720373022556305\n",
            "Valid loss: 0.5697030425071716\n",
            "0.569209\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7552720595074209\n",
            "Valid AUROC: 0.7826568941823179\n",
            "[0.5        0.81571615 0.9693887  ... 0.5        0.9461268  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5660417246818542\n",
            "Valid loss: 0.566638103553227\n",
            "0.6062062\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7632527501776764\n",
            "Valid AUROC: 0.7880647982342897\n",
            "[0.5        0.8799377  0.9563978  ... 0.5        0.97321916 0.5156772 ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5605390322208404\n",
            "Valid loss: 0.5637060488973346\n",
            "0.7109332\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7653586232080543\n",
            "Valid AUROC: 0.787076167076167\n",
            "[0.5        0.8490801  0.9842202  ... 0.5        0.96750176 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5578062891960144\n",
            "Valid loss: 0.5597345147814069\n",
            "0.63298094\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7710121556920595\n",
            "Valid AUROC: 0.7939141298463331\n",
            "[0.5        0.8927521  0.97487974 ... 0.5        0.5        0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5520322215557099\n",
            "Valid loss: 0.5580440589359829\n",
            "0.68356925\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7727455262377693\n",
            "Valid AUROC: 0.7839566068379628\n",
            "[0.5        0.8013703  0.9823263  ... 0.5        0.99548703 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5482384413480759\n",
            "Valid loss: 0.5531009350504194\n",
            "0.6438067\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7735066263303259\n",
            "Valid AUROC: 0.7988980968641984\n",
            "[0.5       0.7596688 0.9946213 ... 0.5       0.9720232 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5460516256093979\n",
            "Valid loss: 0.5598379458699908\n",
            "0.7323389\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7786886179318879\n",
            "Valid AUROC: 0.7886232457418898\n",
            "[0.5        0.82937795 0.9963741  ... 0.5        0.9924194  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.539718866944313\n",
            "Valid loss: 0.5478769540786743\n",
            "0.5910325\n",
            "BEST VALID LOSS\n",
            "Test AUROC result: 0.8122085301062573\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7270688654783991\n",
            "Valid AUROC: 0.774008870195311\n",
            "[0.5012007  0.5495673  0.6497652  ... 0.5        0.93164814 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5965695667266846\n",
            "Valid loss: 0.5788234046527317\n",
            "0.62697434\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.743364901022317\n",
            "Valid AUROC: 0.7726327405988423\n",
            "[0.5        0.8781738  0.9683311  ... 0.5        0.92717165 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5747011113166809\n",
            "Valid loss: 0.5740119985171727\n",
            "0.55671936\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7454897730695058\n",
            "Valid AUROC: 0.7660592179236246\n",
            "[0.5        0.8535446  0.5        ... 0.5        0.97297204 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5711246240139007\n",
            "Valid loss: 0.5684194649968829\n",
            "0.6051462\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.756911528812403\n",
            "Valid AUROC: 0.7697672094282264\n",
            "[0.5        0.7581809  0.9451059  ... 0.5        0.96500176 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5643459236621857\n",
            "Valid loss: 0.5659685730934143\n",
            "0.6403043\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7590449985983505\n",
            "Valid AUROC: 0.7851678257610462\n",
            "[0.5        0.72117496 0.5        ... 0.5        0.9629901  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5607517248392105\n",
            "Valid loss: 0.5725187999861581\n",
            "0.6796523\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7622064629928225\n",
            "Valid AUROC: 0.7841973097905302\n",
            "[0.5        0.5        0.95812196 ... 0.5        0.9777389  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5581182163953781\n",
            "Valid loss: 0.5674831782068525\n",
            "0.70762146\n",
            "Train AUROC: 0.7686182046977381\n",
            "Valid AUROC: 0.7898869362428684\n",
            "[0.5        0.61736214 0.9849881  ... 0.5        0.98949045 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5534346759319305\n",
            "Valid loss: 0.564674402986254\n",
            "0.7060309\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.772546534650629\n",
            "Valid AUROC: 0.7857893640944487\n",
            "[0.5       0.8022326 0.9899109 ... 0.5       0.5       0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5498699235916138\n",
            "Valid loss: 0.5608243857111249\n",
            "0.68354875\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.774433238591092\n",
            "Valid AUROC: 0.8031720318160995\n",
            "[0.5        0.76731896 0.9809887  ... 0.5        0.96366996 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5470810049772262\n",
            "Valid loss: 0.5750126242637634\n",
            "0.80710346\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7820861669219891\n",
            "Valid AUROC: 0.7903887477616292\n",
            "[0.5       0.9040898 0.9969813 ... 0.5       0.9728228 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5412236362695694\n",
            "Valid loss: 0.5556292193276542\n",
            "0.68776625\n",
            "BEST VALID LOSS\n",
            "Test AUROC result: 0.7486532418392868\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7249289270415943\n",
            "Valid AUROC: 0.7839520259859243\n",
            "[0.61941284 0.56874126 0.60078377 ... 0.5        0.9181753  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5981896615028381\n",
            "Valid loss: 0.5761432221957615\n",
            "0.69221956\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7421246194214681\n",
            "Valid AUROC: 0.777540290675884\n",
            "[0.5        0.5        0.9383029  ... 0.5        0.94982475 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5759239530563355\n",
            "Valid loss: 0.5664409654481071\n",
            "0.5929987\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7497241935908658\n",
            "Valid AUROC: 0.7804932744763252\n",
            "[0.5        0.88329875 0.93990153 ... 0.5        0.9363207  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5695935785770416\n",
            "Valid loss: 0.5635345493044172\n",
            "0.60548306\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7530134195368687\n",
            "Valid AUROC: 0.7887983592220879\n",
            "[0.5        0.80781406 0.9173106  ... 0.5        0.91150236 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5658085644245148\n",
            "Valid loss: 0.5625563859939575\n",
            "0.6560049\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.758594263527497\n",
            "Valid AUROC: 0.7934727022862617\n",
            "[0.5       0.8467072 0.9778349 ... 0.5       0.970698  0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5604046642780304\n",
            "Valid loss: 0.5652837668146405\n",
            "0.6395671\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7605055626653563\n",
            "Valid AUROC: 0.7987448465414567\n",
            "[0.5        0.7533288  0.95517784 ... 0.5        0.9311763  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.558278768658638\n",
            "Valid loss: 0.5649746400969369\n",
            "0.67989427\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7650923374679852\n",
            "Valid AUROC: 0.800799566901262\n",
            "[0.5        0.88113666 0.97818416 ... 0.5        0.9730436  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5538260436058045\n",
            "Valid loss: 0.5665384786469596\n",
            "0.7008214\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7706484397643433\n",
            "Valid AUROC: 0.7887912797234831\n",
            "[0.5       0.8498175 0.9961653 ... 0.5       0.9830965 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5506980407238007\n",
            "Valid loss: 0.5544709052358355\n",
            "0.5746769\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7726470901049208\n",
            "Valid AUROC: 0.7947428476242036\n",
            "[0.5        0.5        0.98453474 ... 0.5        0.99368334 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5476512849330902\n",
            "Valid loss: 0.5526906677654811\n",
            "0.5965591\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7770135466310455\n",
            "Valid AUROC: 0.8040240702952568\n",
            "[0.5        0.77600306 0.9887145  ... 0.5        0.98630524 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5432835954427719\n",
            "Valid loss: 0.5542517048971993\n",
            "0.61641115\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7745229244114002\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.6967522619687052\n",
            "Valid AUROC: 0.77136634323075\n",
            "[0.5       0.5       0.5       ... 0.5       0.9441477 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6101421749591828\n",
            "Valid loss: 0.570727527141571\n",
            "0.5975428\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7423673614861477\n",
            "Valid AUROC: 0.7828796901678258\n",
            "[0.5        0.5        0.87253135 ... 0.5        0.9400369  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5762168955802918\n",
            "Valid loss: 0.5682389310428074\n",
            "0.60193896\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.747211612683491\n",
            "Valid AUROC: 0.7824472160912839\n",
            "[0.5        0.5        0.94325584 ... 0.5        0.9451812  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5701581251621246\n",
            "Valid loss: 0.5642767889159066\n",
            "0.68449676\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7495618913319395\n",
            "Valid AUROC: 0.7823306125848499\n",
            "[0.5        0.5        0.92482525 ... 0.5        0.9734404  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5671429848670959\n",
            "Valid loss: 0.5597629632268634\n",
            "0.64693\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7560355588932245\n",
            "Valid AUROC: 0.7866043393162037\n",
            "[0.5       0.5       0.9191333 ... 0.5       0.9714446 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5615979135036469\n",
            "Valid loss: 0.5578563468796867\n",
            "0.6544238\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7565854430483797\n",
            "Valid AUROC: 0.7918435847249408\n",
            "[0.5       0.5       0.9188642 ... 0.5       0.9782119 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5585413688421249\n",
            "Valid loss: 0.5563521129744393\n",
            "0.61692816\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7633407166672651\n",
            "Valid AUROC: 0.7849995835589055\n",
            "[0.5        0.55963284 0.9789073  ... 0.5        0.98539954 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5548588919639588\n",
            "Valid loss: 0.5527368017605373\n",
            "0.56564647\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7681123216925507\n",
            "Valid AUROC: 0.7949571065672761\n",
            "[0.5       0.5       0.5       ... 0.5       0.9916372 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5499643206596374\n",
            "Valid loss: 0.5513863222939628\n",
            "0.64536345\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7729350443603926\n",
            "Valid AUROC: 0.8061277224836547\n",
            "[0.5       0.5       0.9659522 ... 0.5       0.9891558 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5463943690061569\n",
            "Valid loss: 0.5562836868422372\n",
            "0.7275285\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7773653279467626\n",
            "Valid AUROC: 0.802404530879107\n",
            "[0.5       0.5       0.9765844 ... 0.5       0.993338  0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.542721011042595\n",
            "Valid loss: 0.5496194703238351\n",
            "0.6156003\n",
            "BEST VALID LOSS\n",
            "Test AUROC result: 0.8028592927012791\n"
          ]
        }
      ],
      "source": [
        "pneumonia_test_results, pneumonia_actual_test_auroc_results, pneumonia_final_threshold = diagnosis_cv_run_fun(model_data, model, pneumonia_stays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "gather": {
          "logged": 1710795780263
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.8346082949308756,\n",
              " 0.8001819953306247,\n",
              " 0.7915861368624497,\n",
              " 0.7886005803696412,\n",
              " 0.8020617283950616,\n",
              " 0.7923244389862677,\n",
              " 0.8122085301062573,\n",
              " 0.7486532418392868,\n",
              " 0.7745229244114002,\n",
              " 0.8028592927012791]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pneumonia_actual_test_auroc_results\n",
        "pneumonia_final_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "gather": {
          "logged": 1710795781123
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save \n",
        "with open(\"pneumonia_cv_chronic_switch_test_results\", \"wb\") as fp:   #Pickling\n",
        "    pickle.dump(pneumonia_test_results, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "gather": {
          "logged": 1710795781669
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test_auroc: 0.7947607163933144\n",
            "std test_auroc: 0.021517355346640375\n",
            "test_auroc 2.5th percentile: 0.7544739204180123\n",
            "test_auroc 97.5th percentile: 0.8295683478453365\n",
            "mean test_accuracy: 0.7209430663409935\n",
            "std test_accuracy: 0.02469243573392646\n",
            "test_accuracy 2.5th percentile: 0.6694815668202765\n",
            "test_accuracy 97.5th percentile: 0.7510678439126952\n",
            "mean test_balanced_accuracy: 0.7301116095278456\n",
            "std test_balanced_accuracy: 0.021762136793995617\n",
            "test_balanced_accuracy 2.5th percentile: 0.6887899137393729\n",
            "test_balanced_accuracy 97.5th percentile: 0.7605944264069263\n",
            "mean test_recall: 0.6776117160239636\n",
            "std test_recall: 0.05534722678112555\n",
            "test_recall 2.5th percentile: 0.5536285135486889\n",
            "test_recall 97.5th percentile: 0.7273223381033228\n",
            "mean test_precision: 0.8183787520586255\n",
            "std test_precision: 0.024382362752854013\n",
            "test_precision 2.5th percentile: 0.77905625\n",
            "test_precision 97.5th percentile: 0.8514123365739189\n",
            "mean test_f1: 0.739932934816018\n",
            "std test_f1: 0.03763191575461791\n",
            "test_f1 2.5th percentile: 0.6552851045861044\n",
            "test_f1 97.5th percentile: 0.7772341234630498\n",
            "mean test_auprc: 0.8435155700185663\n",
            "std test_auprc: 0.02428816480369917\n",
            "test_auprc 2.5th percentile: 0.8023083006770553\n",
            "test_auprc 97.5th percentile: 0.8806010255369516\n",
            "mean test_tpr: 0.6776117160239636\n",
            "std test_tpr: 0.05534722678112555\n",
            "test_tpr 2.5th percentile: 0.5536285135486889\n",
            "test_tpr 97.5th percentile: 0.7273223381033228\n",
            "mean test_fpr: 0.21738849696827217\n",
            "std test_fpr: 0.03477505487086759\n",
            "test_fpr 2.5th percentile: 0.16819444444444442\n",
            "test_fpr 97.5th percentile: 0.2728249388753056\n"
          ]
        }
      ],
      "source": [
        "analyze_results_fun(pneumonia_test_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.00it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 3/3 [00:01<00:00,  2.62it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.09it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.20it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.96it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.86it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 3/3 [00:01<00:00,  2.45it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.81it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 3/3 [00:01<00:00,  2.11it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.20it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 3/3 [00:01<00:00,  2.22it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.20it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.01it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.19it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.98it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.07it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.08it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 3/3 [00:01<00:00,  2.32it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.98it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.00it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.20it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 3/3 [00:01<00:00,  2.32it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 3/3 [00:01<00:00,  2.25it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.98it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.19it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.02it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.20it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.06it/s]\n",
            "100%|| 3/3 [00:01<00:00,  2.32it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.05it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.03it/s]\n",
            " 30%|       | 15/50 [00:12<00:28,  1.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.6950722879058139\n",
            "Valid AUROC: 0.7814701821081815\n",
            "[0.5043391 0.5       0.5       ... 0.8067422 0.6360695 0.5      ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.6121254944801331\n",
            "Valid loss: 0.5677178246634347\n",
            "0.6084497\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7432102133453509\n",
            "Valid AUROC: 0.7758610201158166\n",
            "[0.54713154 0.67880684 0.80330044 ... 0.89953524 0.5        0.56977755]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5764546918869019\n",
            "Valid loss: 0.5639224393027169\n",
            "0.5713088\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7508073133453215\n",
            "Valid AUROC: 0.802208498159585\n",
            "[0.5        0.50153697 0.7783672  ... 0.8832424  0.5216739  0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5698820161819458\n",
            "Valid loss: 0.5638657893453326\n",
            "0.71340036\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7593654653933852\n",
            "Valid AUROC: 0.8104155746536877\n",
            "[0.5        0.5757977  0.5        ... 0.5        0.59049934 0.65363216]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.562416080236435\n",
            "Valid loss: 0.5781238675117493\n",
            "0.77587533\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.761442533882855\n",
            "Valid AUROC: 0.7985680845265962\n",
            "[0.60045123 0.73244244 0.9039043  ... 0.5        0.5960458  0.84817   ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5597183418273926\n",
            "Valid loss: 0.5545157705034528\n",
            "0.63571566\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7662427481198837\n",
            "Valid AUROC: 0.8081532848722625\n",
            "[0.5        0.5        0.89711714 ... 0.5        0.5        0.8083239 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5565062308311463\n",
            "Valid loss: 0.554630424295153\n",
            "0.6644284\n",
            "Train AUROC: 0.7758496582667421\n",
            "Valid AUROC: 0.8124809895991753\n",
            "[0.5       0.6626067 0.8287576 ... 0.9173284 0.6409827 0.8355991]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5481612181663513\n",
            "Valid loss: 0.558265915938786\n",
            "0.71637577\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7770051539879103\n",
            "Valid AUROC: 0.8142901547582044\n",
            "[0.5       0.5       0.8710755 ... 0.9168442 0.5       0.8905732]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5464196038246155\n",
            "Valid loss: 0.5566759535244533\n",
            "0.7316136\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7804022016331535\n",
            "Valid AUROC: 0.7964235029804142\n",
            "[0.5        0.5916263  0.8253257  ... 0.8708283  0.5586078  0.71317804]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5409422606229782\n",
            "Valid loss: 0.5455746565546308\n",
            "0.58569986\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7846917668333617\n",
            "Valid AUROC: 0.8186378594684506\n",
            "[0.5        0.5        0.8247122  ... 0.7786331  0.5764705  0.93777955]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5356585371494293\n",
            "Valid loss: 0.5602102620261056\n",
            "0.6765569\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.8243981136758501\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.6875238864428448\n",
            "Valid AUROC: 0.7798196810061218\n",
            "[0.5        0.5        0.5        ... 0.60693353 0.8782348  0.8533538 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.6116157579421997\n",
            "Valid loss: 0.5620009132793972\n",
            "0.6062589\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7385599157733588\n",
            "Valid AUROC: 0.7726054637071588\n",
            "[0.5       0.5       0.5       ... 0.646261  0.5       0.9124598]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5792239701747894\n",
            "Valid loss: 0.5676867195538112\n",
            "0.5097017\n",
            "Train AUROC: 0.7416098735222699\n",
            "Valid AUROC: 0.7849381584974805\n",
            "[0.5        0.5        0.5        ... 0.60444695 0.87748384 0.89160496]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5758979451656342\n",
            "Valid loss: 0.5557889853204999\n",
            "0.5610774\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7496812873030547\n",
            "Valid AUROC: 0.8119220838712363\n",
            "[0.5       0.5       0.5       ... 0.5       0.7057449 0.7636452]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5681857323646545\n",
            "Valid loss: 0.5455379060336522\n",
            "0.69067305\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7576357869157542\n",
            "Valid AUROC: 0.7931899387831592\n",
            "[0.5        0.59835005 0.5        ... 0.59524786 0.7586572  0.8941258 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5618465769290925\n",
            "Valid loss: 0.5502793022564479\n",
            "0.608807\n",
            "Train AUROC: 0.7600748311877128\n",
            "Valid AUROC: 0.8020297338941407\n",
            "[0.5        0.5        0.5        ... 0.52566063 0.5        0.81867385]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5592081475257874\n",
            "Valid loss: 0.5435647453580584\n",
            "0.6427733\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.761483221433338\n",
            "Valid AUROC: 0.8090005413734227\n",
            "[0.5        0.5        0.5        ... 0.5        0.860929   0.88442093]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5571629852056503\n",
            "Valid loss: 0.5402509570121765\n",
            "0.60801274\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7710329675687116\n",
            "Valid AUROC: 0.7952981718235955\n",
            "[0.5        0.56534386 0.5        ... 0.545453   0.5        0.90744907]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5505473864078522\n",
            "Valid loss: 0.5504860281944275\n",
            "0.57019424\n",
            "Train AUROC: 0.7704607607091932\n",
            "Valid AUROC: 0.7826002581934784\n",
            "[0.5        0.5        0.5        ... 0.6144935  0.83348465 0.8572256 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5468090403079987\n",
            "Valid loss: 0.5598897423063006\n",
            "0.50015193\n",
            "Train AUROC: 0.7782227331510191\n",
            "Valid AUROC: 0.818833132053471\n",
            "[0.5        0.5        0.5        ... 0.5        0.7910093  0.73578316]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5417594343423844\n",
            "Valid loss: 0.5347763895988464\n",
            "0.61355615\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.8058009476375712\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7205059090974082\n",
            "Valid AUROC: 0.7747478449173365\n",
            "[0.5       0.5       0.5       ... 0.5       0.8958128 0.7946724]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.6008265006542206\n",
            "Valid loss: 0.5652544753892081\n",
            "0.5683544\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7355483911889075\n",
            "Valid AUROC: 0.7870682546953732\n",
            "[0.5        0.5        0.5        ... 0.5        0.86256254 0.706404  ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5822931015491486\n",
            "Valid loss: 0.5593828644071307\n",
            "0.5612491\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7458995791610813\n",
            "Valid AUROC: 0.7979098821471703\n",
            "[0.5        0.60615146 0.5        ... 0.5        0.871349   0.74054736]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5733852779865265\n",
            "Valid loss: 0.5521575127329145\n",
            "0.54635257\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7535336179310356\n",
            "Valid AUROC: 0.7975417482197144\n",
            "[0.5       0.608344  0.5       ... 0.5       0.9285547 0.7192579]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5675316059589386\n",
            "Valid loss: 0.5530281152044024\n",
            "0.54097956\n",
            "Train AUROC: 0.7565138061067883\n",
            "Valid AUROC: 0.8057764544205223\n",
            "[0.5        0.5        0.5        ... 0.5        0.80633163 0.738786  ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5640214824676514\n",
            "Valid loss: 0.5462910192353385\n",
            "0.5662793\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7576060619263688\n",
            "Valid AUROC: 0.8069745554491318\n",
            "[0.5        0.5        0.5        ... 0.5        0.5        0.73434114]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5599272525310517\n",
            "Valid loss: 0.5414349692208427\n",
            "0.6112232\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.765742140824792\n",
            "Valid AUROC: 0.8086967475950526\n",
            "[0.5      0.5      0.5      ... 0.5      0.829049 0.5     ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5536082744598388\n",
            "Valid loss: 0.5425875016621181\n",
            "0.6194621\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7681116759549962\n",
            "Valid AUROC: 0.8090782076375296\n",
            "[0.5        0.5        0.5        ... 0.5        0.91162723 0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5515679609775543\n",
            "Valid loss: 0.5418308462415423\n",
            "0.6364404\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7728325615926129\n",
            "Valid AUROC: 0.8098103110814975\n",
            "[0.5       0.5       0.5       ... 0.5       0.5       0.7499313]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5470761543512345\n",
            "Valid loss: 0.5389618873596191\n",
            "0.63052493\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7777315172027834\n",
            "Valid AUROC: 0.8137231916045474\n",
            "[0.5        0.5        0.5        ... 0.5        0.8616586  0.79597473]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5425848168134689\n",
            "Valid loss: 0.5365109699113029\n",
            "0.57848513\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.8011725561367922\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7098949863751403\n",
            "Valid AUROC: 0.7822298338400033\n",
            "[0.5        0.56499195 0.5        ... 0.5107098  0.5        0.8590099 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.6051353931427002\n",
            "Valid loss: 0.564258371080671\n",
            "0.5455455\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7377082106755678\n",
            "Valid AUROC: 0.7950747511764462\n",
            "[0.5        0.64711064 0.5        ... 0.5        0.5        0.7774618 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5787779295444488\n",
            "Valid loss: 0.5557536227362496\n",
            "0.57862526\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7430472758263116\n",
            "Valid AUROC: 0.7760238204306001\n",
            "[0.5       0.8502213 0.5       ... 0.5       0.8275188 0.8413247]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.572539724111557\n",
            "Valid loss: 0.5607561724526542\n",
            "0.52451235\n",
            "Train AUROC: 0.7507113162940184\n",
            "Valid AUROC: 0.7903379419481115\n",
            "[0.5       0.6865377 0.5       ... 0.5       0.8332934 0.8722403]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5667354345321656\n",
            "Valid loss: 0.5520366515432086\n",
            "0.5548457\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7546028418483162\n",
            "Valid AUROC: 0.796833798359222\n",
            "[0.5       0.7941679 0.5       ... 0.5       0.5860114 0.7922517]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5629704511165619\n",
            "Valid loss: 0.5494399581636701\n",
            "0.54222286\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.757626395108244\n",
            "Valid AUROC: 0.804560238204306\n",
            "[0.5        0.5656823  0.5        ... 0.5        0.7371181  0.86988264]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.559124870300293\n",
            "Valid loss: 0.5430576971599034\n",
            "0.6180938\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7640875615174785\n",
            "Valid AUROC: 0.800437887810769\n",
            "[0.5        0.69912076 0.5        ... 0.5        0.8304467  0.7236213 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5538026142120361\n",
            "Valid loss: 0.543159008026123\n",
            "0.5383723\n",
            "Train AUROC: 0.7655095886025008\n",
            "Valid AUROC: 0.8204035314204805\n",
            "[0.5        0.6681654  0.5        ... 0.5        0.7122572  0.75648904]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5499905520677566\n",
            "Valid loss: 0.5387352619852338\n",
            "0.6442269\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7700008062956271\n",
            "Valid AUROC: 0.8224332653146212\n",
            "[0.5       0.7198861 0.5       ... 0.5       0.7353716 0.8445911]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5453132712841033\n",
            "Valid loss: 0.5401021242141724\n",
            "0.66602534\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.777321373550644\n",
            "Valid AUROC: 0.8146770499312872\n",
            "[0.5        0.7196257  0.5        ... 0.5        0.79313016 0.83218765]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5411287313699722\n",
            "Valid loss: 0.5343723467418126\n",
            "0.5230036\n",
            "BEST VALID LOSS\n",
            "Test AUROC result: 0.8080233042030794\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7161000194710623\n",
            "Valid AUROC: 0.7610167409319951\n",
            "[0.5        0.5        0.50944954 ... 0.5        0.94065154 0.6074394 ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5988338220119477\n",
            "Valid loss: 0.5758911456380572\n",
            "0.5793031\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7409292602731503\n",
            "Valid AUROC: 0.7704137342272934\n",
            "[0.50905764 0.7674786  0.5        ... 0.5        0.942177   0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5767617547512054\n",
            "Valid loss: 0.5727718898228237\n",
            "0.58069485\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7486966221955332\n",
            "Valid AUROC: 0.7773562237121558\n",
            "[0.57745963 0.83544743 0.84047383 ... 0.5        0.9722988  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5703528618812561\n",
            "Valid loss: 0.5700122458594186\n",
            "0.58255374\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7527291960684538\n",
            "Valid AUROC: 0.7747709573980761\n",
            "[0.6384303  0.5        0.88170606 ... 0.5        0.94143546 0.54941845]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5663100755214692\n",
            "Valid loss: 0.5680590442248753\n",
            "0.542229\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7573718219904114\n",
            "Valid AUROC: 0.7811972681464207\n",
            "[0.54241055 0.7831371  0.9578837  ... 0.5        0.96668696 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5630265653133393\n",
            "Valid loss: 0.5668385795184544\n",
            "0.52503437\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.761907420551734\n",
            "Valid AUROC: 0.7965204264356806\n",
            "[0.72380334 0.67175937 0.94142425 ... 0.5        0.5        0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5584716784954071\n",
            "Valid loss: 0.5662661790847778\n",
            "0.57423013\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7679434628846425\n",
            "Valid AUROC: 0.8045812684795736\n",
            "[0.78409815 0.800731   0.9705221  ... 0.5        0.9914771  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5524655431509018\n",
            "Valid loss: 0.5766043492725917\n",
            "0.7280526\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7718593796690791\n",
            "Valid AUROC: 0.7837771207262733\n",
            "[0.5        0.83894837 0.9959269  ... 0.5        0.5        0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5488543653488159\n",
            "Valid loss: 0.5601579206330436\n",
            "0.60988784\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7732246686802281\n",
            "Valid AUROC: 0.8036840461416732\n",
            "[0.67755383 0.652856   0.99025726 ... 0.5        0.9935122  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5455130195617676\n",
            "Valid loss: 0.5641163843018668\n",
            "0.65193707\n",
            "Train AUROC: 0.7792148412141544\n",
            "Valid AUROC: 0.7975617373922459\n",
            "[0.7242685  0.8582367  0.99638605 ... 0.5        0.99356514 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5397944235801697\n",
            "Valid loss: 0.5567757657596043\n",
            "0.6310231\n",
            "BEST VALID LOSS\n",
            "Test AUROC result: 0.8070153896529142\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7149363817791877\n",
            "Valid AUROC: 0.7602931745304626\n",
            "[0.5       0.5       0.5       ... 0.5       0.8909671 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6028316855430603\n",
            "Valid loss: 0.5787088019507272\n",
            "0.6020552\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7360361084192764\n",
            "Valid AUROC: 0.7642710198642402\n",
            "[0.5        0.5        0.5        ... 0.5        0.94200075 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5795319640636444\n",
            "Valid loss: 0.574803182056972\n",
            "0.5272088\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7487150319693616\n",
            "Valid AUROC: 0.7795360846208303\n",
            "[0.5        0.84477425 0.5        ... 0.5        0.9063024  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5705055356025696\n",
            "Valid loss: 0.5747001341411045\n",
            "0.60874563\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7491590639943596\n",
            "Valid AUROC: 0.7804718277599633\n",
            "[0.5        0.72421104 0.9525814  ... 0.5        0.9574186  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5686734211444855\n",
            "Valid loss: 0.5737739716257367\n",
            "0.60717934\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7564107862197489\n",
            "Valid AUROC: 0.7833005038937243\n",
            "[0.5        0.77012134 0.97398835 ... 0.5        0.97959876 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.562550892829895\n",
            "Valid loss: 0.5731405360358102\n",
            "0.6513412\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7596737599259361\n",
            "Valid AUROC: 0.7859230416857534\n",
            "[0.5        0.83541715 0.941382   ... 0.5        0.9909361  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5589186871051788\n",
            "Valid loss: 0.5723934003285\n",
            "0.6593539\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7628918437344541\n",
            "Valid AUROC: 0.7792903843751301\n",
            "[0.5        0.84103596 0.9857671  ... 0.5        0.9779549  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5543679296970367\n",
            "Valid loss: 0.5625690817832947\n",
            "0.5864792\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7694845025677484\n",
            "Valid AUROC: 0.7933533919127139\n",
            "[0.5        0.6676995  0.9960758  ... 0.5        0.97217214 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5496846419572831\n",
            "Valid loss: 0.5749023130961827\n",
            "0.71389467\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7707735448392261\n",
            "Valid AUROC: 0.7960796235372507\n",
            "[0.5        0.79477865 0.9949326  ... 0.5        0.98248005 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.546805157661438\n",
            "Valid loss: 0.5671165840966361\n",
            "0.61839306\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7729035703208923\n",
            "Valid AUROC: 0.7955561570815808\n",
            "[0.5        0.7157971  0.99710304 ... 0.5        0.9895264  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5447411227226258\n",
            "Valid loss: 0.559637827532632\n",
            "0.57595325\n",
            "BEST VALID LOSS\n",
            "Test AUROC result: 0.8092810910772076\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.717782744419698\n",
            "Valid AUROC: 0.766172073460209\n",
            "[0.5       0.5       0.5938617 ... 0.5       0.9789379 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6011524045467377\n",
            "Valid loss: 0.575261652469635\n",
            "0.6300994\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7424075895277393\n",
            "Valid AUROC: 0.7724486736351144\n",
            "[0.5       0.7824176 0.930094  ... 0.5       0.9854489 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.577782793045044\n",
            "Valid loss: 0.5749039394514901\n",
            "0.65049165\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7452327459318712\n",
            "Valid AUROC: 0.7656165410402698\n",
            "[0.5        0.86367023 0.9659168  ... 0.5        0.9663354  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.572173936367035\n",
            "Valid loss: 0.5688270330429077\n",
            "0.6235956\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7514316862776605\n",
            "Valid AUROC: 0.767994419689335\n",
            "[0.5       0.8061513 0.9299625 ... 0.5       0.9811261 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5666378259658813\n",
            "Valid loss: 0.5671125820704869\n",
            "0.61516947\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7571842148381216\n",
            "Valid AUROC: 0.7757868654478826\n",
            "[0.5        0.8595221  0.9575804  ... 0.5        0.97327405 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5634513747692108\n",
            "Valid loss: 0.5649189608437675\n",
            "0.6264066\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.763635494421578\n",
            "Valid AUROC: 0.7847347270228626\n",
            "[0.5        0.821303   0.96989113 ... 0.5        0.98708445 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5578382050991059\n",
            "Valid loss: 0.5631050978388105\n",
            "0.65969366\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7682367561372992\n",
            "Valid AUROC: 0.7936076292008496\n",
            "[0.5        0.9141006  0.98673093 ... 0.5        0.9866981  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5534869849681854\n",
            "Valid loss: 0.574597452368055\n",
            "0.71998835\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7743021141224321\n",
            "Valid AUROC: 0.7969951692833049\n",
            "[0.5        0.8945406  0.989926   ... 0.5        0.98778987 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5484514224529267\n",
            "Valid loss: 0.5671050463403974\n",
            "0.7167626\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7737888248863942\n",
            "Valid AUROC: 0.790731270561779\n",
            "[0.5        0.9027188  0.9950631  ... 0.5        0.99513584 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5469564133882523\n",
            "Valid loss: 0.5581861053194318\n",
            "0.63790035\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7776465986892955\n",
            "Valid AUROC: 0.7945344188564527\n",
            "[0.5        0.8338784  0.99459296 ... 0.5        0.9948408  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5429378944635391\n",
            "Valid loss: 0.5625089066369193\n",
            "0.7036784\n",
            "Test AUROC result: 0.8399188994969715\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.49879316851870725\n",
            "Valid AUROC: 0.5\n",
            "[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6932522189617157\n",
            "Valid loss: 0.6931472335542951\n",
            "1.5\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.5198624205535245\n",
            "Valid AUROC: 0.7557489693082913\n",
            "[0.5        0.5        0.5        ... 0.5        0.8562772  0.69503987]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.685216270685196\n",
            "Valid loss: 0.6135359747069222\n",
            "0.7076647\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7401614017914745\n",
            "Valid AUROC: 0.7797191104818224\n",
            "[0.63911736 0.72788054 0.86456704 ... 0.5        0.9125686  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5860367155075074\n",
            "Valid loss: 0.5801715935979571\n",
            "0.68303955\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7509569126975316\n",
            "Valid AUROC: 0.7794561279307043\n",
            "[0.5        0.8717394  0.9444394  ... 0.5        0.92602414 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5724052929878235\n",
            "Valid loss: 0.5666120563234601\n",
            "0.6625391\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7557456578570717\n",
            "Valid AUROC: 0.7839157956107108\n",
            "[0.5        0.71957636 0.8985953  ... 0.5        0.9523137  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5671262896060943\n",
            "Valid loss: 0.5633284875324794\n",
            "0.5950762\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7631388504859089\n",
            "Valid AUROC: 0.7861393828342982\n",
            "[0.5       0.8386595 0.9497532 ... 0.5       0.5       0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5616450667381286\n",
            "Valid loss: 0.5613120368548802\n",
            "0.6320528\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7646895101304054\n",
            "Valid AUROC: 0.7969333277807854\n",
            "[0.5        0.8200168  0.93761635 ... 0.5        0.98668575 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5580561256408691\n",
            "Valid loss: 0.5604632156235831\n",
            "0.6478738\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7725760781868791\n",
            "Valid AUROC: 0.80484362636905\n",
            "[0.5        0.818629   0.9885415  ... 0.5        0.98268753 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.550746601819992\n",
            "Valid loss: 0.5678354842322213\n",
            "0.67067385\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.777435776665711\n",
            "Valid AUROC: 0.8041833590138674\n",
            "[0.6047677 0.8273586 0.9870396 ... 0.5       0.9757951 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.545493574142456\n",
            "Valid loss: 0.5605450698307582\n",
            "0.6732133\n",
            "Train AUROC: 0.7789334630405803\n",
            "Valid AUROC: 0.8082571940199059\n",
            "[0.58674705 0.86469764 0.9740142  ... 0.5        0.9863593  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5427174431085586\n",
            "Valid loss: 0.5661258186612811\n",
            "0.67524654\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.785859130975159\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7195078004539385\n",
            "Valid AUROC: 0.7772200474742847\n",
            "[0.5       0.5       0.5       ... 0.5       0.9489189 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5991727948188782\n",
            "Valid loss: 0.5736310311726162\n",
            "0.60534495\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7415949778788092\n",
            "Valid AUROC: 0.7764152750593428\n",
            "[0.5       0.7657688 0.9570789 ... 0.5       0.9486349 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5763679277896882\n",
            "Valid loss: 0.5685319900512695\n",
            "0.64248013\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7513908527156564\n",
            "Valid AUROC: 0.7840144921500855\n",
            "[0.5       0.8738745 0.9306187 ... 0.5       0.9425736 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5695390796661377\n",
            "Valid loss: 0.5669237204960415\n",
            "0.60523766\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n"
          ]
        }
      ],
      "source": [
        "sepsis_test_results, sepsis_actual_test_auroc_results, sepsis_final_threshold = diagnosis_cv_run_fun(model_data, model, sepsis_stays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save \n",
        "#with open(\"sepsis_cv_chronic_switch_test_results\", \"wb\") as fp:   #Pickling\n",
        "#    pickle.dump(sepsis_test_results, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1710838494808
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Load\n",
        "with open('sepsis_cv_chronic_switch_test_results', 'rb') as f:\n",
        "    sepsis_test_results = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1710838505845
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test_auroc: 0.8095139284960622\n",
            "std test_auroc: 0.013529437781517342\n",
            "test_auroc 2.5th percentile: 0.7893046516365265\n",
            "test_auroc 97.5th percentile: 0.8364267226872192\n",
            "mean test_accuracy: 0.746431068513224\n",
            "std test_accuracy: 0.0136024663712991\n",
            "test_accuracy 2.5th percentile: 0.7249372261663768\n",
            "test_accuracy 97.5th percentile: 0.7708383515925415\n",
            "mean test_balanced_accuracy: 0.7510976303660024\n",
            "std test_balanced_accuracy: 0.01318183474281759\n",
            "test_balanced_accuracy 2.5th percentile: 0.7276261792833661\n",
            "test_balanced_accuracy 97.5th percentile: 0.7736774906620348\n",
            "mean test_recall: 0.7116003617326493\n",
            "std test_recall: 0.026077891200200938\n",
            "test_recall 2.5th percentile: 0.6665079913180741\n",
            "test_recall 97.5th percentile: 0.751852700096432\n",
            "mean test_precision: 0.8075976581483342\n",
            "std test_precision: 0.02396834526175985\n",
            "test_precision 2.5th percentile: 0.7633167320428748\n",
            "test_precision 97.5th percentile: 0.8371279982232751\n",
            "mean test_f1: 0.7559673083225462\n",
            "std test_f1: 0.014195973538178062\n",
            "test_f1 2.5th percentile: 0.7333924302788845\n",
            "test_f1 97.5th percentile: 0.778982264519738\n",
            "mean test_auprc: 0.842222766322711\n",
            "std test_auprc: 0.016282520968714853\n",
            "test_auprc 2.5th percentile: 0.8155122797274099\n",
            "test_auprc 97.5th percentile: 0.869155383142107\n",
            "mean test_tpr: 0.7116003617326493\n",
            "std test_tpr: 0.026077891200200938\n",
            "test_tpr 2.5th percentile: 0.6665079913180741\n",
            "test_tpr 97.5th percentile: 0.751852700096432\n",
            "mean test_fpr: 0.20940510100064463\n",
            "std test_fpr: 0.026492123070083955\n",
            "test_fpr 2.5th percentile: 0.17030621586315434\n",
            "test_fpr 97.5th percentile: 0.25576723113487815\n"
          ]
        }
      ],
      "source": [
        "analyze_results_fun(sepsis_test_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "uti_test_results, uti_actual_test_auroc_results, uti_final_threshold = diagnosis_cv_run_fun(model_data, model, uti_stays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save \n",
        "#with open(\"uti_cv_chronic_switch_test_results\", \"wb\") as fp:   #Pickling\n",
        "#    pickle.dump(uti_test_results, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1710838554492
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Load\n",
        "with open('uti_cv_chronic_switch_test_results', 'rb') as f:\n",
        "    uti_test_results = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1710838556194
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test_auroc: 0.8031066059431886\n",
            "std test_auroc: 0.027938443281141888\n",
            "test_auroc 2.5th percentile: 0.756808151188022\n",
            "test_auroc 97.5th percentile: 0.8423909265003009\n",
            "mean test_accuracy: 0.7223024529416877\n",
            "std test_accuracy: 0.017710411680584272\n",
            "test_accuracy 2.5th percentile: 0.6908197650502712\n",
            "test_accuracy 97.5th percentile: 0.7495339412360689\n",
            "mean test_balanced_accuracy: 0.7350152510003166\n",
            "std test_balanced_accuracy: 0.017723902469494707\n",
            "test_balanced_accuracy 2.5th percentile: 0.7022129816376297\n",
            "test_balanced_accuracy 97.5th percentile: 0.7576175521697958\n",
            "mean test_recall: 0.6772688631299217\n",
            "std test_recall: 0.044444572216346484\n",
            "test_recall 2.5th percentile: 0.6161141718595384\n",
            "test_recall 97.5th percentile: 0.7472277716475986\n",
            "mean test_precision: 0.8329803759667194\n",
            "std test_precision: 0.0382031356335541\n",
            "test_precision 2.5th percentile: 0.7832495496627707\n",
            "test_precision 97.5th percentile: 0.8948313866941486\n",
            "mean test_f1: 0.7454736856718482\n",
            "std test_f1: 0.024583503423787886\n",
            "test_f1 2.5th percentile: 0.7023793985590477\n",
            "test_f1 97.5th percentile: 0.7793797287970964\n",
            "mean test_auprc: 0.8616084493960031\n",
            "std test_auprc: 0.028719806534040642\n",
            "test_auprc 2.5th percentile: 0.8090191092340905\n",
            "test_auprc 97.5th percentile: 0.9044527763477396\n",
            "mean test_tpr: 0.6772688631299217\n",
            "std test_tpr: 0.044444572216346484\n",
            "test_tpr 2.5th percentile: 0.6161141718595384\n",
            "test_tpr 97.5th percentile: 0.7472277716475986\n",
            "mean test_fpr: 0.20723836112928842\n",
            "std test_fpr: 0.05037041054216716\n",
            "test_fpr 2.5th percentile: 0.13628460777851023\n",
            "test_fpr 97.5th percentile: 0.2885835913312694\n"
          ]
        }
      ],
      "source": [
        "analyze_results_fun(uti_test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Bad bio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1710838765774
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/antibiotics.csv'\n",
        "antibiotics_df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1710838799413
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define antibiotics with bad bioavailability\n",
        "pattern = 'Azithromycin|Ciprofloxacin|Cefpodoxime|Clindamycin|Amoxicillin|Clarithromycin|Nitrofurantoin|Ampicillin|Erythromycin|Penicillin|DiCLOXacillin|Tetracycline|Neomycin|Augmentin|flucloxacillin'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1710838815873
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Filter for those patients with bad bioavailability drugs\n",
        "filtered_antibiotics_df = antibiotics_df[antibiotics_df['ROUTE'] == 'PO']\n",
        "filtered_antibiotics_df = filtered_antibiotics_df[filtered_antibiotics_df['antibiotics'].str.contains(pattern, case=False, na=False)]\n",
        "# Define stay list\n",
        "bad_bio_stay_id_list = filtered_antibiotics_df.SPELL_IDENTIFIER.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1710838945415
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/chronic_switch_icare_df_preprocessed.csv'\n",
        "icare_df_preprocessed = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_episodes.csv'\n",
        "episodes = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_disease.csv'\n",
        "disease = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_demographics.csv'\n",
        "demographics = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/snomed_embedding_128d-copy.csv'\n",
        "embedding = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_problem_dummies.csv'\n",
        "problem_dummies = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1710844636075
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5610"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "icare_df_preprocessed.SPELL_IDENTIFIER.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1710838972783
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Merge\n",
        "problem_dummies2 = pd.merge(problem_dummies, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "problem_dummies2 = pd.merge(icare_df_preprocessed[['SPELL_IDENTIFIER', 'date']], problem_dummies2)\n",
        "\n",
        "# Strip name \n",
        "problem_dummies2.columns = problem_dummies2.columns.str.removeprefix('PROBLEM_')\n",
        "\n",
        "# Convert the date columns to datetime objects if they are not already\n",
        "problem_dummies2['date'] = pd.to_datetime(problem_dummies2['date'])\n",
        "problem_dummies2['DT_TM'] = pd.to_datetime(problem_dummies2['DT_TM'])\n",
        "\n",
        "# Calculate the absolute time difference between 'date' and 'DT_TM'\n",
        "problem_dummies2['time_diff'] = (problem_dummies2['date'] - problem_dummies2['DT_TM']).abs()\n",
        "\n",
        "# Filter rows where 'time_diff' is not negative\n",
        "problem_dummies2 = problem_dummies2[problem_dummies2['time_diff'] >= pd.Timedelta(0)]\n",
        "\n",
        "# Sort the DataFrame by 'SPELL_IDENTIFIER' and 'time_diff'\n",
        "problem_dummies2.sort_values(by=['SPELL_IDENTIFIER', 'time_diff'], inplace=True)\n",
        "\n",
        "# Convert to str\n",
        "problem_dummies2['date'] = problem_dummies2['date'].astype(str)\n",
        "\n",
        "# Keep only the rows with the smallest time difference for each 'SPELL_IDENTIFIER'\n",
        "problem_dummies2 = problem_dummies2.groupby(['SPELL_IDENTIFIER', 'date']).first().reset_index()\n",
        "\n",
        "### REASON the problem_dummies2 is shorter is not because it is missing some dates! \n",
        "### It is because in the final data we have some dates repeated for a spesfic spell \n",
        "### if they were admited in between 6am and 12pm the 12hour prediction is done at 6am \n",
        "### of the first day, then 48 done at 6am the next day, then the next prediction done \n",
        "### at 12pm that day causing there to be two prediction for that day...phew\n",
        "### So just get a set of co-morbidities for each spell and merge \n",
        "\n",
        "# Drop the 'time_diff' column as it's no longer needed\n",
        "problem_dummies2.drop(columns=['time_diff', 'SUBJECT', 'DT_TM', 'new_subject', 'date'], inplace=True)\n",
        "\n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(inplace=True)\n",
        "\n",
        "# Some still got through by having their co-morbidid diagnosis updated during their stay \n",
        "# In this case we just use the frst one throughout and remove the others \n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(subset=['SPELL_IDENTIFIER'], keep='first', inplace=True)\n",
        "\n",
        "# Filter for features\n",
        "X_data = icare_df_preprocessed.drop(columns=['SPELL_IDENTIFIER', 'po_flag'])\n",
        "X_data = X_data.drop(columns=columns_to_drop)\n",
        "model_data = pd.concat([icare_df_preprocessed[['SPELL_IDENTIFIER', 'po_flag']], X_data], axis=1)\n",
        "# Merge\n",
        "demographics = pd.merge(demographics, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "demographics.drop(columns=['SUBJECT'], inplace=True)\n",
        "model_data = pd.merge(model_data, demographics, how='left')\n",
        "model_data = pd.merge(model_data, disease, how='left')\n",
        "# Drop \n",
        "model_data = model_data.drop(columns=['date', 'ROUTE', '24_hour_flag', '48_hour_flag', 'iv_treatment_length'])\n",
        "# fillna\n",
        "model_data['AGE'] = model_data['AGE'].fillna(-1)\n",
        "model_data['IMDDECIL'] = model_data['IMDDECIL'].fillna(-1)\n",
        "model_data = model_data.fillna(0)\n",
        "# Merge co-morbidites\n",
        "model_data = pd.merge(model_data, problem_dummies2, how='left')\n",
        "# Rename\n",
        "model_data.rename(columns={'SPELL_IDENTIFIER': 'stay_id'}, inplace=True)\n",
        "# Random shuffle\n",
        "stays = model_data['stay_id'].unique()\n",
        "random.Random(5).shuffle(stays)\n",
        "model_data = model_data.set_index(\"stay_id\").loc[stays].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1710844666908
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5610"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_data.stay_id.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1710839031129
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4116/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Chronic_switch_model(\n",
              "  (final_layers): Sequential(\n",
              "    (0): Linear(in_features=268, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.1, inplace=False)\n",
              "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (vital_model): Initial_vitals_model(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(253, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Linear(in_features=253, out_features=512, bias=True)\n",
              "      (2): ReLU()\n",
              "      (3): Dropout(p=0.1, inplace=False)\n",
              "      (4): Linear(in_features=512, out_features=128, bias=True)\n",
              "      (5): ReLU()\n",
              "      (6): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (set_transformer): SetTransformer(\n",
              "    (enc): Sequential(\n",
              "      (0): ISAB(\n",
              "        (mab0): MAB0(\n",
              "          (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_k): Linear(in_features=128, out_features=160, bias=True)\n",
              "          (fc_v): Linear(in_features=128, out_features=160, bias=True)\n",
              "          (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "        )\n",
              "        (mab1): MAB(\n",
              "          (fc_q): Linear(in_features=128, out_features=160, bias=True)\n",
              "          (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (1): ISAB(\n",
              "        (mab0): MAB0(\n",
              "          (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "        )\n",
              "        (mab1): MAB(\n",
              "          (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (isab): ISAB(\n",
              "      (mab0): MAB0(\n",
              "        (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_k): Linear(in_features=128, out_features=160, bias=True)\n",
              "        (fc_v): Linear(in_features=128, out_features=160, bias=True)\n",
              "        (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "      )\n",
              "      (mab1): MAB(\n",
              "        (fc_q): Linear(in_features=128, out_features=160, bias=True)\n",
              "        (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (pma): PMA(\n",
              "      (mab): MAB0(\n",
              "        (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (dec): Sequential(\n",
              "      (0): Linear(in_features=160, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (demographics): Linear(in_features=12, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 1,126,583 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "final_input_dim = 268\n",
        "final_output_dim = 1\n",
        "final_hid_dim = 512\n",
        "final_hid_dim2 = 128\n",
        "demographics_input_dim = 12\n",
        "demographics_output_dim = 12\n",
        "vital_input_dim = 253\n",
        "vital_hid_dim = 512\n",
        "vital_output_dim = 128\n",
        "dropout = 0.1\n",
        "\n",
        "# Define model\n",
        "model = Chronic_switch_model(\n",
        "    final_input_dim, \n",
        "    final_output_dim, \n",
        "    final_hid_dim, \n",
        "    final_hid_dim2,\n",
        "    demographics_input_dim,\n",
        "    demographics_output_dim,\n",
        "    vital_input_dim, \n",
        "    vital_hid_dim, \n",
        "    vital_output_dim, \n",
        "    dropout).to(device)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1710843871318
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4116/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.20it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.23it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.16it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.17it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.18it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.19it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.21it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.21it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.21it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 5/5 [00:02<00:00,  2.31it/s]\n",
            "/tmp/ipykernel_4116/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.21it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.25it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.84it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.22it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.25it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.21it/s]\n",
            "100%|| 4/4 [00:02<00:00,  1.96it/s]\n",
            "/tmp/ipykernel_4116/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.25it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.25it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.22it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.25it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.26it/s]\n",
            "100%|| 4/4 [00:01<00:00,  2.05it/s]\n",
            "/tmp/ipykernel_4116/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.22it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.04it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.22it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.21it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.22it/s]\n",
            "100%|| 5/5 [00:02<00:00,  2.35it/s]\n",
            "/tmp/ipykernel_4116/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.19it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.22it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.23it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 4/4 [00:01<00:00,  2.12it/s]\n",
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/tmp/ipykernel_4116/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.26it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.13it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.20it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.22it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.22it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.22it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.26it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.25it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.26it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.22it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.31it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.24it/s]\n",
            "100%|| 5/5 [00:02<00:00,  2.46it/s]\n",
            "/tmp/ipykernel_4116/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.32it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.31it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.33it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.28it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.29it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.30it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.30it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.27it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.30it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.29it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 4/4 [00:01<00:00,  2.09it/s]\n",
            "/tmp/ipykernel_4116/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:38<00:00,  1.29it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.30it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.29it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.31it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.32it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.30it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.29it/s]\n",
            "100%|| 7/7 [00:02<00:00,  2.34it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.29it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.31it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.32it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.29it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.26it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.29it/s]\n",
            "100%|| 4/4 [00:01<00:00,  2.07it/s]\n",
            "/tmp/ipykernel_4116/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.31it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.30it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.30it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.32it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.29it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.31it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.30it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.11it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.31it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.28it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.29it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.29it/s]\n",
            "100%|| 4/4 [00:01<00:00,  2.03it/s]\n",
            "/tmp/ipykernel_4116/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:38<00:00,  1.29it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.29it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.27it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.32it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.29it/s]\n",
            "100%|| 50/50 [00:40<00:00,  1.24it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.26it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.29it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.30it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.27it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.31it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:02<00:00,  2.34it/s]\n",
            "100%|| 50/50 [00:38<00:00,  1.30it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.31it/s]\n",
            "100%|| 50/50 [00:39<00:00,  1.28it/s]\n",
            "100%|| 7/7 [00:03<00:00,  2.32it/s]\n",
            "100%|| 4/4 [00:01<00:00,  2.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7282084972158595\n",
            "Valid AUROC: 0.7919493400422166\n",
            "[0.5       0.5       0.5       ... 0.7458981 0.5095525 0.5      ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5947360348701477\n",
            "Valid loss: 0.5651802335466657\n",
            "0.5924756\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7491536794203698\n",
            "Valid AUROC: 0.792919339233884\n",
            "[0.5        0.5590289  0.73691523 ... 0.7553793  0.5        0.59409684]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5737382161617279\n",
            "Valid loss: 0.5587632570947919\n",
            "0.63012135\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7564256703021439\n",
            "Valid AUROC: 0.7970443357963868\n",
            "[0.5        0.5        0.83671963 ... 0.7959285  0.5373942  0.6495511 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5675568413734436\n",
            "Valid loss: 0.5551360079220363\n",
            "0.5894195\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7615356896172687\n",
            "Valid AUROC: 0.8081001599165334\n",
            "[0.5        0.5        0.8201851  ... 0.8589042  0.53524745 0.5238043 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5619715225696563\n",
            "Valid loss: 0.5530407769339425\n",
            "0.6623686\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7624091495566728\n",
            "Valid AUROC: 0.8029522475397938\n",
            "[0.5       0.6420573 0.87203   ... 0.8208659 0.5       0.7727416]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5600967967510223\n",
            "Valid loss: 0.548548025744302\n",
            "0.58699894\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7721500848102959\n",
            "Valid AUROC: 0.812208073159939\n",
            "[0.5        0.5        0.68837225 ... 0.7721364  0.5        0.66490525]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.552048374414444\n",
            "Valid loss: 0.5478676983288356\n",
            "0.63533473\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7766489387001412\n",
            "Valid AUROC: 0.8178132768222693\n",
            "[0.5        0.5        0.5        ... 0.7382683  0.5        0.78093785]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5487138354778289\n",
            "Valid loss: 0.5486898592540196\n",
            "0.7090227\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7792866735146902\n",
            "Valid AUROC: 0.817818068484943\n",
            "[0.5        0.55085707 0.7581945  ... 0.8146424  0.5670402  0.835394  ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5443668061494827\n",
            "Valid loss: 0.5460380826677594\n",
            "0.655398\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7824584480336033\n",
            "Valid AUROC: 0.8226509811241823\n",
            "[0.5625803  0.5        0.810235   ... 0.85051155 0.6504338  0.8136739 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5401688998937607\n",
            "Valid loss: 0.5575010265622821\n",
            "0.7130929\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7848954918972741\n",
            "Valid AUROC: 0.8254341038049136\n",
            "[0.5023761  0.5        0.8839322  ... 0.69351673 0.7043911  0.9126671 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5357483887672424\n",
            "Valid loss: 0.5664443288530622\n",
            "0.7729795\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.8109452600556677\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7188514111749085\n",
            "Valid AUROC: 0.7740119935035189\n",
            "[0.53567696 0.5870517  0.5        ... 0.55592895 0.5        0.78475016]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.604602564573288\n",
            "Valid loss: 0.5686282770974296\n",
            "0.5238429\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7360897434378253\n",
            "Valid AUROC: 0.7760567192770582\n",
            "[0.5        0.5        0.5        ... 0.50576746 0.9253507  0.67278194]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5818394100666047\n",
            "Valid loss: 0.562802152974265\n",
            "0.50446296\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7415750701205044\n",
            "Valid AUROC: 0.7949148377961938\n",
            "[0.5        0.5582484  0.5        ... 0.53947735 0.94510007 0.7483587 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5757196009159088\n",
            "Valid loss: 0.5519741433007377\n",
            "0.54826355\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7487512314173403\n",
            "Valid AUROC: 0.7836850872444093\n",
            "[0.5        0.63950574 0.5        ... 0.5253516  0.8896881  0.770294  ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5689869546890258\n",
            "Valid loss: 0.5565719178744725\n",
            "0.52028\n",
            "Train AUROC: 0.7484449478091558\n",
            "Valid AUROC: 0.7997139049681423\n",
            "[0.5      0.515301 0.5      ... 0.5      0.5      0.5     ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5677298879623414\n",
            "Valid loss: 0.5487312248774937\n",
            "0.5130366\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7555161292069991\n",
            "Valid AUROC: 0.7983369424894848\n",
            "[0.5        0.54313195 0.5        ... 0.5        0.9017833  0.7167005 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5638976788520813\n",
            "Valid loss: 0.546769346509661\n",
            "0.5353088\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7601627951498401\n",
            "Valid AUROC: 0.8076829217507184\n",
            "[0.5       0.5       0.5       ... 0.5       0.9186054 0.6043036]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5580271828174591\n",
            "Valid loss: 0.5426744222640991\n",
            "0.613821\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7683194937046829\n",
            "Valid AUROC: 0.8131097738724858\n",
            "[0.5        0.59398866 0.5        ... 0.5        0.8861126  0.6956792 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.553256276845932\n",
            "Valid loss: 0.541070648602077\n",
            "0.6485405\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7696468767620627\n",
            "Valid AUROC: 0.8175725648607004\n",
            "[0.5        0.5        0.5        ... 0.5        0.86540073 0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5503359615802765\n",
            "Valid loss: 0.5403005736214774\n",
            "0.58294934\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7744147116710537\n",
            "Valid AUROC: 0.8141310956565194\n",
            "[0.5        0.6469252  0.5        ... 0.5        0.8753076  0.56336874]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5459573936462402\n",
            "Valid loss: 0.5385814138821193\n",
            "0.625414\n",
            "BEST VALID LOSS\n",
            "Test AUROC result: 0.7826007819740615\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7205866949189598\n",
            "Valid AUROC: 0.7901782367884063\n",
            "[0.6205471  0.68465424 0.6487868  ... 0.5        0.88896877 0.5       ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.6040735900402069\n",
            "Valid loss: 0.5648812055587769\n",
            "0.5597164\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7391610272633394\n",
            "Valid AUROC: 0.7994038645733561\n",
            "[0.5        0.6944449  0.5        ... 0.5        0.88206106 0.7639229 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5815909743309021\n",
            "Valid loss: 0.5515628371919904\n",
            "0.6016445\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7480884920909717\n",
            "Valid AUROC: 0.7920540956981634\n",
            "[0.5        0.7001089  0.5        ... 0.5        0.87355965 0.86247385]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5754177451133728\n",
            "Valid loss: 0.5570515990257263\n",
            "0.5175806\n",
            "Train AUROC: 0.7504991916599865\n",
            "Valid AUROC: 0.808709449048432\n",
            "[0.5        0.6239391  0.5        ... 0.5        0.91098356 0.82908744]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5713974559307098\n",
            "Valid loss: 0.545817528452192\n",
            "0.5722859\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7572229445431898\n",
            "Valid AUROC: 0.8127955690667555\n",
            "[0.5        0.76086813 0.5        ... 0.5        0.87386775 0.7834303 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5659535586833954\n",
            "Valid loss: 0.5438057695116315\n",
            "0.60895354\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7624015579058679\n",
            "Valid AUROC: 0.8077936950818307\n",
            "[0.5        0.64592016 0.5        ... 0.5        0.88639975 0.8010257 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5605500960350036\n",
            "Valid loss: 0.5434840406690326\n",
            "0.5638876\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7686847194504001\n",
            "Valid AUROC: 0.805858909757215\n",
            "[0.5       0.7030616 0.5       ... 0.5       0.8978327 0.5      ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5562778413295746\n",
            "Valid loss: 0.5443759730884007\n",
            "0.5219813\n",
            "Train AUROC: 0.7704926277468773\n",
            "Valid AUROC: 0.8242416607670844\n",
            "[0.5        0.58591807 0.5        ... 0.5        0.87851584 0.84571224]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5511190897226333\n",
            "Valid loss: 0.541528446333749\n",
            "0.6667883\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7769735153241875\n",
            "Valid AUROC: 0.824929413234498\n",
            "[0.5        0.64963084 0.5        ... 0.5        0.90595657 0.8124337 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.547693874835968\n",
            "Valid loss: 0.5349117176873344\n",
            "0.58553755\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7819012193059781\n",
            "Valid AUROC: 0.8221513346937076\n",
            "[0.5        0.5676069  0.5        ... 0.5        0.86015224 0.88202375]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5435156559944153\n",
            "Valid loss: 0.5351135219846453\n",
            "0.6199554\n",
            "Test AUROC result: 0.784365562886034\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7197542877882126\n",
            "Valid AUROC: 0.7859459459459459\n",
            "[0.6491146  0.5636965  0.7227836  ... 0.5        0.89324844 0.7123592 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.6039306378364563\n",
            "Valid loss: 0.5646118436540876\n",
            "0.5964873\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7396613127352232\n",
            "Valid AUROC: 0.8004414275600715\n",
            "[0.5        0.65914243 0.5        ... 0.5        0.8589634  0.86695725]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5787761867046356\n",
            "Valid loss: 0.5561023865427289\n",
            "0.6204566\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7470828590117872\n",
            "Valid AUROC: 0.7915225086411528\n",
            "[0.5       0.7779449 0.5       ... 0.5       0.9031741 0.7865194]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5753767478466034\n",
            "Valid loss: 0.5605135900633675\n",
            "0.50099653\n",
            "Train AUROC: 0.7524790204924878\n",
            "Valid AUROC: 0.8014292258360054\n",
            "[0.5        0.5        0.5        ... 0.5        0.85759294 0.76947397]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5703812515735627\n",
            "Valid loss: 0.5522031017712185\n",
            "0.56322503\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7594066618665687\n",
            "Valid AUROC: 0.8023058343397326\n",
            "[0.5        0.6788495  0.5        ... 0.5        0.91433036 0.8587217 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5657097625732422\n",
            "Valid loss: 0.5484356369291034\n",
            "0.5789331\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7624990829559182\n",
            "Valid AUROC: 0.8143611793611795\n",
            "[0.5        0.56648904 0.5        ... 0.5        0.88922405 0.80955744]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5593409252166748\n",
            "Valid loss: 0.5458050199917385\n",
            "0.64366925\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7675405075657016\n",
            "Valid AUROC: 0.8201915629034274\n",
            "[0.5        0.63179874 0.5        ... 0.5        0.8730781  0.90962064]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5559675234556198\n",
            "Valid loss: 0.5503668870244708\n",
            "0.64932114\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7703986771178484\n",
            "Valid AUROC: 0.8108920168242201\n",
            "[0.5        0.79321426 0.5        ... 0.5        0.8461165  0.8904687 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5526644611358642\n",
            "Valid loss: 0.5409922344344003\n",
            "0.5837976\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7767577381397128\n",
            "Valid AUROC: 0.8199770957398076\n",
            "[0.5       0.6914146 0.5       ... 0.5       0.5       0.8622957]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.549158616065979\n",
            "Valid loss: 0.5393296820776803\n",
            "0.6291702\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7803641303712316\n",
            "Valid AUROC: 0.8205992587348521\n",
            "[0.5       0.6451194 0.5       ... 0.5       0.9386506 0.868804 ]\n",
            "[0. 0. 0. ... 0. 1. 1.]\n",
            "Train loss: 0.5439878851175308\n",
            "Valid loss: 0.534640201500484\n",
            "0.594372\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.773453754699797\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.4991228320619412\n",
            "Valid AUROC: 0.5\n",
            "[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6931439650058746\n",
            "Valid loss: 0.6931472335542951\n",
            "1.5\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.4997929608512497\n",
            "Valid AUROC: 0.5\n",
            "[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.693152232170105\n",
            "Valid loss: 0.6931472335542951\n",
            "1.5\n",
            "Train AUROC: 0.5\n",
            "Valid AUROC: 0.5\n",
            "[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6931472408771515\n",
            "Valid loss: 0.6931472335542951\n",
            "1.5\n",
            "Train AUROC: 0.49998563353989284\n",
            "Valid AUROC: 0.5\n",
            "[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6931462895870208\n",
            "Valid loss: 0.6931472335542951\n",
            "1.5\n",
            "Train AUROC: 0.4999518350833253\n",
            "Valid AUROC: 0.5\n",
            "[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.693147406578064\n",
            "Valid loss: 0.6931472335542951\n",
            "1.5\n",
            "Train AUROC: 0.4999518350833253\n",
            "Valid AUROC: 0.5\n",
            "[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6931486225128174\n",
            "Valid loss: 0.6931472335542951\n",
            "1.5\n",
            "Train AUROC: 0.5\n",
            "Valid AUROC: 0.5\n",
            "[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6931472408771515\n",
            "Valid loss: 0.6931472335542951\n",
            "1.5\n",
            "Train AUROC: 0.5\n",
            "Valid AUROC: 0.5\n",
            "[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6931472408771515\n",
            "Valid loss: 0.6931472335542951\n",
            "1.5\n",
            "Train AUROC: 0.4999518350833253\n",
            "Valid AUROC: 0.5\n",
            "[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6931475353240967\n",
            "Valid loss: 0.6931472335542951\n",
            "1.5\n",
            "Train AUROC: 0.5\n",
            "Valid AUROC: 0.5\n",
            "[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6931472408771515\n",
            "Valid loss: 0.6931472335542951\n",
            "1.5\n",
            "Test AUROC result: 0.5\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7157783090803418\n",
            "Valid AUROC: 0.7756723441469202\n",
            "[0.5       0.5       0.5       ... 0.5       0.9502676 0.5638498]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.597820235490799\n",
            "Valid loss: 0.5732446738651821\n",
            "0.6394219\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7490550023815508\n",
            "Valid AUROC: 0.7795452463249073\n",
            "[0.5       0.804028  0.8814885 ... 0.5       0.5       0.5783212]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5747519278526306\n",
            "Valid loss: 0.5686460052217756\n",
            "0.64513123\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7559834450719248\n",
            "Valid AUROC: 0.7894448840211552\n",
            "[0.5        0.86139596 0.84543335 ... 0.5        0.5        0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5667550575733185\n",
            "Valid loss: 0.5691256437982831\n",
            "0.70474637\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7624579362711904\n",
            "Valid AUROC: 0.7929773456044643\n",
            "[0.5        0.916982   0.97814536 ... 0.5        0.96126896 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.561620284318924\n",
            "Valid loss: 0.5670409628323146\n",
            "0.6010886\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7699950702174169\n",
            "Valid AUROC: 0.7931385083079999\n",
            "[0.5        0.80686295 0.975198   ... 0.5        0.96804875 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5555462008714676\n",
            "Valid loss: 0.5606407948902675\n",
            "0.64380044\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7724965824720917\n",
            "Valid AUROC: 0.7901711572898014\n",
            "[0.5        0.5        0.9590497  ... 0.5        0.98787105 0.5915864 ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5523560881614685\n",
            "Valid loss: 0.5568191749708993\n",
            "0.6308555\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7788722533911501\n",
            "Valid AUROC: 0.7922179652688127\n",
            "[0.5        0.85083115 0.9718178  ... 0.5        0.9590273  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5456987476348877\n",
            "Valid loss: 0.5555002604212079\n",
            "0.6291065\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7799492788756488\n",
            "Valid AUROC: 0.8061579144629992\n",
            "[0.5        0.5        0.9839422  ... 0.5        0.99133897 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5434382444620133\n",
            "Valid loss: 0.5647859232766288\n",
            "0.71287036\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7854933814502857\n",
            "Valid AUROC: 0.8052271686169992\n",
            "[0.5        0.83434725 0.98300505 ... 0.5        0.9858876  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5382438528537751\n",
            "Valid loss: 0.5571147458893912\n",
            "0.68534756\n",
            "Train AUROC: 0.7868764258825597\n",
            "Valid AUROC: 0.8085945113063757\n",
            "[0.5       0.8614324 0.9834953 ... 0.5       0.9910001 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5358239394426346\n",
            "Valid loss: 0.5645000338554382\n",
            "0.76056206\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7877887757063232\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7269785875936875\n",
            "Valid AUROC: 0.7604418440011661\n",
            "[0.5        0.5284412  0.5        ... 0.5        0.89610404 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5997241795063019\n",
            "Valid loss: 0.5786432794162205\n",
            "0.56394374\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7410955993348259\n",
            "Valid AUROC: 0.7663569733061257\n",
            "[0.5        0.8500338  0.5        ... 0.5        0.953912   0.52561736]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5791155505180359\n",
            "Valid loss: 0.5739377822194781\n",
            "0.5833961\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7462763180413275\n",
            "Valid AUROC: 0.7675919293715903\n",
            "[0.5        0.74805325 0.945714   ... 0.5        0.9780477  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5730691373348236\n",
            "Valid loss: 0.5713633298873901\n",
            "0.6080989\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.752740827920247\n",
            "Valid AUROC: 0.7768592012659808\n",
            "[0.5        0.7488413  0.95286113 ... 0.5        0.9694818  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5671724569797516\n",
            "Valid loss: 0.5712919660976955\n",
            "0.6388299\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7557627914803539\n",
            "Valid AUROC: 0.7781901470037063\n",
            "[0.5        0.8216827  0.9078182  ... 0.5        0.987528   0.52282137]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.564875146150589\n",
            "Valid loss: 0.566478431224823\n",
            "0.60197324\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7632090778318033\n",
            "Valid AUROC: 0.784900678798984\n",
            "[0.5       0.5       0.9726351 ... 0.5       0.9678573 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5599350833892822\n",
            "Valid loss: 0.5674119591712952\n",
            "0.665633\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7639493265359653\n",
            "Valid AUROC: 0.7796447757464706\n",
            "[0.5        0.8402962  0.5        ... 0.5        0.96167296 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5566496539115906\n",
            "Valid loss: 0.5638090797833034\n",
            "0.5840598\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7649210403009972\n",
            "Valid AUROC: 0.7802960896181236\n",
            "[0.5       0.7772843 0.9865218 ... 0.5       0.5       0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5541128718852997\n",
            "Valid loss: 0.5617136018616813\n",
            "0.5490836\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7741331674163998\n",
            "Valid AUROC: 0.7870924082788491\n",
            "[0.5        0.8189531  0.97460073 ... 0.5        0.9951676  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5475956147909165\n",
            "Valid loss: 0.5619255900382996\n",
            "0.6724987\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7768092876674146\n",
            "Valid AUROC: 0.7955765626952069\n",
            "[0.5       0.7833669 0.9910512 ... 0.5       0.9938211 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5445287322998047\n",
            "Valid loss: 0.5687133073806763\n",
            "0.6746691\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7868392309053521\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7126859000567725\n",
            "Valid AUROC: 0.775089951276392\n",
            "[0.5       0.5       0.5       ... 0.5       0.8885946 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5999370515346527\n",
            "Valid loss: 0.5781970620155334\n",
            "0.7347745\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7414962227083242\n",
            "Valid AUROC: 0.7635001873984927\n",
            "[0.5        0.88452363 0.9382078  ... 0.5        0.9421438  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5763165879249573\n",
            "Valid loss: 0.5692439760480609\n",
            "0.6277574\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7475899424882573\n",
            "Valid AUROC: 0.779866947070337\n",
            "[0.5        0.9059294  0.8726871  ... 0.5        0.97047746 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5709305608272552\n",
            "Valid loss: 0.5723634191921779\n",
            "0.6616868\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7548880814342916\n",
            "Valid AUROC: 0.7806265356265358\n",
            "[0.5        0.8346565  0.93464625 ... 0.5        0.9616658  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5659793448448182\n",
            "Valid loss: 0.570716210774013\n",
            "0.668312\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7598690011931031\n",
            "Valid AUROC: 0.7815743555574064\n",
            "[0.5        0.815484   0.96926326 ... 0.5        0.5        0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5615791022777558\n",
            "Valid loss: 0.5623350058283124\n",
            "0.6745521\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7653202052167277\n",
            "Valid AUROC: 0.7948636155415816\n",
            "[0.5       0.8109432 0.978967  ... 0.5       0.969712  0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5566174221038819\n",
            "Valid loss: 0.5740052461624146\n",
            "0.752962\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7693842010413714\n",
            "Valid AUROC: 0.7991500437263148\n",
            "[0.5        0.8871912  0.9870947  ... 0.5        0.98750347 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5534416836500168\n",
            "Valid loss: 0.5738781435149056\n",
            "0.77195704\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7725816971558673\n",
            "Valid AUROC: 0.7941073585141383\n",
            "[0.5        0.90994436 0.9594189  ... 0.5        0.97779036 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5484319496154785\n",
            "Valid loss: 0.5577606984547206\n",
            "0.71839947\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.77525891776118\n",
            "Valid AUROC: 0.8003706325740223\n",
            "[0.5        0.8729761  0.9846156  ... 0.5        0.98559475 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5456870394945145\n",
            "Valid loss: 0.5645303045000348\n",
            "0.74761033\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7800379029734276\n",
            "Valid AUROC: 0.8068083954524633\n",
            "[0.5       0.8952818 0.9788905 ... 0.5       0.9910007 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5412167686223984\n",
            "Valid loss: 0.5668900779315403\n",
            "0.79207385\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7710056025845499\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.7199626569701798\n",
            "Valid AUROC: 0.7701611627035355\n",
            "[0.50537956 0.5        0.5        ... 0.5        0.9433892  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6008523869514465\n",
            "Valid loss: 0.5718607221330915\n",
            "0.62136465\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7398844803783552\n",
            "Valid AUROC: 0.7656394453004622\n",
            "[0.5        0.8171614  0.95321226 ... 0.5        0.96427065 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5779005634784699\n",
            "Valid loss: 0.5687597479139056\n",
            "0.6241274\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7467352113603183\n",
            "Valid AUROC: 0.7847969849664764\n",
            "[0.5       0.837764  0.9560324 ... 0.5       0.969971  0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5718542993068695\n",
            "Valid loss: 0.5673904504094806\n",
            "0.6795158\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7547216577299777\n",
            "Valid AUROC: 0.7938412526548121\n",
            "[0.5       0.5       0.9570317 ... 0.5       0.973578  0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5660719895362853\n",
            "Valid loss: 0.5716091990470886\n",
            "0.67103225\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7567510691586025\n",
            "Valid AUROC: 0.7981064423437305\n",
            "[0.5        0.93289304 0.9808919  ... 0.5        0.9684484  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5627400255203248\n",
            "Valid loss: 0.5685346722602844\n",
            "0.6232233\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7622284831007229\n",
            "Valid AUROC: 0.7942547786615581\n",
            "[0.5        0.84862304 0.97726816 ... 0.5        0.9900602  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5581150484085083\n",
            "Valid loss: 0.5586455294064113\n",
            "0.6532515\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7664682426192677\n",
            "Valid AUROC: 0.7959698913088744\n",
            "[0.5        0.81583613 0.93501306 ... 0.5        0.986024   0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5547253400087356\n",
            "Valid loss: 0.5563070433480399\n",
            "0.62031454\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7710254576082161\n",
            "Valid AUROC: 0.8047007870736685\n",
            "[0.5        0.82954764 0.9947462  ... 0.5        0.9831803  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5503109991550446\n",
            "Valid loss: 0.5606883338519505\n",
            "0.6063812\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7737827534048397\n",
            "Valid AUROC: 0.806144380127431\n",
            "[0.5        0.8588239  0.9968951  ... 0.5        0.98767495 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5473024123907089\n",
            "Valid loss: 0.5598165392875671\n",
            "0.66397816\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7779406797695858\n",
            "Valid AUROC: 0.8057556323658018\n",
            "[0.5        0.5        0.99513465 ... 0.5        0.9842366  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5434151941537857\n",
            "Valid loss: 0.5539015276091439\n",
            "0.5750398\n",
            "BEST VALID LOSS\n",
            "Test AUROC result: 0.7732784024456504\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "Train AUROC: 0.6683708886751047\n",
            "Valid AUROC: 0.7808428767750801\n",
            "[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.6189373230934143\n",
            "Valid loss: 0.5725679738180978\n",
            "0.65508056\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7417851340767062\n",
            "Valid AUROC: 0.7835693166201642\n",
            "[0.5        0.61003596 0.88852865 ... 0.5        0.9789634  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5764192390441895\n",
            "Valid loss: 0.566541143826076\n",
            "0.5805949\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7434524866200336\n",
            "Valid AUROC: 0.7855907216924166\n",
            "[0.5        0.5        0.948958   ... 0.5        0.93571454 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5721208626031875\n",
            "Valid loss: 0.563243431704385\n",
            "0.64925706\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7527963534909667\n",
            "Valid AUROC: 0.7956127930704201\n",
            "[0.5        0.6049909  0.917211   ... 0.5        0.98857063 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5659197354316712\n",
            "Valid loss: 0.5656353235244751\n",
            "0.74132705\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7592818905545294\n",
            "Valid AUROC: 0.7941927289384917\n",
            "[0.5        0.50771576 0.9673256  ... 0.5        0.9631596  0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5615948796272278\n",
            "Valid loss: 0.5566400630133492\n",
            "0.5820112\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7628543926224955\n",
            "Valid AUROC: 0.7967809103402325\n",
            "[0.5        0.5        0.94847846 ... 0.5        0.97593427 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5565651845932007\n",
            "Valid loss: 0.5540660704885211\n",
            "0.59530437\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7637610910748602\n",
            "Valid AUROC: 0.7994665389580643\n",
            "[0.5       0.5       0.5       ... 0.5       0.9846149 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5547304952144623\n",
            "Valid loss: 0.5528485689844403\n",
            "0.6226807\n",
            "BEST VALID LOSS\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Train AUROC: 0.7711843936945272\n",
            "Valid AUROC: 0.7932145088077291\n",
            "[0.5        0.5        0.9560419  ... 0.5        0.99058455 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5483029603958129\n",
            "Valid loss: 0.5516460963657924\n",
            "0.5218748\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.771662748309353\n",
            "Valid AUROC: 0.7956502727689166\n",
            "[0.5        0.5        0.9827596  ... 0.5        0.98766416 0.5       ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5472309875488282\n",
            "Valid loss: 0.5479678511619568\n",
            "0.59354186\n",
            "BEST VALID LOSS\n",
            "Train AUROC: 0.7770941264227004\n",
            "Valid AUROC: 0.8134631241410903\n",
            "[0.5       0.5       0.9728257 ... 0.5       0.9929715 0.5      ]\n",
            "[0. 1. 1. ... 0. 1. 0.]\n",
            "Train loss: 0.5417105942964554\n",
            "Valid loss: 0.5722031508173261\n",
            "0.7391924\n",
            "UPDATED BEST INTERMEDIATE MODEL\n",
            "Test AUROC result: 0.7876620864628602\n"
          ]
        }
      ],
      "source": [
        "# Can use diagnosis_cv_run function as just need functionality to filter test set\n",
        "bad_bio_test_results, bad_bio_actual_test_auroc_results, bad_bio_final_threshold = diagnosis_cv_run_fun(model_data, model, bad_bio_stay_id_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1710843871995
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save \n",
        "with open(\"bad_bio_cv_chronic_switch_test_results\", \"wb\") as fp:   #Pickling\n",
        "    pickle.dump(bad_bio_test_results, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1710843872694
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test_auroc: 0.7557939457720296\n",
            "std test_auroc: 0.08594136418201168\n",
            "test_auroc 2.5th percentile: 0.5609762605815237\n",
            "test_auroc 97.5th percentile: 0.8057350510770652\n",
            "mean test_accuracy: 0.6845771559129034\n",
            "std test_accuracy: 0.0883127508030187\n",
            "test_accuracy 2.5th percentile: 0.48134184739170915\n",
            "test_accuracy 97.5th percentile: 0.7260350183277177\n",
            "mean test_balanced_accuracy: 0.6987186452388354\n",
            "std test_balanced_accuracy: 0.06688606390720815\n",
            "test_balanced_accuracy 2.5th percentile: 0.5464291958041958\n",
            "test_balanced_accuracy 97.5th percentile: 0.7371465041084755\n",
            "mean test_recall: 0.6106196345706854\n",
            "std test_recall: 0.2088635893878391\n",
            "test_recall 2.5th percentile: 0.12865384615384615\n",
            "test_recall 97.5th percentile: 0.7308493606847823\n",
            "mean test_precision: 0.7213708395426932\n",
            "std test_precision: 0.2415033440656824\n",
            "test_precision 2.5th percentile: 0.1741097208854668\n",
            "test_precision 97.5th percentile: 0.8371588634048681\n",
            "mean test_f1: 0.6598064516129832\n",
            "std test_f1: 0.22112276800901295\n",
            "test_f1 2.5th percentile: 0.1526622718052738\n",
            "test_f1 97.5th percentile: 0.7571688966501862\n",
            "mean test_auprc: 0.8108542527520672\n",
            "std test_auprc: 0.07879305494539131\n",
            "test_auprc 2.5th percentile: 0.6314998300721941\n",
            "test_auprc 97.5th percentile: 0.8611912920846205\n",
            "mean test_tpr: 0.6106196345706854\n",
            "std test_tpr: 0.2088635893878391\n",
            "test_tpr 2.5th percentile: 0.12865384615384615\n",
            "test_tpr 97.5th percentile: 0.7308493606847823\n",
            "mean test_fpr: 0.21318234409301437\n",
            "std test_fpr: 0.08280771161354664\n",
            "test_fpr 2.5th percentile: 0.03579545454545455\n",
            "test_fpr 97.5th percentile: 0.28424544676814384\n"
          ]
        }
      ],
      "source": [
        "analyze_results_fun(bad_bio_test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Outcomes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "gather": {
          "logged": 1710776388408
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def test_stats(list1, list2):\n",
        "\n",
        "    # Test if same distribution\n",
        "    k2, p = stats.mannwhitneyu(list1, list2)\n",
        "    alpha = 0.05\n",
        "    print(p)\n",
        "    if p < alpha:\n",
        "        print('Different distribution')\n",
        "    else:\n",
        "        print(' Same distribution')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "gather": {
          "logged": 1710776825680
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 1,126,583 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "# Load model\n",
        "\n",
        "# Hyperparameters\n",
        "final_input_dim = 268\n",
        "final_output_dim = 1\n",
        "final_hid_dim = 512\n",
        "final_hid_dim2 = 128\n",
        "demographics_input_dim = 12\n",
        "demographics_output_dim = 12\n",
        "vital_input_dim = 253\n",
        "vital_hid_dim = 512\n",
        "vital_output_dim = 128\n",
        "dropout = 0.1\n",
        "\n",
        "# Define model\n",
        "model = Chronic_switch_model(\n",
        "    final_input_dim, \n",
        "    final_output_dim, \n",
        "    final_hid_dim, \n",
        "    final_hid_dim2,\n",
        "    demographics_input_dim,\n",
        "    demographics_output_dim,\n",
        "    vital_input_dim, \n",
        "    vital_hid_dim, \n",
        "    vital_output_dim, \n",
        "    dropout).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load('chronic_switch_model.pt'))\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "gather": {
          "logged": 1710776842741
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/chronic_switch_icare_df_preprocessed.csv'\n",
        "icare_df_preprocessed = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_episodes.csv'\n",
        "episodes = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_disease.csv'\n",
        "disease = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_demographics.csv'\n",
        "demographics = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/snomed_embedding_128d-copy.csv'\n",
        "embedding = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_problem_dummies.csv'\n",
        "problem_dummies = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "gather": {
          "logged": 1710776867820
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Merge\n",
        "problem_dummies2 = pd.merge(problem_dummies, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "problem_dummies2 = pd.merge(icare_df_preprocessed[['SPELL_IDENTIFIER', 'date']], problem_dummies2)\n",
        "\n",
        "# Strip name \n",
        "problem_dummies2.columns = problem_dummies2.columns.str.removeprefix('PROBLEM_')\n",
        "\n",
        "# Convert the date columns to datetime objects if they are not already\n",
        "problem_dummies2['date'] = pd.to_datetime(problem_dummies2['date'])\n",
        "problem_dummies2['DT_TM'] = pd.to_datetime(problem_dummies2['DT_TM'])\n",
        "\n",
        "# Calculate the absolute time difference between 'date' and 'DT_TM'\n",
        "problem_dummies2['time_diff'] = (problem_dummies2['date'] - problem_dummies2['DT_TM']).abs()\n",
        "\n",
        "# Filter rows where 'time_diff' is not negative\n",
        "problem_dummies2 = problem_dummies2[problem_dummies2['time_diff'] >= pd.Timedelta(0)]\n",
        "\n",
        "# Sort the DataFrame by 'SPELL_IDENTIFIER' and 'time_diff'\n",
        "problem_dummies2.sort_values(by=['SPELL_IDENTIFIER', 'time_diff'], inplace=True)\n",
        "\n",
        "# Convert to str\n",
        "problem_dummies2['date'] = problem_dummies2['date'].astype(str)\n",
        "\n",
        "# Keep only the rows with the smallest time difference for each 'SPELL_IDENTIFIER'\n",
        "problem_dummies2 = problem_dummies2.groupby(['SPELL_IDENTIFIER', 'date']).first().reset_index()\n",
        "\n",
        "### REASON the problem_dummies2 is shorter is not because it is missing some dates! \n",
        "### It is because in the final data we have some dates repeated for a spesfic spell \n",
        "### if they were admited in between 6am and 12pm the 12hour prediction is done at 6am \n",
        "### of the first day, then 48 done at 6am the next day, then the next prediction done \n",
        "### at 12pm that day causing there to be two prediction for that day...phew\n",
        "### So just get a set of co-morbidities for each spell and merge \n",
        "\n",
        "# Drop the 'time_diff' column as it's no longer needed\n",
        "problem_dummies2.drop(columns=['time_diff', 'SUBJECT', 'DT_TM', 'new_subject', 'date'], inplace=True)\n",
        "\n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(inplace=True)\n",
        "\n",
        "# Some still got through by having their co-morbidid diagnosis updated during their stay \n",
        "# In this case we just use the frst one throughout and remove the others \n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(subset=['SPELL_IDENTIFIER'], keep='first', inplace=True)\n",
        "\n",
        "# Filter for features\n",
        "X_data = icare_df_preprocessed.drop(columns=['SPELL_IDENTIFIER', 'po_flag'])\n",
        "X_data = X_data.drop(columns=columns_to_drop)\n",
        "model_data = pd.concat([icare_df_preprocessed[['SPELL_IDENTIFIER', 'po_flag']], X_data], axis=1)\n",
        "# Merge\n",
        "demographics = pd.merge(demographics, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "demographics.drop(columns=['SUBJECT'], inplace=True)\n",
        "model_data = pd.merge(model_data, demographics, how='left')\n",
        "model_data = pd.merge(model_data, disease, how='left')\n",
        "# Drop \n",
        "model_data = model_data.drop(columns=['date', 'ROUTE', '24_hour_flag', '48_hour_flag', 'iv_treatment_length'])\n",
        "# fillna\n",
        "model_data['AGE'] = model_data['AGE'].fillna(-1)\n",
        "model_data['IMDDECIL'] = model_data['IMDDECIL'].fillna(-1)\n",
        "model_data = model_data.fillna(0)\n",
        "# Merge co-morbidites\n",
        "model_data = pd.merge(model_data, problem_dummies2, how='left')\n",
        "# Rename\n",
        "model_data.rename(columns={'SPELL_IDENTIFIER': 'stay_id'}, inplace=True)\n",
        "# Random shuffle\n",
        "stays = model_data['stay_id'].unique()\n",
        "random.Random(5).shuffle(stays)\n",
        "model_data = model_data.set_index(\"stay_id\").loc[stays].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710776618442
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import json, snowflake.connector\n",
        "\n",
        "# establish the connection to snowflake\n",
        "ctx = snowflake.connector.connect( \n",
        "    **json.load(open('/opt/ich/python-snowflake-defaults.json')))\n",
        "    \n",
        "# verify and test if connection is working\n",
        "try: \n",
        "    cs = ctx.cursor() \n",
        "    cs.execute('SELECT current_version(), current_role(), current_warehouse()')\n",
        "    print(cs.fetchone())\n",
        "finally: \n",
        "    cs.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "gather": {
          "logged": 1710776904699
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import \n",
        "query = '''\n",
        "SELECT * from ICHT_PROD.ICHT_COVID.EPISODES\n",
        "'''\n",
        "cur = ctx.cursor().execute(query)\n",
        "episodes = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "gather": {
          "logged": 1710776909589
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import \n",
        "query = '''\n",
        "SELECT * from ICHT_PROD.ICHT_COVID.demographic\n",
        "'''\n",
        "cur = ctx.cursor().execute(query)\n",
        "demographic = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "gather": {
          "logged": 1710776911670
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Get discharge time\n",
        "stay_list = icare_df_preprocessed.SPELL_IDENTIFIER.unique().tolist()\n",
        "episodes2 = episodes[episodes['SPELL_IDENTIFIER'].isin(stay_list)]\n",
        "episodes2 = episodes2[['SPELL_IDENTIFIER', 'DISCHARGE_DATE_TIME']].drop_duplicates()\n",
        "episodes2.rename(columns={'SPELL_IDENTIFIER': 'stay_id', 'DISCHARGE_DATE_TIME':'outtime'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "gather": {
          "logged": 1710777210783
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def los_cv_run_fun(data, icu_stays):\n",
        "\n",
        "    ### Import LOS ###\n",
        "\n",
        "    po_los_dict = {}\n",
        "    iv_los_dict = {}\n",
        "\n",
        "    # Split into folds\n",
        "    split_generator = cv_data_fun(data)\n",
        "\n",
        "    # Iterate through folds\n",
        "    for x in range(N_EPOCHS):\n",
        "        train_idx, val_idx, test_idx = next(split_generator)\n",
        "\n",
        "        # Get train val and test\n",
        "        train_data = data.loc[train_idx]\n",
        "        valid_data = data.loc[val_idx]\n",
        "        test_data = data.loc[test_idx]\n",
        "        \n",
        "        test_data = test_data[(test_data['iv_treatment_length'] >= 1) & (test_data['iv_treatment_length'] < 8)]\n",
        "\n",
        "        for i in test_data.iv_treatment_length.unique():\n",
        "            temp_data = test_data[(test_data['iv_treatment_length'] == i) & (test_data['po_flag'] == 1)]\n",
        "            temp_data = pd.merge(temp_data, icu_stays)\n",
        "            temp_data['date'] = pd.to_datetime(temp_data['date'])\n",
        "            temp_data['outtime'] = pd.to_datetime(temp_data['outtime'])\n",
        "            temp_data['remaining_los'] =  (temp_data['outtime'] - temp_data['date']).dt.days\n",
        "            remaining_los_list = temp_data['remaining_los'].values.tolist()\n",
        "            \n",
        "            if x == 0:\n",
        "                po_los_dict[i] = remaining_los_list\n",
        "            else:\n",
        "                new_los_list = po_los_dict[i]\n",
        "                new_los_list.extend(remaining_los_list)\n",
        "                po_los_dict[i] = new_los_list\n",
        "        \n",
        "        for i in test_data.iv_treatment_length.unique():\n",
        "            temp_data = test_data[(test_data['iv_treatment_length'] == i) & (test_data['po_flag'] == 0)]\n",
        "            temp_data = pd.merge(temp_data, icu_stays)\n",
        "            temp_data['date'] = pd.to_datetime(temp_data['date'])\n",
        "            temp_data['outtime'] = pd.to_datetime(temp_data['outtime'])\n",
        "            temp_data['remaining_los'] =  (temp_data['outtime'] - temp_data['date']).dt.days\n",
        "            remaining_los_list = temp_data['remaining_los'].values.tolist()\n",
        "            if x == 0:\n",
        "                iv_los_dict[i] = remaining_los_list\n",
        "            else:\n",
        "                new_los_list = iv_los_dict[i]\n",
        "                new_los_list.extend(remaining_los_list)\n",
        "                iv_los_dict[i] = new_los_list\n",
        "\n",
        "        return po_los_dict, iv_los_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "gather": {
          "logged": 1710777263198
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Rename\n",
        "icare_df_preprocessed_2 = icare_df_preprocessed.rename(columns={'SPELL_IDENTIFIER':'stay_id'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "gather": {
          "logged": 1710777264180
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Run\n",
        "po_los_dict, iv_los_dict = los_cv_run_fun(icare_df_preprocessed_2, episodes2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "gather": {
          "logged": 1710777326563
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "3.932926829268293\n",
            "6.178947368421053\n",
            "3.6149015675002043e-13\n",
            "Different distribution\n",
            "2\n",
            "3.0597826086956523\n",
            "6.030959752321982\n",
            "3.5197832922118626e-23\n",
            "Different distribution\n",
            "3\n",
            "2.9647058823529413\n",
            "5.788571428571428\n",
            "5.278304649447711e-11\n",
            "Different distribution\n",
            "4\n",
            "3.1216216216216215\n",
            "5.735849056603773\n",
            "7.53305298830694e-09\n",
            "Different distribution\n",
            "5\n",
            "3.0833333333333335\n",
            "5.633333333333334\n",
            "0.00011822025825896418\n",
            "Different distribution\n",
            "6\n",
            "4.724137931034483\n",
            "4.702702702702703\n",
            "0.31891233791178597\n",
            " Same distribution\n",
            "7\n",
            "1.9545454545454546\n",
            "5.444444444444445\n",
            "0.0019320212257584975\n",
            "Different distribution\n"
          ]
        }
      ],
      "source": [
        "for i in po_los_dict.keys():\n",
        "    print(i)\n",
        "    print(mean(po_los_dict[i]))\n",
        "    print(mean(iv_los_dict[i]))\n",
        "    test_stats(po_los_dict[i], iv_los_dict[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "gather": {
          "logged": 1710777330745
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def reject_outliers(data, m=2):\n",
        "    return data[abs(data - np.mean(data)) < m * np.std(data)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "gather": {
          "logged": 1710777539794
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "3.2625\n",
            "5.292817679558011\n",
            "4.30546467398865e-13\n",
            "Different distribution\n",
            "2\n",
            "2.1040462427745665\n",
            "5.1237785016286646\n",
            "8.39323685819308e-28\n",
            "Different distribution\n",
            "3\n",
            "2.111111111111111\n",
            "4.982035928143713\n",
            "1.9176060758276937e-12\n",
            "Different distribution\n",
            "4\n",
            "2.072463768115942\n",
            "4.910891089108911\n",
            "5.895619891750137e-11\n",
            "Different distribution\n",
            "5\n",
            "2.2045454545454546\n",
            "4.607142857142857\n",
            "1.1061039950292758e-05\n",
            "Different distribution\n",
            "6\n",
            "3.5555555555555554\n",
            "3.7058823529411766\n",
            "0.28401680045512734\n",
            " Same distribution\n",
            "7\n",
            "1.3\n",
            "4.823529411764706\n",
            "0.0005780910406318757\n",
            "Different distribution\n"
          ]
        }
      ],
      "source": [
        "# See if results are same with outliers removed\n",
        "po_means = []\n",
        "po_std = []\n",
        "iv_means = []\n",
        "iv_std = []\n",
        "for i in po_los_dict.keys():\n",
        "    print(i)\n",
        "    po_los_dict2 = reject_outliers(np.array(po_los_dict[i]))\n",
        "    iv_los_dict2 = reject_outliers(np.array(iv_los_dict[i]))\n",
        "\n",
        "    print(mean(po_los_dict2))\n",
        "    po_means.append(mean(po_los_dict2))\n",
        "    po_std.append(std(po_los_dict2))\n",
        "    print(mean(iv_los_dict2))\n",
        "    iv_means.append(mean(iv_los_dict2))\n",
        "    iv_std.append(std(iv_los_dict2))\n",
        "\n",
        "    test_stats(po_los_dict2, iv_los_dict2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "gather": {
          "logged": 1710777626782
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Mean remaining LOS')"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Remaining LOS by IV treatment duration')"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Prior days cumulative IV treatment length')"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.axis.XTick at 0x7fb404f04fd0>,\n",
              " <matplotlib.axis.XTick at 0x7fb404f05c60>,\n",
              " <matplotlib.axis.XTick at 0x7fb3dd972bc0>,\n",
              " <matplotlib.axis.XTick at 0x7fb3de211450>,\n",
              " <matplotlib.axis.XTick at 0x7fb3de2100a0>,\n",
              " <matplotlib.axis.XTick at 0x7fb3de212c20>,\n",
              " <matplotlib.axis.XTick at 0x7fb3de213430>]"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb3de0a7520>"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAHWCAYAAAARl3+JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQI0lEQVR4nO3de3zP9f//8ft7s5NtxtjmtIOznEpIyFmJRVMpIoYkOUUqOjh1oHP8EjltHcwhUlKOheRQSorIefEJOY+RYXv+/nDZ++ttG+/3bHtvL7fr5fK+XPZ+vl6v5/Pxfr3f2+57vg6zGWOMAAAAUKB5uLsAAAAA3DhCHQAAgAUQ6gAAACyAUAcAAGABhDoAAAALINQBAABYAKEOAADAAgh1AAAAFkCoAwAAsABCHZBLoqKiFBsbm61tmzVrpmbNmuVoPQVZbGysAgIC3F0GCpgb+R7MTatWrZLNZtOqVavcXQoshlCHfCs+Pl42m83+KFSokMqUKaPY2Fj9888/7i7PsqKionTfffddd739+/frySefVFRUlHx8fBQaGqqYmBitXbs20/UTExPVo0cPVahQQb6+vipZsqSaNGmikSNH5vRLyLYrX/sXX3whm82madOmZbn+8uXLZbPZNGHChCzXWbdunUaNGqVTp07ldLlOO3funEaNGlVgQsS3336rUaNGubuMG/bhhx8qPj7e3WXgJlLI3QUA1zNmzBiVK1dO58+f14YNGxQfH68ff/xRW7dula+vr7vLy9KOHTvk4ZG9v5uWLVuWw9XkrLVr16pt27aSpMcff1zVqlXT4cOHFR8fr8aNG2v8+PEaMGCAff3du3erXr168vPzU8+ePRUVFaVDhw5p06ZNeuONNzR69Gh3vZQsRUdHKygoSAkJCXr88cczXSchIUGenp7q1KlTlv2sW7dOo0ePVmxsrIoWLZpL1V7buXPn7Pu4IMwAf/vtt5o4cWKBD3YffvihSpQokWG2sEmTJvrvv//k7e3tnsJgWYQ65Htt2rRR3bp1JV0OECVKlNAbb7yhhQsX6uGHH3ZzdVnz8fHJ9rb5+Yf9yZMn9dBDD8nPz09r165VhQoV7MuGDBmi1q1b6+mnn1adOnXUsGFDSdJ7772n5ORkbd68WZGRkQ79HTlyJE/rd5aPj48eeughxcXF6eDBgypdurTD8vPnz2vBggW6++67FRoamiNjpqWl6cKFC/n6j5WblTFG58+fl5+f3w335eHhwXuMXMHhVxQ4jRs3liTt2bPHof2vv/7SQw89pODgYPn6+qpu3bpauHChwzrph3R//PFHDRw4UCEhISpatKj69OmjCxcu6NSpU+rWrZuKFSumYsWK6bnnnpMxxqGPt99+Ww0bNlTx4sXl5+enOnXqaN68eRnqvPp8nvSx165dqyFDhigkJET+/v7q0KGDjh496rDt1efUpZ+DM3fuXL322msqW7asfH191bJlS+3evTvD2BMnTlT58uXl5+enO+64Q2vWrMmx8/Q++ugjHT58WG+99ZZDoJMkPz8/ffzxx7LZbBozZoy9fc+ePSpbtmyGQCfJpUC0d+9etW7dWv7+/ipdurTGjBljf3+MMYqKitL999+fYbvz588rKChIffr0cXosSeratavS0tI0e/bsDMu++eYbJSUlqUuXLlluP2rUKD377LOSpHLlytlPJUhMTJQk2Ww29e/fXzNnzlT16tXl4+OjJUuWSJL++ecf9ezZU2FhYfLx8VH16tU1Y8YMh/4vXLigESNGqE6dOgoKCpK/v78aN26slStX2tdJTExUSEiIJGn06NH2GtJnwdLPV9y/f7/uu+8+BQQEqEyZMpo4caIkacuWLWrRooX8/f0VGRmphISEDK/z1KlTevrppxUeHi4fHx9VrFhRb7zxhtLS0hzqsNlsevvttzVlyhRVqFBBPj4+qlevnjZu3GhfLzY21j72ladfXIsxRq+++qrKli2rwoULq3nz5vrzzz8zfT8y6yv9ezP9fZH+71D80qVLVbduXfn5+emjjz6SJMXFxalFixYKDQ2Vj4+PqlWrpkmTJjn0GRUVpT///FOrV6+2v4b077+szqn7/PPPVadOHfn5+alEiRLq2rVrhlNN0t+vf/75RzExMQoICFBISIiGDh2q1NTUa+4nWB8zdShw0n/wFitWzN72559/qlGjRipTpoyGDRsmf39/zZ07VzExMZo/f746dOjg0MeAAQNUsmRJjR49Whs2bNCUKVNUtGhRrVu3ThEREXr99df17bff6q233lKNGjXUrVs3+7bjx49X+/bt1aVLF124cEGzZ89Wx44dtWjRIkVHR1+3/gEDBqhYsWIaOXKkEhMT9f7776t///6aM2fOdbcdN26cPDw8NHToUCUlJenNN99Uly5d9NNPP9nXmTRpkvr376/GjRtr8ODBSkxMVExMjIoVK6ayZcted4zr+frrr+Xr65vlLGm5cuV011136fvvv9d///0nPz8/RUZGasWKFfr+++/VokWLbI2bmpqqe++9V3feeafefPNNLVmyRCNHjtSlS5c0ZswY2Ww2de3aVW+++aZOnDih4OBgh5pPnz6trl27ujRmkyZNVLZsWSUkJGjIkCEOyxISElS4cGHFxMRkuf0DDzygnTt3atasWXrvvfdUokQJSbKHLEn6/vvvNXfuXPXv318lSpRQVFSU/v33X91555320BcSEqLFixerV69eOn36tJ5++mlJ0unTpzVt2jR17txZvXv31pkzZzR9+nS1bt1aP//8s2677TaFhIRo0qRJ6tu3rzp06KAHHnhAklSrVi2HfdumTRs1adJEb775pmbOnKn+/fvL399fL774orp06aIHHnhAkydPVrdu3dSgQQOVK1dO0uVDu02bNtU///yjPn36KCIiQuvWrdPw4cN16NAhvf/++xn225kzZ9SnTx/ZbDa9+eabeuCBB7R37155eXmpT58+OnjwoJYvX65PP/3UqfdpxIgRevXVV9W2bVu1bdtWmzZt0j333KMLFy44tX1WduzYoc6dO6tPnz7q3bu3qlSpIuny91j16tXVvn17FSpUSF9//bWeeuoppaWlqV+/fpKk999/XwMGDFBAQIBefPFFSVJYWFiWY8XHx6tHjx6qV6+exo4dq3///Vfjx4/X2rVr9dtvvzkcuk9NTVXr1q1Vv359vf3221qxYoXeeecdVahQQX379r2h14wCzgD5VFxcnJFkVqxYYY4ePWoOHDhg5s2bZ0JCQoyPj485cOCAfd2WLVuamjVrmvPnz9vb0tLSTMOGDU2lSpUy9Nm6dWuTlpZmb2/QoIGx2WzmySeftLddunTJlC1b1jRt2tShrnPnzjk8v3DhgqlRo4Zp0aKFQ3tkZKTp3r17hrFbtWrlMPbgwYONp6enOXXqlL2tadOmDuOuXLnSSDK33HKLSUlJsbePHz/eSDJbtmwxxhiTkpJiihcvburVq2cuXrxoXy8+Pt5IyvBaMhMZGWmio6OzXF60aFFz6623XrOPgQMHGknmjz/+MMYYs3XrVuPn52ckmdtuu80MGjTIfPnll+bs2bPXrccYY7p3724kmQEDBtjb0tLSTHR0tPH29jZHjx41xhizY8cOI8lMmjTJYfv27dubqKgoh/2emcxe+7PPPmskmR07dtjbkpKSjK+vr+ncufN1a3/rrbeMJLNv374MyyQZDw8P8+effzq09+rVy5QqVcocO3bMob1Tp04mKCjI/hm8dOmSw+fBGGNOnjxpwsLCTM+ePe1tR48eNZLMyJEjM9SQvm9ff/11hz78/PyMzWYzs2fPtrf/9ddfGfp55ZVXjL+/v9m5c6dDv8OGDTOenp5m//79xhhj9u3bZySZ4sWLmxMnTtjX++qrr4wk8/XXX9vb+vXrZ5z99XTkyBHj7e1toqOjHd7fF154wUhy+B4cOXJkpv2mf29e+R5FRkYaSWbJkiUZ1r/6Z4AxxrRu3dqUL1/eoa169eqZfs+lfz+vXLnSGHP5Z0hoaKipUaOG+e+//+zrLVq0yEgyI0aMsLelv19jxoxx6LN27dqmTp06GcbCzYXDr8j3WrVqpZCQEIWHh+uhhx6Sv7+/Fi5caJ91OnHihL7//ns9/PDDOnPmjI4dO6Zjx47p+PHjat26tXbt2pXhEEavXr0cDsPUr19fxhj16tXL3ubp6am6detq7969DtteeU7NyZMnlZSUpMaNG2vTpk1OvZ4nnnjCYezGjRsrNTVVf//993W37dGjh8P5dumHotNr/OWXX3T8+HH17t1bhQr930R8ly5dHGY2b8SZM2cUGBh4zXXSl58+fVqSVL16dW3evFldu3ZVYmKixo8fr5iYGIWFhWnq1KlOj92/f3/71+mzWBcuXNCKFSskSZUrV1b9+vU1c+ZM+3onTpzQ4sWL1aVLl+sexstM+uzelYcd58+fr/Pnz1/z0KuzmjZtqmrVqtmfG2M0f/58tWvXTsYY++f52LFjat26tZKSkuyfNU9PT/vnIS0tTSdOnNClS5dUt25dpz+P6a68GKRo0aKqUqWK/P39HWZkq1SpoqJFizp8T3z++edq3LixihUr5lBrq1atlJqaqh9++MFhnEceecThs3j1Z9hVK1as0IULFzRgwACH9zd9NvNGlCtXTq1bt87QfuXPgKSkJB07dkxNmzbV3r17lZSU5PI4v/zyi44cOaKnnnrK4Vy76OhoVa1aVd98802GbZ588kmH540bN872PoR1cPgV+d7EiRNVuXJlJSUlacaMGfrhhx8cLkLYvXu3jDF6+eWX9fLLL2fax5EjR1SmTBn784iICIflQUFBkqTw8PAM7SdPnnRoW7RokV599VVt3rxZKSkp9nZnA8PVY6f/grt6nOxsmx4MK1as6LBeoUKFFBUV5VR91xMYGKgzZ85cc5305VeGv8qVK+vTTz9Vamqqtm3bpkWLFunNN9/UE088oXLlyqlVq1bX7NPDw0Ply5d3aKtcubIkOZwL1a1bN/Xv319///23IiMj9fnnn+vixYt67LHHXHmZdrVq1VKNGjU0a9Ys+3loCQkJKlGiRKa/8F2Vfhgz3dGjR3Xq1ClNmTJFU6ZMyXSbKy8u+fjjj/XOO+/or7/+0sWLF7Ps91p8fX0dDglLlz/7ZcuWzfC5vvp7YteuXfrjjz8ybJ9ZrdKNff4zk/6Zr1SpkkN7SEjIDf8hk9U+XLt2rUaOHKn169fr3LlzDsuSkpLsP0+clf4a0g/vXqlq1ar68ccfHdoye7+KFSuW7X0I6yDUId+744477Fe/xsTE6K677tKjjz6qHTt2KCAgwH4y9tChQ7P8JXt1yPH09Mx0vczazRUXSqxZs0bt27dXkyZN9OGHH6pUqVLy8vJSXFxcpieQOzvG1ePkxrY55ZZbbtFvv/2mlJSULK/w/eOPP+Tl5ZXhF610+TXUrFlTNWvWVIMGDdS8eXPNnDnzuqHOWZ06ddLgwYM1c+ZMvfDCC/rss89Ut27dTH9hOqtr164aNmyYfvnlF5UtW1YrV65Unz59HGZDs+vqqynTP89du3ZV9+7dM90m/Xy4zz77TLGxsYqJidGzzz6r0NBQeXp6auzYsRkuJLoWV74fJMfPW1pamu6++24999xzma6bHrxd6TO3ZPWHV1YXGGR2peuePXvUsmVLVa1aVe+++67Cw8Pl7e2tb7/9Vu+9957DxSG5Jat9CBDqUKCk/8Jq3ry5PvjgAw0bNsw+e+Pl5ZVjwSAr8+fPl6+vr5YuXeoQaOLi4nJ1XGelX126e/duNW/e3N5+6dIlJSYmOpwcn1333Xef1q9fr88//zzTCw8SExO1Zs0atWrV6rq3f0gP64cOHbruuGlpadq7d69DSNi5c6ckOcxCBgcHKzo6WjNnzlSXLl20du3aDCfru6pz584aPny4EhISFBkZqdTUVKcPvbp6yDckJESBgYFKTU297ud53rx5Kl++vP1GyemuvqFzdg47O6tChQpKTk7O0e89V+pN/8zv2rXLYSb36NGjGWau0mfuTp065XDhgTOnPqT7+uuvlZKSooULFzrMOl55xXE6Z19H+mvYsWNHhguJduzYkelV40BmOKcOBU6zZs10xx136P3339f58+cVGhqqZs2a6aOPPso0HFx9u5Ab4enpKZvN5vCXfWJior788sscG+NG1K1bV8WLF9fUqVN16dIle/vMmTNz7NBMnz59FBoaqmeffTbDOTznz59Xjx49ZIzRiBEj7O1r1qxxODSY7ttvv5WU+WGnzHzwwQf2r40x+uCDD+Tl5aWWLVs6rPfYY49p27ZtevbZZ697c2BnREREqHHjxpozZ44+++wzlStXzn4Pvuvx9/eXJKf/o4Snp6cefPBBzZ8/X1u3bs2w/MrPc/qMzZWzXD/99JPWr1/vsE3hwoVdqsEVDz/8sNavX6+lS5dmWHbq1CmHz6GzXNlnrVq1kpeXl/7f//t/DvshsyCffgueK8/zO3v2rD7++GOna8tsnyclJWX6h52/v79Tr6Fu3boKDQ3V5MmTHU7pWLx4sbZv3+7UVfWAxEwdCqhnn31WHTt2VHx8vJ588klNnDhRd911l2rWrKnevXurfPny+vfff7V+/Xr973//0++//54j40ZHR+vdd9/Vvffeq0cffVRHjhzRxIkTVbFiRf3xxx85MsaN8Pb21qhRozRgwAC1aNFCDz/8sBITExUfH68KFSo4PXOwe/duvfrqqxnaa9eurejoaM2bN0/R0dG6/fbbM/xHid27d2v8+PEOoeeNN97Qr7/+qgceeMA+W7hp0yZ98sknCg4Oduqkdl9fXy1ZskTdu3dX/fr1tXjxYn3zzTd64YUXMpxfFB0dreLFi+vzzz9XmzZtcuTmwF27dtUTTzyhgwcP2m9R4Yw6depIkl588UV16tRJXl5eateunT24ZGbcuHFauXKl6tevr969e6tatWo6ceKENm3apBUrVujEiROSLs+afvHFF+rQoYOio6O1b98+TZ48WdWqVVNycrK9Pz8/P1WrVk1z5sxR5cqVFRwcrBo1aqhGjRrZ3Bv/59lnn9XChQt13333KTY2VnXq1NHZs2e1ZcsWzZs3T4mJifZbuTgrfZ8NHDhQrVu3vmYwT79H29ixY3Xfffepbdu2+u2337R48eIM495zzz2KiIhQr1697IF/xowZCgkJ0f79+52q7Z577pG3t7fatWunPn36KDk5WVOnTlVoaGiGPyrr1KmjSZMm6dVXX1XFihUVGhqa6S19vLy89MYbb6hHjx5q2rSpOnfubL+lSVRUlAYPHuxUbQC3NEG+lX6bgY0bN2ZYlpqaaipUqGAqVKhgLl26ZIwxZs+ePaZbt26mZMmSxsvLy5QpU8bcd999Zt68edftM/1WB+m3xkjXvXt34+/v79A2ffp0U6lSJePj42OqVq1q4uLiMr1VQla3NLl67Ktvb2BM1rc0+fzzzx22Tb9NRFxcnEP7hAkTTGRkpPHx8TF33HGHWbt2ralTp4659957M+zLq6XfyiGzR69evRzG7t27t4mIiDBeXl6mRIkSpn379mbNmjUZ+ly7dq3p16+fqVGjhgkKCjJeXl4mIiLCxMbGmj179ly3pvT3Yc+ePeaee+4xhQsXNmFhYWbkyJEmNTU1022eeuopI8kkJCRct/8rX3tWt3M5ceKE8fHxMZLMtm3bnO7TmMu3/ShTpozx8PBwuHWGJNOvX79Mt/n3339Nv379THh4uPHy8jIlS5Y0LVu2NFOmTLGvk5aWZl5//XX7e127dm2zaNEi0717dxMZGenQ37p160ydOnWMt7e3w21JMvuMG3P5M1i9evUM7ZntozNnzpjhw4ebihUrGm9vb1OiRAnTsGFD8/bbb5sLFy4YY/7vs/rWW29l6PPKeoy5fKuWAQMGmJCQEGOz2a57e5PU1FQzevRoU6pUKePn52eaNWtmtm7dmuF70Bhjfv31V1O/fn3j7e1tIiIizLvvvpvlLU2y+iwsXLjQ1KpVy/j6+pqoqCjzxhtvmBkzZmTo4/DhwyY6OtoEBgY63FIos+95Y4yZM2eOqV27tvHx8THBwcGmS5cu5n//+5/DOlm9X1ndrgU3F5sxeXiGNQC3SEtLU0hIiB544AGXbiFSkA0ePFjTp0/X4cOH7YcfAcDKOKcOsJjz589nuJLwk08+0YkTJwrEP3PPCefPn9dnn32mBx98kEAH4KbBOXWAxWzYsEGDBw9Wx44dVbx4cW3atEnTp09XjRo11LFjR3eXl6uOHDmiFStWaN68eTp+/LgGDRrk7pIAIM8Q6gCLiYqKUnh4uCZMmGD/H6jdunXTuHHjHP4bhRVt27ZNXbp0UWhoqCZMmKDbbrvN3SUBQJ7hnDoAAAAL4Jw6AAAACyDUAQAAWECBPqcuLS1NBw8eVGBgYK7+GxwAAAB3McbozJkzKl26tDw8sp6PK9Ch7uDBgwoPD3d3GQAAALnuwIEDKlu2bJbLC3SoCwwMlHT5RRYpUsTN1QAAAOS806dPKzw83J57slKgQ136IdciRYoQ6gAAgKVd71QzLpQAAACwAEIdAACABRDqAAAALKBAn1MHAAAKttTUVF28eNHdZbiVl5eXPD09b7gfQh0AAMhzxhgdPnxYp06dcncp+ULRokVVsmTJG7rvLqEOAADkufRAFxoaqsKFC9+0/0TAGKNz587pyJEjkqRSpUpluy9CHQAAyFOpqan2QFe8eHF3l+N2fn5+kqQjR44oNDQ024diuVACAADkqfRz6AoXLuzmSvKP9H1xI+cXEuoAAIBb3KyHXDOTE/uCUAcAAGABhDoAAAAL4EIJAACQL0QN+yZPx0scF+3yNrGxsfr4448lXb6/XEREhLp166YXXnhBhQoVUmpqqiZMmKAZM2Zo165d8vPz05133qmXXnpJjRo1yumX4ICZOgAAABfce++9OnTokHbt2qVnnnlGo0aN0ltvvSVjjDp16qQxY8Zo0KBB2r59u1atWqXw8HA1a9ZMX375Za7WxUwdAACAC3x8fFSyZElJUt++fbVgwQItXLhQ5cuX17x587Rw4UK1a9fOvv6UKVN0/PhxPf7447r77rvl7++fK3UxUwcAAHAD/Pz8dOHCBSUkJKhy5coOgS7dM888o+PHj2v58uW5VgehDgAAIBuMMVqxYoWWLl2qFi1aaOfOnbrlllsyXTe9fefOnblWD4df86NRQXk4VlLejQUAgAUsWrRIAQEBunjxotLS0vToo49q1KhRWrRokYwxbquLUAcAAOCC5s2ba9KkSfL29lbp0qVVqNDlOFW5cmVt3749023S2ytXrpxrdXH4FQAAwAX+/v6qWLGiIiIi7IFOkjp16qRdu3bp66+/zrDNO++8o+LFi+vuu+/OtboIdQAAADmgU6dO6tChg7p3767p06crMTFRf/zxh/r06aOFCxdq2rRpuXblq0SoAwAAyBE2m01z587VCy+8oPfee09VqlRR48aN9ffff2vVqlWKiYnJ3fGNO8/ou0GnT59WUFCQkpKSVKRIEXeXk3O4UAIAYGHnz5/Xvn37VK5cOfn6+rq7nHzhWvvE2bzDTB0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAD/UQLWwVXDAICbGDN1AAAAFkCoAwAAsABCHQAAgAW4NdSNGjVKNpvN4VG1alV3lgQAAFAguf1CierVq2vFihX254UKub0kAADgDnl5wZuUrYveYmNjderUKaWmpurixYtasmRJhnXWrFmjJk2a6Pfff1etWrVyolKnuD1BFSpUSCVLlnR3GQAAAE7r1auXHnzwQf3vf/9T2bJlHZbFxcWpbt26eRropHxwTt2uXbtUunRplS9fXl26dNH+/fvdXRIAAMA13XfffQoJCVF8fLxDe3Jysj7//HP16tUrz2tya6irX7++4uPjtWTJEk2aNEn79u1T48aNdebMmUzXT0lJ0enTpx0eAAAAea1QoULq1q2b4uPjZYyxt3/++edKTU1V586d87wmt4a6Nm3aqGPHjqpVq5Zat26tb7/9VqdOndLcuXMzXX/s2LEKCgqyP8LDw/O4YgAAgMt69uypPXv2aPXq1fa2uLg4PfjggwoKyuPzA5UPzqm7UtGiRVW5cmXt3r070+XDhw/XkCFD7M9Pnz5NsANuRAE4KRkA8quqVauqYcOGmjFjhpo1a6bdu3drzZo1GjNmjFvqcfs5dVdKTk7Wnj17VKpUqUyX+/j4qEiRIg4PAAAAd+nVq5fmz5+vM2fOKC4uThUqVFDTpk3dUotbQ93QoUO1evVqJSYmat26derQoYM8PT3dchwaAADAVQ8//LA8PDyUkJCgTz75RD179pTNZnNLLW49/Pq///1PnTt31vHjxxUSEqK77rpLGzZsUEhIiDvLAgAAcEpAQIAeeeQRDR8+XKdPn1ZsbKzbanFrqJs9e7Y7hwcAALhhvXr10vTp09W2bVuVLl3abXXkqwslAKBAyMsLTLi4BDeTAvB5v/q+dJLUoEEDh9uauEu+ulACAAAA2UOoAwAAsABCHQAAgAUQ6gAAACyAUAcAAGABXP0KAADcIi0tLXc6Pvhb7vSbmdK1c6SbnNgXhDoAAJCnvL295eHhoYMHDyokJETe3t45+18YLuXh7UXOn7+hzY0xunDhgo4ePSoPDw95e3tnuy9CHQAAyFMeHh4qV66cDh06pIMHD+b8AKeO5nyfWTm7L0e6KVy4sCIiIuThkf0z4wh1AAAgz3l7eysiIkKXLl1Sampqznb+Qcec7e9a+v9yw114enqqUKFCNzxbSagDAABuYbPZ5OXlJS8vr5ztOPlAzvZ3Lb6+eTfWdXD1KwAAgAUQ6gAAACyAUAcAAGABhDoAAAALINQBAABYAKEOAADAAgh1AAAAFkCoAwAAsABCHQAAgAUQ6gAAACyAfxMGAMgbo4LycKykvBsLyCeYqQMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAAC8g3oW7cuHGy2Wx6+umn3V0KAABAgZMvQt3GjRv10UcfqVatWu4uBQAAoEBye6hLTk5Wly5dNHXqVBUrVszd5QAAABRIbg91/fr1U3R0tFq1anXddVNSUnT69GmHBwAAAKRC7hx89uzZ2rRpkzZu3OjU+mPHjtXo0aNzuSoAAICCx20zdQcOHNCgQYM0c+ZM+fr6OrXN8OHDlZSUZH8cOHAgl6sEAAAoGNw2U/frr7/qyJEjuv322+1tqamp+uGHH/TBBx8oJSVFnp6eDtv4+PjIx8cnr0sFAADI99wW6lq2bKktW7Y4tPXo0UNVq1bV888/nyHQAQAAIGtuC3WBgYGqUaOGQ5u/v7+KFy+eoR0AAADX5varXwEAAHDj3Hr169VWrVrl7hIAAAAKJGbqAAAALIBQBwAAYAGEOgAAAAsg1AEAAFgAoQ4AAMACCHUAAAAWQKgDAACwAKdD3fr167Vo0SKHtk8++UTlypVTaGionnjiCaWkpOR4gQAAALg+p0PdmDFj9Oeff9qfb9myRb169VKrVq00bNgwff311xo7dmyuFAkAAIBrczrUbd68WS1btrQ/nz17turXr6+pU6dqyJAhmjBhgubOnZsrRQIAAODanA51J0+eVFhYmP356tWr1aZNG/vzevXq6cCBAzlbHQAAAJzidKgLCwvTvn37JEkXLlzQpk2bdOedd9qXnzlzRl5eXjlfIQAAAK7L6VDXtm1bDRs2TGvWrNHw4cNVuHBhNW7c2L78jz/+UIUKFXKlSAAAAFxbIWdXfOWVV/TAAw+oadOmCggIUHx8vLy9ve3LZ8yYoXvuuSdXigQA4KY0KigPx0rKu7GQK5wOdSVKlNAPP/ygpKQkBQQEyNPT02H5559/roCAgBwvEAAAANfndKhLFxQUpFOnTmn37t2SpIoVK6po0aIKDg7O8eIAAADgHJf+o0RiYqKio6NVokQJ1a9fX/Xr11eJEiV03333KTExMZdKBAAAwPU4PVN34MAB3XnnnfLy8tIrr7yiW265RZK0bds2TZo0SQ0aNNDGjRtVtmzZXCsWAAAAmXM61I0aNUpVqlTR0qVL5evra2+PiYnR4MGDde+992rUqFGaNm1arhQKAACArDkd6pYsWaI5c+Y4BLp0fn5+euWVV9SpU6ccLQ4AAADOcfqcumPHjikqKirL5eXLl9eJEydyoiYAAAC4yOlQV6pUKW3bti3L5Vu3blXJkiVzpCgAAAC4xulQFxMTo6FDh+ro0aMZlh05ckTPP/+8YmJicrI2AAAAOMnpc+pGjhypb7/9VhUqVFDXrl1VtWpVGWO0fft2JSQkqGTJkhoxYkRu1goAAIAsOB3qihUrpp9++kkvvPCCZs+erVOnTkmSihYtqkcffVSvv/46NyAGAFhe1LBv8mysxIzXJgJZcunmw8WKFdOkSZN0/PhxHT58WIcPH9bx48c1efJkXbp0Sa+//npu1QkAAIBrcCnUpbPZbAoNDVVoaKhsNpsk6dChQ3r55ZdztDgAAAA4J1uhDgAAAPkLoQ4AAMACCHUAAAAW4PTVr0OGDLnm8szuXwcAAIC84XSo++233667TpMmTW6oGAAAAGSP06Fu5cqVuVkHAAAAbgDn1AEAAFgAoQ4AAMACCHUAAAAWQKgDAACwAEIdAACABTh99Wu6P/74I9N2m80mX19fRUREyMfH54YLAwAAgPNcDnW33XabbDZblsu9vLz0yCOP6KOPPpKvr+8NFQcAAADnuHz4dcGCBapUqZKmTJmizZs3a/PmzZoyZYqqVKmihIQETZ8+Xd9//71eeuml3KgXAAAAmXB5pu61117T+PHj1bp1a3tbzZo1VbZsWb388sv6+eef5e/vr2eeeUZvv/12jhYLAACAzLk8U7dlyxZFRkZmaI+MjNSWLVskXT5Ee+jQoRuvDgAAAE5xOdRVrVpV48aN04ULF+xtFy9e1Lhx41S1alVJ0j///KOwsLCcqxIAAADX5PLh14kTJ6p9+/YqW7asatWqJeny7F1qaqoWLVokSdq7d6+eeuqpnK3UzaKGfZNnYyVyfQkAAHCRy6GuYcOG2rdvn2bOnKmdO3dKkjp27KhHH31UgYGBkqTHHnssZ6sEAADANbkc6iQpMDBQTz75ZE7XAgAAgGzKVqjbtWuXVq5cqSNHjigtLc1h2YgRI3KkMAAAADjP5VA3depU9e3bVyVKlFDJkiUdbkRss9kIdQAAAG7gcqh79dVX9dprr+n555/PjXoAAACQDS7f0uTkyZPq2LFjbtQCAACAbHI51HXs2FHLli3LjVoAAACQTS4ffq1YsaJefvllbdiwQTVr1pSXl5fD8oEDB+ZYcQAAAHCOy6FuypQpCggI0OrVq7V69WqHZTabjVAHAADgBi6Hun379uVGHQAAALgBLp9TBwAAgPzHqZm6IUOG6JVXXpG/v7+GDBlyzXXffffdHCkMAAAAznMq1P3222+6ePGi/eusXHkjYgAAAOQdp0LdypUrM/36Rk2aNEmTJk1SYmKiJKl69eoaMWKE2rRpk2NjAAAA3Azcek5d2bJlNW7cOP3666/65Zdf1KJFC91///36888/3VkWAABAgePy1a9nz57VuHHj9N133+nIkSNKS0tzWL53716n+2rXrp3D89dee02TJk3Shg0bVL16dVdLAwAAuGm5HOoef/xxrV69Wo899phKlSqVY+fRpaam6vPPP9fZs2fVoEGDTNdJSUlRSkqK/fnp06dzZGwAAICCzuVQt3jxYn3zzTdq1KhRjhSwZcsWNWjQQOfPn1dAQIAWLFigatWqZbru2LFjNXr06BwZFwAAwEpcPqeuWLFiCg4OzrECqlSpos2bN+unn35S37591b17d23bti3TdYcPH66kpCT748CBAzlWBwAAQEHmcqh75ZVXNGLECJ07dy5HCvD29lbFihVVp04djR07VrfeeqvGjx+f6bo+Pj4qUqSIwwMAAADZOPz6zjvvaM+ePQoLC1NUVJS8vLwclm/atOmGCkpLS3M4bw4AAADX53Koi4mJybHBhw8frjZt2igiIkJnzpxRQkKCVq1apaVLl+bYGAAAADcDl0PdyJEjc2zwI0eOqFu3bjp06JCCgoJUq1YtLV26VHfffXeOjQEAAHAzcDnU5aTp06e7c3gAAADLcCrUBQcHa+fOnSpRooSKFSt2zXvTnThxIseKAwAAgHOcCnXvvfeeAgMDJUnvv/9+btYDAACAbHAq1HXv3j3TrwEAAJA/3NA5defPn9eFCxcc2rh3HAAAQN5z+ebDZ8+eVf/+/RUaGip/f38VK1bM4QEAAIC853Koe+655/T9999r0qRJ8vHx0bRp0zR69GiVLl1an3zySW7UCAAAgOtw+fDr119/rU8++UTNmjVTjx491LhxY1WsWFGRkZGaOXOmunTpkht1AgAA4Bpcnqk7ceKEypcvL+ny+XPptzC566679MMPP+RsdQAAAHCKy6GufPny2rdvnySpatWqmjt3rqTLM3hFixbN0eIAAADgHJdDXY8ePfT7779LkoYNG6aJEyfK19dXgwcP1rPPPpvjBQIAAOD6XD6nbvDgwfavW7Vqpb/++ku//vqrKlasqFq1auVocQAAAHDODf/v18jISEVGRuZELQAAAMimbIW6jRs3auXKlTpy5IjS0tIclr377rs5UhgAAACc53Koe/311/XSSy+pSpUqCgsLk81msy+78msAAADkHZdD3fjx4zVjxgzFxsbmQjkAAADIDpevfvXw8FCjRo1yoxYAAABkk8uhbvDgwZo4cWJu1AIAAIBscvnw69ChQxUdHa0KFSqoWrVq8vLyclj+xRdf5FhxAAAAcI7LoW7gwIFauXKlmjdvruLFi3NxBAAAQD7gcqj7+OOPNX/+fEVHR+dGPQAAAMgGl8+pCw4OVoUKFXKjFgAAAGSTy6Fu1KhRGjlypM6dO5cb9QAAACAbXD78OmHCBO3Zs0dhYWGKiorKcKHEpk2bcqw4AAAAOMflUBcTE5MLZQAAAOBGuBzqRo4cmRt1AAAA4Aa4fE6dJJ06dUrTpk3T8OHDdeLECUmXD7v+888/OVocAAAAnOPyTN0ff/yhVq1aKSgoSImJierdu7eCg4P1xRdfaP/+/frkk09yo04AAABcg8szdUOGDFFsbKx27dolX19fe3vbtm31ww8/5GhxAAAAcI7LoW7jxo3q06dPhvYyZcro8OHDOVIUAAAAXONyqPPx8dHp06cztO/cuVMhISE5UhQAAABc43Koa9++vcaMGaOLFy9Kkmw2m/bv36/nn39eDz74YI4XCAAAgOtzOdS98847Sk5OVmhoqP777z81bdpUFStWVGBgoF577bXcqBEAAADX4fLVr0FBQVq+fLnWrl2r33//XcnJybr99tvVqlWr3KgPAAAATnAp1F28eFF+fn7avHmzGjVqpEaNGuVWXQAAAHCBS4dfvby8FBERodTU1NyqBwAAANng8jl1L774ol544QX7f5IAAACA+7l8Tt0HH3yg3bt3q3Tp0oqMjJS/v7/D8k2bNuVYcQAAAHCOy6EuJiYmF8oAAADAjXA51I0cOTI36gAAAMANcPmcOgAAAOQ/hDoAAAALINQBAABYAKEOAADAAgh1AAAAFuDy1a+pqamKj4/Xd999pyNHjigtLc1h+ffff59jxQEAAMA5Loe6QYMGKT4+XtHR0apRo4ZsNltu1AUAAAAXuBzqZs+erblz56pt27a5UQ8AAACyweVz6ry9vVWxYsXcqAUAAADZ5PJM3TPPPKPx48frgw8+4NArABRwUcO+ybOxEn3zbCjgpuRyqPvxxx+1cuVKLV68WNWrV5eXl5fD8i+++CLHigMAAIBzXA51RYsWVYcOHXKjFgAAAGSTy6EuLi4uN+oAAADADeDmwwAAABbg8kydJM2bN09z587V/v37deHCBYdlmzZtypHCAAAA4DyXZ+omTJigHj16KCwsTL/99pvuuOMOFS9eXHv37lWbNm1yo0YAAABch8szdR9++KGmTJmizp07Kz4+Xs8995zKly+vESNG6MSJE7lRIwowbpfgOvYZACA7XJ6p279/vxo2bChJ8vPz05kzZyRJjz32mGbNmpWz1QEAAMApLs/UlSxZUidOnFBkZKQiIiK0YcMG3Xrrrdq3b5+MMblRIwBcFzOcAG52Ls/UtWjRQgsXLpQk9ejRQ4MHD9bdd9+tRx55xOX7140dO1b16tVTYGCgQkNDFRMTox07drhaEgAAwE3P5Zm6KVOmKC0tTZLUr18/FS9eXOvWrVP79u3Vp08fl/pavXq1+vXrp3r16unSpUt64YUXdM8992jbtm3y9/d3tTQAAICblsuhzsPDQx4e/zfB16lTJ3Xq1Clbgy9ZssTheXx8vEJDQ/Xrr7+qSZMm2eoTAADgZpStmw+vWbNGXbt2VYMGDfTPP/9Ikj799FP9+OOPN1RMUlKSJCk4ODjT5SkpKTp9+rTDAwAAANkIdfPnz1fr1q3l5+en3377TSkpKZIuB7LXX38924WkpaXp6aefVqNGjVSjRo1M1xk7dqyCgoLsj/Dw8GyPBwAAYCUuh7pXX31VkydP1tSpU+Xl5WVvb9So0Q39N4l+/fpp69atmj17dpbrDB8+XElJSfbHgQMHsj0eAACAlbh8Tt2OHTsyPd8tKChIp06dylYR/fv316JFi/TDDz+obNmyWa7n4+MjHx+fbI0BAABgZS7P1JUsWVK7d+/O0P7jjz+qfPnyLvVljFH//v21YMECff/99ypXrpyr5QAAAEDZCHW9e/fWoEGD9NNPP8lms+ngwYOaOXOmhg4dqr59+7rUV79+/fTZZ58pISFBgYGBOnz4sA4fPqz//vvP1bIAAABuai4ffh02bJjS0tLUsmVLnTt3Tk2aNJGPj4+GDh2qAQMGuNTXpEmTJEnNmjVzaI+Li1NsbKyrpQEAANy0XA51NptNL774op599lnt3r1bycnJqlatmgICAlwenH8rBgAAkDNcDnXpvL29Va1atZysBQAAANnkdKjr2bOnU+vNmDEj28UAAAAge5wOdfHx8YqMjFTt2rU5bAoAAJDPOB3q+vbtq1mzZmnfvn3q0aOHunbtmuW/8wIAAEDecvqWJhMnTtShQ4f03HPP6euvv1Z4eLgefvhhLV26lJk7AAAAN3PpPnU+Pj7q3Lmzli9frm3btql69ep66qmnFBUVpeTk5NyqEQAAANfh8s2H7Rt6eMhms8kYo9TU1JysCQAAAC5yKdSlpKRo1qxZuvvuu1W5cmVt2bJFH3zwgfbv35+t+9QBAAAgZzh9ocRTTz2l2bNnKzw8XD179tSsWbNUokSJ3KwNAAAATnI61E2ePFkREREqX768Vq9erdWrV2e63hdffJFjxQEAAMA5Toe6bt26yWaz5WYtAAAAyCaXbj4MAACA/CnbV78CAAAg/yDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFFHJ3AQAAwPqihn2TZ2Ml+ubZUPkKM3UAAAAWQKgDAACwAEIdAACABRDqAAAALIBQBwAAYAGEOgAAAAsg1AEAAFgAoQ4AAMACCHUAAAAWQKgDAACwAEIdAACABRDqAAAALIBQBwAAYAGEOgAAAAsg1AEAAFiAW0PdDz/8oHbt2ql06dKy2Wz68ssv3VkOAABAgeXWUHf27FndeuutmjhxojvLAAAAKPAKuXPwNm3aqE2bNu4sAQAAwBI4pw4AAMAC3DpT56qUlBSlpKTYn58+fdqN1QAAAOQfBWqmbuzYsQoKCrI/wsPD3V0SAABAvlCgQt3w4cOVlJRkfxw4cMDdJQEAAOQLBerwq4+Pj3x8fNxdBgAAQL7j1lCXnJys3bt325/v27dPmzdvVnBwsCIiItxYGQAAQMHi1lD3yy+/qHnz5vbnQ4YMkSR1795d8fHxbqoKAACg4HFrqGvWrJmMMe4sAQAAwBIK1IUSAAAAyByhDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAMAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwALyRaibOHGioqKi5Ovrq/r16+vnn392d0kAAAAFittD3Zw5czRkyBCNHDlSmzZt0q233qrWrVvryJEj7i4NAACgwHB7qHv33XfVu3dv9ejRQ9WqVdPkyZNVuHBhzZgxw92lAQAAFBhuDXUXLlzQr7/+qlatWtnbPDw81KpVK61fv96NlQEAABQshdw5+LFjx5SamqqwsDCH9rCwMP31118Z1k9JSVFKSor9eVJSkiTp9OnTuVuopLSUc7k+RrrTNpNnYymX9x37zXWW3WcS+y1bg/E9mr3B+Ky5PhiftewNlvsZJD3nGHPt1+XWUOeqsWPHavTo0Rnaw8PD3VBN7gnKy8HG5elouYr95ro8fxXsN9dZZJ9J7LfsYJ9lj1X325kzZxQUlPV4bg11JUqUkKenp/7991+H9n///VclS5bMsP7w4cM1ZMgQ+/O0tDSdOHFCxYsXl81my/V688Lp06cVHh6uAwcOqEiRIu4up8Bgv7mOfZY97LfsYb+5jn2WPVbcb8YYnTlzRqVLl77mem4Ndd7e3qpTp46+++47xcTESLoc1L777jv1798/w/o+Pj7y8fFxaCtatGgeVJr3ihQpYpkPY15iv7mOfZY97LfsYb+5jn2WPVbbb9eaoUvn9sOvQ4YMUffu3VW3bl3dcccdev/993X27Fn16NHD3aUBAAAUGG4PdY888oiOHj2qESNG6PDhw7rtttu0ZMmSDBdPAAAAIGtuD3WS1L9//0wPt96MfHx8NHLkyAyHmXFt7DfXsc+yh/2WPew317HPsudm3m82c73rYwEAAJDvuf0/SgAAAODGEeoAAAAsgFAHAABgAYS6fOKHH35Qu3btVLp0adlsNn355ZfuLqlAGDt2rOrVq6fAwECFhoYqJiZGO3bscHdZ+dqkSZNUq1Yt+z2cGjRooMWLF7u7rAJl3Lhxstlsevrpp91dSr42atQo2Ww2h0fVqlXdXVaB8M8//6hr164qXry4/Pz8VLNmTf3yyy/uLitfi4qKyvB5s9ls6tevn7tLyzOEunzi7NmzuvXWWzVx4kR3l1KgrF69Wv369dOGDRu0fPlyXbx4Uffcc4/Onj3r7tLyrbJly2rcuHH69ddf9csvv6hFixa6//779eeff7q7tAJh48aN+uijj1SrVi13l1IgVK9eXYcOHbI/fvzxR3eXlO+dPHlSjRo1kpeXlxYvXqxt27bpnXfeUbFixdxdWr62ceNGh8/a8uXLJUkdO3Z0c2V5J1/c0gRSmzZt1KZNG3eXUeAsWbLE4Xl8fLxCQ0P166+/qkmTJm6qKn9r166dw/PXXntNkyZN0oYNG1S9enU3VVUwJCcnq0uXLpo6dapeffVVd5dTIBQqVCjTf/uIrL3xxhsKDw9XXFycva1cuXJurKhgCAkJcXg+btw4VahQQU2bNnVTRXmPmTpYSlJSkiQpODjYzZUUDKmpqZo9e7bOnj2rBg0auLucfK9fv36Kjo5Wq1at3F1KgbFr1y6VLl1a5cuXV5cuXbR//353l5TvLVy4UHXr1lXHjh0VGhqq2rVra+rUqe4uq0C5cOGCPvvsM/Xs2dMy/xveGczUwTLS0tL09NNPq1GjRqpRo4a7y8nXtmzZogYNGuj8+fMKCAjQggULVK1aNXeXla/Nnj1bmzZt0saNG91dSoFRv359xcfHq0qVKjp06JBGjx6txo0ba+vWrQoMDHR3efnW3r17NWnSJA0ZMkQvvPCCNm7cqIEDB8rb21vdu3d3d3kFwpdffqlTp04pNjbW3aXkKUIdLKNfv37aunUr5+w4oUqVKtq8ebOSkpI0b948de/eXatXrybYZeHAgQMaNGiQli9fLl9fX3eXU2BceUpJrVq1VL9+fUVGRmru3Lnq1auXGyvL39LS0lS3bl29/vrrkqTatWtr69atmjx5MqHOSdOnT1ebNm1UunRpd5eSpzj8Ckvo37+/Fi1apJUrV6ps2bLuLiff8/b2VsWKFVWnTh2NHTtWt956q8aPH+/usvKtX3/9VUeOHNHtt9+uQoUKqVChQlq9erUmTJigQoUKKTU11d0lFghFixZV5cqVtXv3bneXkq+VKlUqwx9Yt9xyC4eunfT3339rxYoVevzxx91dSp5jpg4FmjFGAwYM0IIFC7Rq1SpOJs6mtLQ0paSkuLuMfKtly5basmWLQ1uPHj1UtWpVPf/88/L09HRTZQVLcnKy9uzZo8cee8zdpeRrjRo1ynBrpp07dyoyMtJNFRUscXFxCg0NVXR0tLtLyXOEunwiOTnZ4a/Xffv2afPmzQoODlZERIQbK8vf+vXrp4SEBH311VcKDAzU4cOHJUlBQUHy8/Nzc3X50/Dhw9WmTRtFRETozJkzSkhI0KpVq7R06VJ3l5ZvBQYGZjhP09/fX8WLF+f8zWsYOnSo2rVrp8jISB08eFAjR46Up6enOnfu7O7S8rXBgwerYcOGev311/Xwww/r559/1pQpUzRlyhR3l5bvpaWlKS4uTt27d1ehQjdhxDHIF1auXGkkZXh0797d3aXla5ntM0kmLi7O3aXlWz179jSRkZHG29vbhISEmJYtW5ply5a5u6wCp2nTpmbQoEHuLiNfe+SRR0ypUqWMt7e3KVOmjHnkkUfM7t273V1WgfD111+bGjVqGB8fH1O1alUzZcoUd5dUICxdutRIMjt27HB3KW5hM8YY98RJAAAA5BQulAAAALAAQh0AAIAFEOoAAAAsgFAHAABgAYQ6AAAACyDUAQAAWAChDgAAwAIIdQAAABZAqAOcFBUVpffffz9PxoqPj1fRokXzZKyCZtSoUbrtttvyTT/IP/Lb901e/swAJEIdbkKxsbGy2Wyy2Wzy9vZWxYoVNWbMGF26dOma223cuFFPPPFEHlWJnGSz2fTll186tA0dOlTfffddro57Zch45513VKxYMZ0/fz7DeufOnVORIkU0YcKETPuJjY1VTExMLlbqKL8F3lWrVslms+nUqVPuLiVT+S1M4uZFqMNN6d5779WhQ4e0a9cuPfPMMxo1apTeeuutTNe9cOGCJCkkJESFCxfO9pjp/SB/CAgIUPHixfNsvMcee0xnz57VF198kWHZvHnzdOHCBXXt2vWGxrh48eINbQ+gYCPU4abk4+OjkiVLKjIyUn379lWrVq20cOFCSf83K/Laa6+pdOnSqlKliqSMh1L279+v+++/XwEBASpSpIgefvhh/fvvv/bl6bMd06ZNU7ly5eTr65tlPfHx8YqIiFDhwoXVoUMHHT9+3GH5nj17dP/99yssLEwBAQGqV6+eVqxYYV8+ZswY1ahRI0O/t912m15++WVJl2c77rjjDvn7+6to0aJq1KiR/v777yxr+t///qfOnTsrODhY/v7+qlu3rn766SeHfXSlp59+Ws2aNbM/b9asmQYMGKCnn35axYoVU1hYmKZOnaqzZ8+qR48eCgwMVMWKFbV48WKH/XD1jMeXX34pm82WZZ0bN27U3XffrRIlSigoKEhNmzbVpk2b7MujoqIkSR06dJDNZrM/v3I2atmyZfL19c0wEzRo0CC1aNHC/vzHH39U48aN5efnp/DwcA0cOFBnz57NsrYrhYaGql27dpoxY0aGZTNmzFBMTIyCg4MzLBs1apQ+/vhjffXVV/YZ5lWrVikxMVE2m01z5sxR06ZN5evrq5kzZ0qSpk2bpltuuUW+vr6qWrWqPvzwQ4c+n3/+eVWuXFmFCxdW+fLl9fLLL9sDYXx8vEaPHq3ff//dPl58fLykyzOeH330ke677z4VLlxYt9xyi9avX6/du3erWbNm8vf3V8OGDbVnzx6H8b766ivdfvvt8vX1Vfny5TV69GiHmXGbzaZp06apQ4cOKly4sCpVqmT/fkxMTFTz5s0lScWKFZPNZlNsbKxT+/xGx063cOFCVapUSb6+vmrevLk+/vhj+8zhqlWr1KNHDyUlJdn316hRo+zbnjt3Tj179lRgYKAiIiI0ZcoUp2sHXGaAm0z37t3N/fff79DWvn17c/vtt9uXBwQEmMcee8xs3brVbN261RhjTGRkpHnvvfeMMcakpqaa2267zdx1113ml19+MRs2bDB16tQxTZs2tfc5cuRI4+/vb+69916zadMm8/vvv2daz4YNG4yHh4d54403zI4dO8z48eNN0aJFTVBQkH2dzZs3m8mTJ5stW7aYnTt3mpdeesn4+vqav//+2xhjzIEDB4yHh4f5+eef7dts2rTJ2Gw2s2fPHnPx4kUTFBRkhg4danbv3m22bdtm4uPj7dtf7cyZM6Z8+fKmcePGZs2aNWbXrl1mzpw5Zt26dVnuw0GDBjm8/qZNm5rAwEDzyiuvmJ07d5pXXnnFeHp6mjZt2pgpU6aYnTt3mr59+5rixYubs2fPGmOMiYuLc3jdxhizYMECc+WPqpEjR5pbb73V/vy7774zn376qdm+fbvZtm2b6dWrlwkLCzOnT582xhhz5MgRI8nExcWZQ4cOmSNHjmTo59KlSyYsLMxMmzbN3u/Vbbt37zb+/v7mvffeMzt37jRr1641tWvXNrGxsZnuw8xezzfffGNsNptJTEy0t+3Zs8fYbDazbNmyTPs4c+aMefjhh829995rDh06ZA4dOmRSUlLMvn37jCQTFRVl5s+fb/bu3WsOHjxoPvvsM1OqVCl72/z5801wcLCJj4+39/nKK6+YtWvXmn379pmFCxeasLAw88YbbxhjjDl37px55plnTPXq1e3jnTt3zhhjjCRTpkwZM2fOHLNjxw4TExNjoqKiTIsWLcySJUvMtm3bzJ133mnuvfde+1g//PCDKVKkiImPjzd79uwxy5YtM1FRUWbUqFH2dSSZsmXLmoSEBLNr1y4zcOBAExAQYI4fP24uXbpk5s+fbySZHTt2mEOHDplTp045tb9vdGxjjNm7d6/x8vIyQ4cONX/99ZeZNWuWKVOmjJFkTp48aVJSUsz7779vihQpYt9fZ86cMcZc/pkRHBxsJk6caHbt2mXGjh1rPDw8zF9//ZXlZwa4EYQ63HSuDCRpaWlm+fLlxsfHxwwdOtS+PCwszKSkpDhsd2WoW7ZsmfH09DT79++3L//zzz+NJHuwGjlypPHy8rKHiKx07tzZtG3b1qHtkUceyRBurla9enXz//7f/7M/b9Omjenbt6/9+YABA0yzZs2MMcYcP37cSDKrVq26Zp/pPvroIxMYGGj/xXY1Z0PdXXfdZX9+6dIl4+/vbx577DF726FDh4wks379emNM9kLd1VJTU01gYKD5+uuv7W2SzIIFCxzWu7qfQYMGmRYtWtifL1261Pj4+JiTJ08aY4zp1auXeeKJJxz6WLNmjfHw8DD//fdfprVc/XouXbpkypQpY0aOHGlve/nll01ERIRJTU3N8jVltr/TQ93777/v0F6hQgWTkJDg0PbKK6+YBg0aZNn/W2+9ZerUqWN/ntU+lmReeukl+/P169cbSWb69On2tlmzZhlfX1/785YtW5rXX3/doZ9PP/3UlCpVKst+k5OTjSSzePFiY4wxK1eutIeoa7l6f+fE2M8//7ypUaOGQx8vvviiQz2ZfW6Nufwzo2vXrvbnaWlpJjQ01EyaNOmarwPILg6/4qa0aNEiBQQEyNfXV23atNEjjzzicMikZs2a8vb2znL77du3Kzw8XOHh4fa2atWqqWjRotq+fbu9LTIyUiEhIdesZfv27apfv75DW4MGDRyeJycna+jQobrllltUtGhRBQQEaPv27dq/f799nd69e2vWrFk6f/68Lly4oISEBPXs2VOSFBwcrNjYWLVu3Vrt2rXT+PHjdejQoSxr2rx5s2rXrp3p4UBX1KpVy/61p6enihcvrpo1a9rbwsLCJElHjhzJ9hj//vuvevfurUqVKikoKEhFihRRcnKyw75xRpcuXbRq1SodPHhQkjRz5kxFR0fbDwf//vvvio+PV0BAgP3RunVrpaWlad++fU6N4enpqe7duys+Pl7GGKWlpenjjz9Wjx495OGRvR/HdevWtX999uxZ7dmzR7169XKo89VXX3U4JDpnzhw1atRIJUuWVEBAgF566SWn99eV72n6+3f1e3r+/HmdPn1a0uX9NmbMGId6evfurUOHDuncuXOZ9uvv768iRYrc0Ocip8besWOH6tWr59DvHXfc4XQNV/Zts9lUsmTJG35dQFYKubsAwB2aN2+uSZMmydvbW6VLl1ahQo7fCv7+/jkyTk71M3ToUC1fvlxvv/22KlasKD8/Pz300EMOF1+0a9dOPj4+WrBggby9vXXx4kU99NBD9uVxcXEaOHCglixZojlz5uill17S8uXLdeedd2YYz8/P75r1eHh4yBjj0JbZSfpeXl4Oz202m0Nb+rlyaWlpLvV7pe7du+v48eMaP368IiMj5ePjowYNGrh8YUq9evVUoUIFzZ49W3379tWCBQvs55JJl4N1nz59NHDgwAzbRkREOD1Oz549NXbsWH3//fdKS0vTgQMH1KNHD5dqvdKVn7Hk5GRJ0tSpUzP8oeDp6SlJWr9+vbp06aLRo0erdevWCgoK0uzZs/XOO+84NV5m79+13tPk5GSNHj1aDzzwQIa+rjzPNLPPSnof2eXOsfOib+BqhDrclPz9/VWxYsVsb3/LLbfowIEDOnDggH22btu2bTp16pSqVavmcl/pFyCk27Bhg8PztWvXKjY2Vh06dJB0+ZdVYmKiwzqFChVS9+7dFRcXJ29vb3Xq1ClDOKtdu7Zq166t4cOHq0GDBkpISMg01NWqVUvTpk3TiRMnMp2tCwkJ0datWx3aNm/enOEXmKtCQkJ05swZnT171h5WNm/efM1t1q5dqw8//FBt27aVJB04cEDHjh1zWMfLy0upqanXHb9Lly6aOXOmypYtKw8PD0VHR9uX3X777dq2bdsNfW4kqUKFCmratKlmzJghY4xatWqlyMjIa27j7e3tVP1hYWEqXbq09u7dqy5dumS6zrp16xQZGakXX3zR3nb1BTPOjueM22+/XTt27Lih/ZY+a+5qTTkxdpUqVfTtt986tG3cuDFDfTm1v4AbweFXIBtatWqlmjVrqkuXLtq0aZN+/vlndevWTU2bNnU4HOaM9Nmzt99+W7t27dIHH3ygJUuWOKxTqVIlffHFF9q8ebN+//13Pfroo5n+tf/444/r+++/15IlS+yHXiVp3759Gj58uNavX6+///5by5Yt065du3TLLbdkWlPnzp1VsmRJxcTEaO3atdq7d6/mz5+v9evXS5JatGihX375RZ988ol27dqlkSNHZgh52VG/fn0VLlxYL7zwgvbs2aOEhASH2bLMVKpUSZ9++qm2b9+un376SV26dMkQZqOiovTdd9/p8OHDOnnyZJZ9pb+fr732mh566CH5+PjYlz3//PNat26d+vfvr82bN2vXrl366quv1L9/f5dfZ69evfTFF19owYIF6tWr13XXj4qK0h9//KEdO3bo2LFj15y9HD16tMaOHasJEyZo586d2rJli+Li4vTuu+9Kury/9u/fr9mzZ2vPnj2aMGGCFixYkGG8ffv2afPmzTp27JhSUlJcfo3pRowYoU8++USjR4/Wn3/+qe3bt2v27Nl66aWXnO4jMjJSNptNixYt0tGjR+0zknkxdp8+ffTXX3/p+eef186dOzV37lyHq4Gly/srOTlZ3333nY4dO+ZwaBfIS4Q6IBtsNpu++uorFStWTE2aNFGrVq1Uvnx5zZkzx+W+7rzzTk2dOlXjx4/XrbfeqmXLlmX4pfPuu++qWLFiatiwodq1a6fWrVvr9ttvz9BXpUqV1LBhQ1WtWtXh8FvhwoX1119/6cEHH1TlypX1xBNPqF+/furTp0+mNXl7e2vZsmUKDQ1V27ZtVbNmTY0bN85+CK9169Z6+eWX9dxzz6levXo6c+aMunXr5vJrv1pwcLA+++wzffvtt6pZs6ZmzZrlcK5jZqZPn66TJ0/q9ttv12OPPaaBAwcqNDTUYZ133nlHy5cvV3h4uGrXrp1lXxUrVtQdd9yhP/74I8NMV61atbR69Wrt3LlTjRs3Vu3atTVixAiVLl3a5df54IMPysfHR4ULF3bqpsK9e/dWlSpVVLduXYWEhGjt2rVZrvv4449r2rRpiouLU82aNdW0aVPFx8erXLlykqT27dtr8ODB6t+/v2677TatW7fOftubK+u799571bx5c4WEhGjWrFkuv8Z0rVu31qJFi7Rs2TLVq1dPd955p957773rzk5eqUyZMho9erSGDRumsLAwp4N0Toxdrlw5zZs3T1988YVq1aqlSZMm2Wc500N/w4YN9eSTT+qRRx5RSEiI3nzzTaf7B3KSzVx9AguAAssYo0qVKumpp57SkCFD3F0OYEmvvfaaJk+erAMHDri7FMAB59QBFnH06FHNnj1bhw8fvqET7wE4+vDDD1WvXj0VL15ca9eu1VtvvZWtw+5AbiPUARYRGhqqEiVKaMqUKSpWrJi7ywEsY9euXXr11Vd14sQJRURE6JlnntHw4cPdXRaQAYdfAQAALIALJQAAACyAUAcAAGABhDoAAAALINQBAABYAKEOAADAAgh1AAAAFkCoAwAAsABCHQAAgAUQ6gAAACzg/wPbY3D+dMY9nAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels = ['1', '2', '3', '4', '5', '6', '7']\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, po_means, width, label='PO')\n",
        "rects2 = ax.bar(x + width/2, iv_means, width, label='IV')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Mean remaining LOS')\n",
        "ax.set_title('Remaining LOS by IV treatment duration')\n",
        "ax.set_xlabel('Prior days cumulative IV treatment length')\n",
        "\n",
        "ax.set_xticks(x, labels)\n",
        "ax.legend()\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "gather": {
          "logged": 1710777638632
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def los_cv_run_fun2(data, icu_stays):\n",
        "\n",
        "    ### Import LOS ###\n",
        "\n",
        "    po_los_dict = {}\n",
        "    iv_los_dict = {}\n",
        "\n",
        "    # Split into folds\n",
        "    split_generator = cv_data_fun(data)\n",
        "\n",
        "    # Iterate through folds\n",
        "    for x in range(N_EPOCHS):\n",
        "        train_idx, val_idx, test_idx = next(split_generator)\n",
        "\n",
        "        # Get train val and test\n",
        "        train_data = data.loc[train_idx]\n",
        "        valid_data = data.loc[val_idx]\n",
        "        test_data = data.loc[test_idx]\n",
        "\n",
        "        for i in test_data.flag.unique():\n",
        "            temp_data = test_data[(test_data['flag'] == i) & (test_data['po_flag'] == 1)]\n",
        "            temp_data = pd.merge(temp_data, icu_stays)\n",
        "            temp_data['date'] = pd.to_datetime(temp_data['date'])\n",
        "            temp_data['outtime'] = pd.to_datetime(temp_data['outtime'])\n",
        "            temp_data['remaining_los'] =  (temp_data['outtime'] - temp_data['date']).dt.days\n",
        "            remaining_los_list = temp_data['remaining_los'].values.tolist()\n",
        "            \n",
        "            if x == 0:\n",
        "                po_los_dict[i] = remaining_los_list\n",
        "            else:\n",
        "                new_los_list = po_los_dict[i]\n",
        "                new_los_list.extend(remaining_los_list)\n",
        "                po_los_dict[i] = new_los_list\n",
        "        \n",
        "        for i in test_data.flag.unique():\n",
        "            temp_data = test_data[(test_data['flag'] == i) & (test_data['po_flag'] == 0)]\n",
        "            temp_data = pd.merge(temp_data, icu_stays)\n",
        "            temp_data['date'] = pd.to_datetime(temp_data['date'])\n",
        "            temp_data['outtime'] = pd.to_datetime(temp_data['outtime'])\n",
        "            temp_data['remaining_los'] =  (temp_data['outtime'] - temp_data['date']).dt.days\n",
        "            remaining_los_list = temp_data['remaining_los'].values.tolist()\n",
        "            if x == 0:\n",
        "                iv_los_dict[i] = remaining_los_list\n",
        "            else:\n",
        "                new_los_list = iv_los_dict[i]\n",
        "                new_los_list.extend(remaining_los_list)\n",
        "                iv_los_dict[i] = new_los_list\n",
        "\n",
        "        return po_los_dict, iv_los_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "gather": {
          "logged": 1710777689030
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def label_race (row):\n",
        "    if row['24_hour_flag'] == 1 :\n",
        "        return '24'\n",
        "    if row['48_hour_flag'] == 1 :\n",
        "        return '48'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "icare_df_preprocessed_2['flag'] = icare_df_preprocessed_2.apply(lambda row: label_race(row), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "gather": {
          "logged": 1710777746964
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Run\n",
        "po_los_dict, iv_los_dict = los_cv_run_fun2(icare_df_preprocessed_2, episodes2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "gather": {
          "logged": 1710777773308
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24\n",
            "3.7327586206896552\n",
            "6.48729792147806\n",
            "4.748851980315718e-16\n",
            "Different distribution\n",
            "48\n",
            "4.17\n",
            "5.927392739273928\n",
            "1.3062096228515763e-10\n",
            "Different distribution\n",
            "Other\n",
            "4.190352020860495\n",
            "5.672597864768683\n",
            "8.417013016956244e-25\n",
            "Different distribution\n"
          ]
        }
      ],
      "source": [
        "for i in po_los_dict.keys():\n",
        "    print(i)\n",
        "    print(mean(po_los_dict[i]))\n",
        "    print(mean(iv_los_dict[i]))\n",
        "    test_stats(po_los_dict[i], iv_los_dict[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "gather": {
          "logged": 1710777804463
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24\n",
            "2.893805309734513\n",
            "5.614077669902913\n",
            "1.8309947449483803e-16\n",
            "Different distribution\n",
            "48\n",
            "3.4871794871794872\n",
            "5.055555555555555\n",
            "2.5043050376283927e-10\n",
            "Different distribution\n",
            "Other\n",
            "3.377397260273973\n",
            "4.796992481203008\n",
            "1.0466136418907882e-27\n",
            "Different distribution\n"
          ]
        }
      ],
      "source": [
        "# See if results are same with outliers removed\n",
        "po_means = []\n",
        "po_std = []\n",
        "iv_means = []\n",
        "iv_std = []\n",
        "for i in po_los_dict.keys():\n",
        "    print(i)\n",
        "    po_los_dict2 = reject_outliers(np.array(po_los_dict[i]))\n",
        "    iv_los_dict2 = reject_outliers(np.array(iv_los_dict[i]))\n",
        "\n",
        "    print(mean(po_los_dict2))\n",
        "    po_means.append(mean(po_los_dict2))\n",
        "    po_std.append(std(po_los_dict2))\n",
        "    print(mean(iv_los_dict2))\n",
        "    iv_means.append(mean(iv_los_dict2))\n",
        "    iv_std.append(std(iv_los_dict2))\n",
        "\n",
        "    test_stats(po_los_dict2, iv_los_dict2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "gather": {
          "logged": 1710777846970
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Mean remaining LOS')"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Remaining LOS by IV treatment duration')"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Prior days cumulative IV treatment length')"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.axis.XTick at 0x7fb3f040d240>,\n",
              " <matplotlib.axis.XTick at 0x7fb3f040c8b0>,\n",
              " <matplotlib.axis.XTick at 0x7fb3dec7c4c0>]"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb3de21d2d0>"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels = ['24', '48', 'Other']\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, po_means, width, label='PO')\n",
        "rects2 = ax.bar(x + width/2, iv_means, width, label='IV')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Mean remaining LOS')\n",
        "ax.set_title('Remaining LOS by IV treatment duration')\n",
        "ax.set_xlabel('Prior days cumulative IV treatment length')\n",
        "\n",
        "ax.set_xticks(x, labels)\n",
        "ax.legend()\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Early, late , agree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1710780816695
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
            "Going to open: https://login.microsoftonline.com/be00e2c6-806c-45f8-84c3-3fc99f64b8d3/saml2?SAMLRequest=pZNdb9owFIb%2FSuRdJ3E%2BCMEiVLSsK1pbGKTVtLvgOGDh2MHHIW1%2F%2FUwoUnfR3uzOsp9jPz6vPb56qYVzZBq4khkKPIwcJqkqudxm6Cm%2FdVPkgClkWQglWYZeGaCryRiKWjRk2pqdXLFDy8A4diMJpF%2FIUKslUQVwILKoGRBDyXr6cE9CD5NGK6OoEuhDydcVBQDTxhpeSkrgVm9nTEN8v%2Bs6r4s8pbd%2BiDH28ci31An5duFf7J0%2B4QMfxyfeEhZfvrtdc3luwVdamzME5C7Pl%2B5ysc6RM72o3igJbc30mukjp%2BxpdX8WAGsAEA3TNPHavQvK9tBrND8Whgku9x5I1VWi2DOq6qY19gDPjvyKlb5QW257MJ9lqNnz8vnAsZC%2FVsmQXS9CdRi%2B3SW79O374OdjfvtjudiA%2Bt0cusVCP1DkPF9CDk8hzwFaNpenaI2dwmHs4sgN0jxIyCAiYeSF8fAPcmY2Wi4L01de%2FHsPr%2BZUK1CVUdKKs95ywzBmIU3cFCfUjQdV6qYxjdyooqNRlcSbtIz8U%2BAhOj8i0ovoyX%2B0Zux%2F3Oj9aT7atOazpRKcvjq3SteF%2BTzMwAv6GV66VY8SVhdcTMtSMwAbqhCqu9HMemTI6JYhf3I%2B9d8%2FMPkL&RelayState=44183 to authenticate...\n",
            "We were unable to open a browser window for you, please open the url above manually then paste the URL you are redirected to into the terminal.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<snowflake.connector.cursor.SnowflakeCursor at 0x7f6cf7e79990>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('8.10.2', 'ICHT_RG_COVOAM_22016_PROD', 'ICHT_WH_COVOAM_22016_PROD')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json, snowflake.connector\n",
        "\n",
        "# establish the connection to snowflake\n",
        "ctx = snowflake.connector.connect( \n",
        "    **json.load(open('/opt/ich/python-snowflake-defaults.json')))\n",
        "    \n",
        "# verify and test if connection is working\n",
        "try: \n",
        "    cs = ctx.cursor() \n",
        "    cs.execute('SELECT current_version(), current_role(), current_warehouse()')\n",
        "    print(cs.fetchone())\n",
        "finally: \n",
        "    cs.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1710780831744
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import \n",
        "query = '''\n",
        "SELECT * from ICHT_PROD.ICHT_COVID.EPISODES\n",
        "'''\n",
        "cur = ctx.cursor().execute(query)\n",
        "episodes = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1710780835228
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import \n",
        "query = '''\n",
        "SELECT * from ICHT_PROD.ICHT_COVID.demographic\n",
        "'''\n",
        "cur = ctx.cursor().execute(query)\n",
        "demographic = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1710780861978
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Chronic_switch_model(\n",
              "  (final_layers): Sequential(\n",
              "    (0): Linear(in_features=268, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.1, inplace=False)\n",
              "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (vital_model): Initial_vitals_model(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(253, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Linear(in_features=253, out_features=512, bias=True)\n",
              "      (2): ReLU()\n",
              "      (3): Dropout(p=0.1, inplace=False)\n",
              "      (4): Linear(in_features=512, out_features=128, bias=True)\n",
              "      (5): ReLU()\n",
              "      (6): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (set_transformer): SetTransformer(\n",
              "    (enc): Sequential(\n",
              "      (0): ISAB(\n",
              "        (mab0): MAB0(\n",
              "          (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_k): Linear(in_features=128, out_features=160, bias=True)\n",
              "          (fc_v): Linear(in_features=128, out_features=160, bias=True)\n",
              "          (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "        )\n",
              "        (mab1): MAB(\n",
              "          (fc_q): Linear(in_features=128, out_features=160, bias=True)\n",
              "          (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (1): ISAB(\n",
              "        (mab0): MAB0(\n",
              "          (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "        )\n",
              "        (mab1): MAB(\n",
              "          (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "          (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (isab): ISAB(\n",
              "      (mab0): MAB0(\n",
              "        (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_k): Linear(in_features=128, out_features=160, bias=True)\n",
              "        (fc_v): Linear(in_features=128, out_features=160, bias=True)\n",
              "        (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "      )\n",
              "      (mab1): MAB(\n",
              "        (fc_q): Linear(in_features=128, out_features=160, bias=True)\n",
              "        (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (pma): PMA(\n",
              "      (mab): MAB0(\n",
              "        (fc_q): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_k): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_v): Linear(in_features=160, out_features=160, bias=True)\n",
              "        (fc_o): Linear(in_features=160, out_features=160, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (dec): Sequential(\n",
              "      (0): Linear(in_features=160, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (demographics): Linear(in_features=12, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 1,126,583 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "final_input_dim = 268\n",
        "final_output_dim = 1\n",
        "final_hid_dim = 512\n",
        "final_hid_dim2 = 128\n",
        "demographics_input_dim = 12\n",
        "demographics_output_dim = 12\n",
        "vital_input_dim = 253\n",
        "vital_hid_dim = 512\n",
        "vital_output_dim = 128\n",
        "dropout = 0.1\n",
        "\n",
        "# Define model\n",
        "model = Chronic_switch_model(\n",
        "    final_input_dim, \n",
        "    final_output_dim, \n",
        "    final_hid_dim, \n",
        "    final_hid_dim2,\n",
        "    demographics_input_dim,\n",
        "    demographics_output_dim,\n",
        "    vital_input_dim, \n",
        "    vital_hid_dim, \n",
        "    vital_output_dim, \n",
        "    dropout).to(device)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1710780880053
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/chronic_switch_icare_df_preprocessed.csv'\n",
        "icare_df_preprocessed = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_episodes.csv'\n",
        "episodes = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_disease.csv'\n",
        "disease = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_demographics.csv'\n",
        "demographics = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/snomed_embedding_128d-copy.csv'\n",
        "embedding = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_problem_dummies.csv'\n",
        "problem_dummies = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1710780893051
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Merge\n",
        "problem_dummies2 = pd.merge(problem_dummies, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "problem_dummies2 = pd.merge(icare_df_preprocessed[['SPELL_IDENTIFIER', 'date']], problem_dummies2)\n",
        "\n",
        "# Strip name \n",
        "problem_dummies2.columns = problem_dummies2.columns.str.removeprefix('PROBLEM_')\n",
        "\n",
        "# Convert the date columns to datetime objects if they are not already\n",
        "problem_dummies2['date'] = pd.to_datetime(problem_dummies2['date'])\n",
        "problem_dummies2['DT_TM'] = pd.to_datetime(problem_dummies2['DT_TM'])\n",
        "\n",
        "# Calculate the absolute time difference between 'date' and 'DT_TM'\n",
        "problem_dummies2['time_diff'] = (problem_dummies2['date'] - problem_dummies2['DT_TM']).abs()\n",
        "\n",
        "# Filter rows where 'time_diff' is not negative\n",
        "problem_dummies2 = problem_dummies2[problem_dummies2['time_diff'] >= pd.Timedelta(0)]\n",
        "\n",
        "# Sort the DataFrame by 'SPELL_IDENTIFIER' and 'time_diff'\n",
        "problem_dummies2.sort_values(by=['SPELL_IDENTIFIER', 'time_diff'], inplace=True)\n",
        "\n",
        "# Convert to str\n",
        "problem_dummies2['date'] = problem_dummies2['date'].astype(str)\n",
        "\n",
        "# Keep only the rows with the smallest time difference for each 'SPELL_IDENTIFIER'\n",
        "problem_dummies2 = problem_dummies2.groupby(['SPELL_IDENTIFIER', 'date']).first().reset_index()\n",
        "\n",
        "### REASON the problem_dummies2 is shorter is not because it is missing some dates! \n",
        "### It is because in the final data we have some dates repeated for a spesfic spell \n",
        "### if they were admited in between 6am and 12pm the 12hour prediction is done at 6am \n",
        "### of the first day, then 48 done at 6am the next day, then the next prediction done \n",
        "### at 12pm that day causing there to be two prediction for that day...phew\n",
        "### So just get a set of co-morbidities for each spell and merge \n",
        "\n",
        "# Drop the 'time_diff' column as it's no longer needed\n",
        "problem_dummies2.drop(columns=['time_diff', 'SUBJECT', 'DT_TM', 'new_subject', 'date'], inplace=True)\n",
        "\n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(inplace=True)\n",
        "\n",
        "# Some still got through by having their co-morbidid diagnosis updated during their stay \n",
        "# In this case we just use the frst one throughout and remove the others \n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(subset=['SPELL_IDENTIFIER'], keep='first', inplace=True)\n",
        "\n",
        "# Filter for features\n",
        "X_data = icare_df_preprocessed.drop(columns=['SPELL_IDENTIFIER', 'po_flag'])\n",
        "X_data = X_data.drop(columns=columns_to_drop)\n",
        "model_data = pd.concat([icare_df_preprocessed[['SPELL_IDENTIFIER', 'po_flag']], X_data], axis=1)\n",
        "# Merge\n",
        "demographics = pd.merge(demographics, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "demographics.drop(columns=['SUBJECT'], inplace=True)\n",
        "model_data = pd.merge(model_data, demographics, how='left')\n",
        "model_data = pd.merge(model_data, disease, how='left')\n",
        "# Drop \n",
        "model_data = model_data.drop(columns=['ROUTE', '24_hour_flag', '48_hour_flag'])\n",
        "# fillna\n",
        "model_data['AGE'] = model_data['AGE'].fillna(-1)\n",
        "model_data['IMDDECIL'] = model_data['IMDDECIL'].fillna(-1)\n",
        "model_data = model_data.fillna(0)\n",
        "# Merge co-morbidites\n",
        "model_data = pd.merge(model_data, problem_dummies2, how='left')\n",
        "# Rename\n",
        "model_data.rename(columns={'SPELL_IDENTIFIER': 'stay_id'}, inplace=True)\n",
        "# Random shuffle\n",
        "stays = model_data['stay_id'].unique()\n",
        "random.Random(5).shuffle(stays)\n",
        "model_data = model_data.set_index(\"stay_id\").loc[stays].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1710780996639
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Get discharge time and LOS and mortality \n",
        "stay_list = icare_df_preprocessed.SPELL_IDENTIFIER.unique().tolist()\n",
        "episodes2 = episodes[episodes['SPELL_IDENTIFIER'].isin(stay_list)]\n",
        "episodes2 = episodes2[['SUBJECT', 'SPELL_IDENTIFIER',  'ADMISSION_DATE_TIME', 'DISCHARGE_DATE_TIME']].drop_duplicates()\n",
        "episodes2.rename(columns={'SPELL_IDENTIFIER': 'stay_id', 'ADMISSION_DATE_TIME': 'intime', 'DISCHARGE_DATE_TIME':'outtime'}, inplace=True)\n",
        "# Create los column \n",
        "episodes2['intime'] = pd.to_datetime(episodes2['intime'])\n",
        "episodes2['outtime'] = pd.to_datetime(episodes2['outtime'])\n",
        "episodes2['los'] =  (episodes2['outtime'] - episodes2['intime'])\n",
        "# Convert to float from time delta\n",
        "episodes2['los'] = episodes2['los'] / datetime.timedelta(days=1)\n",
        "# Merge \n",
        "episodes2 = episodes2.merge(demographic[['SUBJECT', 'DEATH_DATE']])\n",
        "# Create death column\n",
        "episodes2['hospital_expire_flag'] = np.where(episodes2.DEATH_DATE <= episodes2.outtime, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1710781022786
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# For only having one positive switch day per stay\n",
        "def lb_predicted_switch_day_fun(data):\n",
        "    # Convert to datetime\n",
        "    data['date'] = pd.to_datetime(data['date'])\n",
        "\n",
        "    # iv_treatment_length\n",
        "    cumcount = []\n",
        "    count = 0\n",
        "    pos = -1\n",
        "    flag = 0\n",
        "\n",
        "    for x in range(len(data)):\n",
        "        pos += 1\n",
        "        if pos == len(data) - 1:\n",
        "            cumcount.append(count) # add count to last one\n",
        "            break # end\n",
        "        elif pos == 0:\n",
        "            cumcount.append(count) # add 0 to first one\n",
        "            count += 1\n",
        "        elif data.iloc[x]['stay_id'] == data.iloc[x+1]['stay_id']:\n",
        "            if data.iloc[x]['lb_prediction'] == 0:\n",
        "                cumcount.append(count)\n",
        "                count += 1\n",
        "            elif flag == 1:\n",
        "                cumcount.append(999)\n",
        "                count = 0\n",
        "                flag = 1\n",
        "            elif data.iloc[x]['stay_id'] != data.iloc[x-1]['stay_id']:\n",
        "                if data.iloc[x]['lb_prediction'] == 1:\n",
        "                    cumcount.append(count)\n",
        "                    count += 1\n",
        "                else:\n",
        "                    cumcount.append(999)\n",
        "                    count = 0\n",
        "            else:\n",
        "                cumcount.append(count)\n",
        "                count = 0\n",
        "                flag = 1\n",
        "        else:\n",
        "            if data.iloc[x]['lb_prediction'] == 0:\n",
        "                cumcount.append(count)\n",
        "                count = 0\n",
        "                flag = 0\n",
        "            elif flag == 1:\n",
        "                cumcount.append(999)\n",
        "                count = 0\n",
        "                flag = 0\n",
        "            else:\n",
        "                cumcount.append(count)\n",
        "                count = 0\n",
        "                flag = 0\n",
        "\n",
        "    print(len(cumcount))\n",
        "\n",
        "    data['lb_predicted_switch_day'] = cumcount\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1710781051626
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Function to split data so even distribution between val and test\n",
        "def cv_data_fun2(data, n_cv=10):\n",
        "    X = data.iloc[:, 4:]\n",
        "    y = data['po_flag']\n",
        "    g = StratifiedKFold3(n_cv).split(X,y)\n",
        "    return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710781227759
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Split into folds\n",
        "split_generator = cv_data_fun2(model_data)\n",
        "\n",
        "# Iterate through folds\n",
        "for x in range(10):\n",
        "    train_idx, val_idx, test_idx = next(split_generator)\n",
        "\n",
        "    # Get train val and test\n",
        "    train_data = model_data.loc[train_idx]\n",
        "    valid_data = model_data.loc[val_idx]\n",
        "    test_data = model_data.loc[test_idx]\n",
        "\n",
        "    # Filter for those who switch\n",
        "    test_stay_id_list = (test_data.groupby(['stay_id'])['po_flag'].nunique() > 1).where(lambda x : x==True).dropna().reset_index()['stay_id'].unique().tolist()\n",
        "    filtered_test_data = test_data[test_data['stay_id'].isin(test_stay_id_list)]\n",
        "\n",
        "\n",
        "    # Find the day they actually switched\n",
        "    test_switch_day = filtered_test_data[filtered_test_data['po_flag'] == 1].drop_duplicates(subset=['stay_id'], keep='first')\n",
        "    test_switch_day = test_switch_day[['stay_id', 'iv_treatment_length']]\n",
        "    test_switch_day.rename(columns={'iv_treatment_length': 'real_switch_day'}, inplace=True)\n",
        "    test_switch_day.reset_index(drop=True, inplace=True)\n",
        "    print(test_switch_day.real_switch_day.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1710781981447
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def early_late_agree_fun(data, model, episodes2):\n",
        "    \n",
        "    # df over epochs\n",
        "    lb_los = pd.DataFrame()\n",
        "\n",
        "    lb_mortality = pd.DataFrame()\n",
        "\n",
        "    lb_count_df = pd.DataFrame()\n",
        "\n",
        "    # Lists for averages over epochs\n",
        "    lb_percentage_agree_list = []\n",
        "    lb_percentage_late_list = []\n",
        "    lb_percentage_early_list = []\n",
        "\n",
        "    # Define batch size \n",
        "    batch_size = 512\n",
        "\n",
        "# Define optimizer and learning_rate\n",
        "    learning_rate = 0.0001\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Define loss\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Define epochs and clip\n",
        "    N_EPOCHS = 10\n",
        "    CLIP = 1\n",
        "\n",
        "    # Split into folds\n",
        "    split_generator = cv_data_fun2(data)\n",
        "\n",
        "    # Iterate through folds\n",
        "    for x in range(N_EPOCHS): # Note this only works as number of splits and epocs are the same\n",
        "        train_idx, val_idx, test_idx = next(split_generator)\n",
        "\n",
        "        # Get train val and test\n",
        "        train_data = data.loc[train_idx]\n",
        "        valid_data = data.loc[val_idx]\n",
        "        test_data = data.loc[test_idx]\n",
        "\n",
        "        # Drop \n",
        "        train_data = train_data.drop(columns=['date', 'iv_treatment_length'])\n",
        "        valid_data = valid_data.drop(columns=['date', 'iv_treatment_length'])\n",
        "\n",
        "        # Split up dfs\n",
        "        vitals_train_data = train_data.iloc[:,2:255]\n",
        "        demographics_train_data = train_data.iloc[:,255:267]\n",
        "        comorbidity_train_data = train_data.iloc[:, 267:]\n",
        "\n",
        "        vitals_valid_data = valid_data.iloc[:,2:255]\n",
        "        demographics_valid_data = valid_data.iloc[:,255:267]\n",
        "        comorbidity_valid_data = valid_data.iloc[:, 267:]\n",
        "\n",
        "        # Initializing the weights of our model each fold\n",
        "        model.apply(init_weights)\n",
        "\n",
        "        # Get labels\n",
        "        train_labels = train_data[['po_flag']]\n",
        "        valid_labels = valid_data[['po_flag']]\n",
        "\n",
        "        # Preprocess comorbidity data\n",
        "        print('Working on set_transformer_processing_fun...')\n",
        "        comorbidity_train_data, comorbidity_train_mask = set_transformer_processing_fun(comorbidity_train_data, embedding)\n",
        "        comorbidity_valid_data, comorbidity_valid_mask = set_transformer_processing_fun(comorbidity_valid_data, embedding)\n",
        "        print('Done!')\n",
        "\n",
        "        # Define dataloaders\n",
        "        train_dataset =  MultiInputDataset([vitals_train_data, demographics_train_data], train_labels, comorbidity_train_data, comorbidity_train_mask)\n",
        "        train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size)#, shuffle=True)#, collate_fn=train_dataset.collate_fn_padd)\n",
        "\n",
        "        valid_dataset = MultiInputDataset([vitals_valid_data, demographics_valid_data], valid_labels, comorbidity_valid_data, comorbidity_valid_mask)\n",
        "        valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=batch_size)#, collate_fn=valid_dataset.collate_fn_padd)\n",
        "\n",
        "        # Run\n",
        "        best_valid_loss = float('inf')\n",
        "        best_valid_auroc = 0\n",
        "\n",
        "        optimal_threshold = 0\n",
        "\n",
        "        for epoch in range(N_EPOCHS):\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            train_loss, train_auroc, train_predictions, train_labels_out = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
        "            valid_loss, valid_auroc, valid_predictions, valid_labels_out = evaluate(model, valid_dataloader, criterion)\n",
        "\n",
        "            end_time = time.time()\n",
        "\n",
        "            fpr, tpr, thresholds = roc_curve(valid_labels_out, valid_predictions)\n",
        "            optimal_idx = np.argmax(tpr - fpr)\n",
        "            current_threshold = thresholds[optimal_idx]\n",
        "\n",
        "            epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "            if valid_loss < best_valid_loss:\n",
        "                best_valid_loss = valid_loss\n",
        "                #print('BEST VALID LOSS')\n",
        "\n",
        "            if valid_auroc > best_valid_auroc:\n",
        "                best_valid_auroc = valid_auroc\n",
        "                #print('UPDATED BEST INTERMEDIATE MODEL')\n",
        "                torch.save(model.state_dict(), f'hold_out_chronic_switch_model_intermediate_early_late_agree.pt')\n",
        "                optimal_threshold = current_threshold\n",
        "\n",
        "        # -----------------------------\n",
        "        # Evaluate best model on test set\n",
        "        # -----------------------------\n",
        "\n",
        "        model.load_state_dict(torch.load(f'hold_out_chronic_switch_model_intermediate_early_late_agree.pt'))\n",
        "\n",
        "        # Filter for those who switch\n",
        "        test_stay_id_list = (test_data.groupby(['stay_id'])['po_flag'].nunique() > 1).where(lambda x : x==True).dropna().reset_index()['stay_id'].unique().tolist()\n",
        "        filtered_test_data = test_data[test_data['stay_id'].isin(test_stay_id_list)]\n",
        "\n",
        "\n",
        "        # Find the day they actually switched\n",
        "        test_switch_day = filtered_test_data[filtered_test_data['po_flag'] == 1].drop_duplicates(subset=['stay_id'], keep='first')\n",
        "        test_switch_day = test_switch_day[['stay_id', 'iv_treatment_length']]\n",
        "        test_switch_day.rename(columns={'iv_treatment_length': 'real_switch_day'}, inplace=True)\n",
        "        test_switch_day.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        # Find LOS and mortality\n",
        "        test_switch_data = pd.merge(test_switch_day, episodes2[['stay_id', 'los', 'hospital_expire_flag']])\n",
        "\n",
        "        # Find day we predict they could switch\n",
        "        # Get Predictions\n",
        "        filtered_test_data.reset_index(inplace=True, drop=True)\n",
        "        filtered_test_data2 = filtered_test_data.drop(columns=['date', 'iv_treatment_length'])\n",
        "\n",
        "        # Get predictions\n",
        "        vitals_test_data = filtered_test_data2.iloc[:,2:255]\n",
        "        demographics_test_data = filtered_test_data2.iloc[:,255:267]\n",
        "        comorbidity_test_data = filtered_test_data2.iloc[:, 267:]\n",
        "        comorbidity_test_data, comorbidity_test_mask = set_transformer_processing_fun(comorbidity_test_data, embedding)\n",
        "        test_labels = filtered_test_data2[['po_flag']]\n",
        "\n",
        "        test_dataset = MultiInputDataset([vitals_test_data, demographics_test_data], test_labels, comorbidity_test_data, comorbidity_test_mask)\n",
        "        temp_test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
        "\n",
        "        test_loss, test_auroc, test_predictions, test_labels_out = evaluate(model, temp_test_dataloader, criterion)\n",
        "        new_test_predictions = new_threshold_fun(test_predictions, optimal_threshold)\n",
        "\n",
        "        filtered_test_data['lb_prediction'] = new_test_predictions\n",
        "\n",
        "        # Find the day we predict they switched\n",
        "        filtered_test_data = lb_predicted_switch_day_fun(filtered_test_data)\n",
        "\n",
        "        test_lb_predicted_switch_day = filtered_test_data[filtered_test_data['lb_prediction'] == 1].drop_duplicates(subset=['stay_id'], keep='first')\n",
        "        test_lb_predicted_switch_day = test_lb_predicted_switch_day[['stay_id', 'lb_predicted_switch_day']]\n",
        "        test_lb_predicted_switch_day.reset_index(drop=True, inplace=True)\n",
        "        test_lb_predicted_switch_day\n",
        "\n",
        "        # Merge and work out difference\n",
        "        test_switch_data = pd.merge(test_switch_day, episodes2[['stay_id', 'los', 'hospital_expire_flag']])\n",
        "        test_switch_data = pd.merge(test_switch_data, test_lb_predicted_switch_day)\n",
        "        test_switch_data['lb_difference'] = test_switch_data['lb_predicted_switch_day'] - test_switch_data['real_switch_day'] #- test_switch_data['lb_predicted_switch_day']\n",
        "\n",
        "        # Get results\n",
        "        lb_los_mean = pd.DataFrame(test_switch_data.groupby('lb_difference').los.mean()) \n",
        "        lb_mortality_mean = pd.DataFrame(test_switch_data.groupby('lb_difference').hospital_expire_flag.mean())\n",
        "        lb_count = pd.DataFrame(test_switch_data['lb_difference'].value_counts())\n",
        "\n",
        "        lb_los_mean.rename(columns={'los':f'los_{x}'}, inplace=True)\n",
        "        lb_mortality_mean.rename(columns={'hospital_expire_flag':f'mortality_{x}'}, inplace=True)\n",
        "        lb_count.rename(columns={'lb_difference':f'lb_difference_{x}'}, inplace=True)\n",
        "\n",
        "        if x == 0:\n",
        "            lb_los = lb_los_mean\n",
        "        else:\n",
        "            lb_los = pd.concat([lb_los, lb_los_mean], axis=1)\n",
        "        if x == 0:\n",
        "            lb_mortality = lb_mortality_mean\n",
        "        else:\n",
        "            lb_mortality = pd.concat([lb_mortality, lb_mortality_mean], axis=1)\n",
        "        \n",
        "        if x == 0:\n",
        "            lb_count_df = lb_count\n",
        "        else:\n",
        "            lb_count_df = pd.concat([lb_count_df, lb_count], axis=1)\n",
        "        \n",
        "        lb_percentage_agree = len(test_switch_data[test_switch_data['lb_difference'] == 0])/len(test_switch_data)\n",
        "        lb_percentage_early = len(test_switch_data[test_switch_data['lb_difference'] < 0])/len(test_switch_data)\n",
        "        lb_percentage_late = len(test_switch_data[test_switch_data['lb_difference'] > 0])/len(test_switch_data)\n",
        "\n",
        "        lb_percentage_agree_list.append(lb_percentage_agree)\n",
        "        lb_percentage_late_list.append(lb_percentage_late)\n",
        "        lb_percentage_early_list.append(lb_percentage_early)\n",
        "\n",
        "    #lb\n",
        "    lb_los_means = pd.DataFrame(lb_los.mean(axis=1))\n",
        "    lb_los_means.rename(columns={lb_los_means.columns[0]: 'lb_los_mean'}, inplace=True)\n",
        "    lb_mortality_means = pd.DataFrame(lb_mortality_mean.mean(axis=1))\n",
        "    lb_mortality_means.rename(columns={lb_mortality_means.columns[0]: 'lb_mortality_means'}, inplace=True)\n",
        "    lb_count_df2 = pd.DataFrame(lb_count_df.mean(axis=1))\n",
        "    lb_count_df3 = pd.DataFrame(lb_count_df.sum(axis=1))\n",
        "    lb_count_df2.rename(columns={lb_count_df2.columns[0]: 'lb_count_sum'}, inplace=True)\n",
        "    lb_count_df3.rename(columns={lb_count_df3.columns[0]: 'lb_count_sum'}, inplace=True)\n",
        "\n",
        "    lb_percentage_agree = statistics.mean(lb_percentage_agree_list)\n",
        "    lb_percentage_late = statistics.mean(lb_percentage_late_list)\n",
        "    lb_percentage_early = statistics.mean(lb_percentage_early_list)\n",
        "\n",
        "    return lb_los_means, lb_mortality_means, lb_count_df2, lb_count_df3, lb_percentage_agree, lb_percentage_early, lb_percentage_late"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1710787287449
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:46<00:00,  1.08it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.81it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.85it/s]\n",
            "100%|| 50/50 [00:45<00:00,  1.11it/s]\n",
            "100%|| 7/7 [00:04<00:00,  1.42it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.88it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.88it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.88it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 6/6 [00:03<00:00,  1.95it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:04<00:00,  1.70it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.91it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.91it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.88it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 5/5 [00:02<00:00,  1.76it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:04<00:00,  1.73it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.96it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 5/5 [00:02<00:00,  1.88it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.91it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.76it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.89it/s]\n",
            "100%|| 5/5 [00:02<00:00,  1.79it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.91it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.95it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.95it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.90it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.96it/s]\n",
            "100%|| 5/5 [00:02<00:00,  1.81it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.95it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.14it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.95it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.91it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.95it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 5/5 [00:02<00:00,  1.76it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.96it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.96it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.91it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.19it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:44<00:00,  1.13it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.91it/s]\n",
            "100%|| 5/5 [00:02<00:00,  1.70it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:44<00:00,  1.12it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.91it/s]\n",
            "100%|| 50/50 [00:45<00:00,  1.11it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.83it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.15it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.91it/s]\n",
            "100%|| 5/5 [00:03<00:00,  1.41it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.94it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.95it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:43<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 5/5 [00:02<00:00,  1.76it/s]\n",
            "/tmp/ipykernel_16409/3153145714.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.95it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.96it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.96it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.18it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.95it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.93it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.16it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.95it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.19it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.92it/s]\n",
            "100%|| 50/50 [00:42<00:00,  1.17it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.96it/s]\n",
            "100%|| 50/50 [00:41<00:00,  1.20it/s]\n",
            "100%|| 7/7 [00:03<00:00,  1.98it/s]\n",
            "100%|| 6/6 [00:03<00:00,  1.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "2621\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "2495\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "2365\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "2380\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "2282\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "2358\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "2551\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "2557\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "2492\n",
            "Working on set_transformer_processing_fun...\n",
            "Done!\n",
            "2576\n"
          ]
        }
      ],
      "source": [
        "# Run\n",
        "lb_los_means, lb_mortality_means, lb_count_df2, lb_count_df3, lb_percentage_agree, lb_percentage_early, lb_percentage_late = early_late_agree_fun(model_data, model, episodes2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1710787289758
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lb_los_mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lb_difference</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-7</th>\n",
              "      <td>14.686875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-6</th>\n",
              "      <td>12.656674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-5</th>\n",
              "      <td>13.650947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-4</th>\n",
              "      <td>12.562467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-3</th>\n",
              "      <td>11.645322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-2</th>\n",
              "      <td>10.255825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-1</th>\n",
              "      <td>8.632213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.256014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.890729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12.616378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12.894190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.970819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>22.719965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-997</th>\n",
              "      <td>11.861111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9.691493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-995</th>\n",
              "      <td>17.812500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               lb_los_mean\n",
              "lb_difference             \n",
              "-7               14.686875\n",
              "-6               12.656674\n",
              "-5               13.650947\n",
              "-4               12.562467\n",
              "-3               11.645322\n",
              "-2               10.255825\n",
              "-1                8.632213\n",
              " 0                8.256014\n",
              " 1                9.890729\n",
              " 2               12.616378\n",
              " 3               12.894190\n",
              " 4               17.970819\n",
              " 6               22.719965\n",
              "-997             11.861111\n",
              " 5                9.691493\n",
              "-995             17.812500"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lb_mortality_means</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lb_difference</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-6</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-5</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-4</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-3</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-2</th>\n",
              "      <td>0.016667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-1</th>\n",
              "      <td>0.014286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.011111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               lb_mortality_means\n",
              "lb_difference                    \n",
              "-6                       0.000000\n",
              "-5                       0.000000\n",
              "-4                       0.000000\n",
              "-3                       0.000000\n",
              "-2                       0.016667\n",
              "-1                       0.014286\n",
              " 0                       0.011111\n",
              " 1                       0.000000\n",
              " 2                       0.111111\n",
              " 3                       0.000000\n",
              " 4                       0.000000"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lb_count_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>76.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-1</th>\n",
              "      <td>59.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-2</th>\n",
              "      <td>39.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-3</th>\n",
              "      <td>24.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-4</th>\n",
              "      <td>16.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-5</th>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-6</th>\n",
              "      <td>2.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-7</th>\n",
              "      <td>1.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-997</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-995</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      lb_count_sum\n",
              " 0       76.500000\n",
              "-1       59.300000\n",
              " 1       46.900000\n",
              "-2       39.700000\n",
              "-3       24.800000\n",
              "-4       16.400000\n",
              " 2       23.200000\n",
              " 3        9.700000\n",
              "-5        7.000000\n",
              " 4        2.625000\n",
              "-6        2.888889\n",
              "-7        1.600000\n",
              " 6        1.250000\n",
              "-997      1.000000\n",
              " 5        1.000000\n",
              "-995      1.000000"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lb_count_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>765.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-1</th>\n",
              "      <td>593.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>469.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-2</th>\n",
              "      <td>397.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-3</th>\n",
              "      <td>248.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-4</th>\n",
              "      <td>164.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>97.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-5</th>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-6</th>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-7</th>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-997</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-995</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      lb_count_sum\n",
              " 0           765.0\n",
              "-1           593.0\n",
              " 1           469.0\n",
              "-2           397.0\n",
              "-3           248.0\n",
              "-4           164.0\n",
              " 2           232.0\n",
              " 3            97.0\n",
              "-5            70.0\n",
              " 4            21.0\n",
              "-6            26.0\n",
              "-7             8.0\n",
              " 6             5.0\n",
              "-997           1.0\n",
              " 5             4.0\n",
              "-995           1.0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "0.2466074487344725"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "0.48391136602379475"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "0.26948118524173276"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lb_los_means\n",
        "lb_mortality_means\n",
        "lb_count_df2\n",
        "lb_count_df3\n",
        "lb_percentage_agree\n",
        "lb_percentage_early\n",
        "lb_percentage_late"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1710789172067
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lb_los_mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lb_difference</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-997</th>\n",
              "      <td>11.861111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-995</th>\n",
              "      <td>17.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-7</th>\n",
              "      <td>14.686875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-6</th>\n",
              "      <td>12.656674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-5</th>\n",
              "      <td>13.650947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-4</th>\n",
              "      <td>12.562467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-3</th>\n",
              "      <td>11.645322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-2</th>\n",
              "      <td>10.255825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-1</th>\n",
              "      <td>8.632213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.256014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.890729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12.616378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12.894190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.970819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9.691493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>22.719965</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               lb_los_mean\n",
              "lb_difference             \n",
              "-997             11.861111\n",
              "-995             17.812500\n",
              "-7               14.686875\n",
              "-6               12.656674\n",
              "-5               13.650947\n",
              "-4               12.562467\n",
              "-3               11.645322\n",
              "-2               10.255825\n",
              "-1                8.632213\n",
              " 0                8.256014\n",
              " 1                9.890729\n",
              " 2               12.616378\n",
              " 3               12.894190\n",
              " 4               17.970819\n",
              " 5                9.691493\n",
              " 6               22.719965"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[11.86111111111111,\n",
              " 17.8125,\n",
              " 14.686875,\n",
              " 12.656674382716048,\n",
              " 13.650946649029985,\n",
              " 12.562466902333323,\n",
              " 11.64532204931315,\n",
              " 10.255824657894568,\n",
              " 8.632213389276703,\n",
              " 8.25601386556075,\n",
              " 9.890728635951927,\n",
              " 12.616377634362184,\n",
              " 12.894190492667056,\n",
              " 17.97081886574074,\n",
              " 9.691493055555556,\n",
              " 22.719965277777774]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lb_los_means.sort_index()\n",
        "lb_los_means.sort_index()['lb_los_mean'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1710789373464
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Mean LOS')"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Patient LOS by switch event temporal difference')"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Number of days between the real and predicted switch event')"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 25.0)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.axis.XTick at 0x7f6cd5ea8df0>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd5ea8dc0>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd5ea89d0>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd7cba860>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd7cbb310>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd7cbbdc0>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd7c0c8b0>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd7cba320>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd7c0d2d0>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd7c0dd80>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd7c0e830>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd7c0f2e0>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd7c0e0e0>,\n",
              " <matplotlib.axis.XTick at 0x7f6cd7c0f880>]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Decided to go with -7 to 6\n",
        "\n",
        "labels = ['-7', '-6', '-5', '-4', '-3', '-2', '-1', '0', '1', '2', '3', '4', '5', '6']\n",
        "\n",
        "lb_los_mean = [14.686875,\n",
        " 12.656674382716048,\n",
        " 13.650946649029985,\n",
        " 12.562466902333323,\n",
        " 11.64532204931315,\n",
        " 10.255824657894568,\n",
        " 8.632213389276703,\n",
        " 8.25601386556075,\n",
        " 9.890728635951927,\n",
        " 12.616377634362184,\n",
        " 12.894190492667056,\n",
        " 17.97081886574074,\n",
        " 9.691493055555556,\n",
        " 22.719965277777774]\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x, lb_los_mean)\n",
        "\n",
        "ax.set_ylabel('Mean LOS')\n",
        "ax.set_title('Patient LOS by switch event temporal difference')\n",
        "ax.set_xlabel('Number of days between the real and predicted switch event')\n",
        "\n",
        "ax.set_ylim(0,25)\n",
        "\n",
        "ax.set_xticks(x, labels)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
