{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1711549554941
        }
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 40)\n",
        "pd.set_option('display.width', 2000)\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import gc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from scipy import spatial\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from sktime.transformations.panel.catch22 import Catch22\n",
        "from sktime.datatypes import check_raise\n",
        "\n",
        "# Remove printing error\n",
        "pd.options.mode.chained_assignment = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1711549563893
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2373d7f970>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU not available, CPU used\n"
          ]
        }
      ],
      "source": [
        "# Set the random seeds for deterministic results.\n",
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Set device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1711549564331
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "columns_to_drop = [\n",
        " 'Diastolic Blood Pressure2',\n",
        " 'Diastolic Blood Pressure3',\n",
        " 'Diastolic Blood Pressure4',\n",
        " 'Diastolic Blood Pressure5',\n",
        " 'Diastolic Blood Pressure6',\n",
        " 'Diastolic Blood Pressure7',\n",
        " 'Diastolic Blood Pressure8',\n",
        " 'Diastolic Blood Pressure9',\n",
        " 'Diastolic Blood Pressure11',\n",
        " 'Diastolic Blood Pressure12',\n",
        " 'Diastolic Blood Pressure13',\n",
        " 'Diastolic Blood Pressure14',\n",
        " 'Diastolic Blood Pressure15',\n",
        " 'Diastolic Blood Pressure16',\n",
        " 'Diastolic Blood Pressure18',\n",
        " 'Diastolic Blood Pressure19',\n",
        " 'Diastolic Blood Pressure20',\n",
        " 'Diastolic Blood Pressure21',\n",
        " 'Diastolic Blood Pressure2_current_stay',\n",
        " 'Diastolic Blood Pressure3_current_stay',\n",
        " 'Diastolic Blood Pressure4_current_stay',\n",
        " 'Diastolic Blood Pressure5_current_stay',\n",
        " 'Diastolic Blood Pressure6_current_stay',\n",
        " 'Diastolic Blood Pressure8_current_stay',\n",
        " 'Diastolic Blood Pressure12_current_stay',\n",
        " 'Diastolic Blood Pressure13_current_stay',\n",
        " 'Diastolic Blood Pressure14_current_stay',\n",
        " 'Diastolic Blood Pressure16_current_stay',\n",
        " 'Diastolic Blood Pressure18_current_stay',\n",
        " 'Diastolic Blood Pressure19_current_stay',\n",
        " 'Diastolic Blood Pressure20_current_stay',\n",
        " 'Diastolic Blood Pressure21_current_stay',\n",
        " 'Glasgow Coma Score0',\n",
        " 'Glasgow Coma Score1',\n",
        " 'Glasgow Coma Score2',\n",
        " 'Glasgow Coma Score3',\n",
        " 'Glasgow Coma Score4',\n",
        " 'Glasgow Coma Score5',\n",
        " 'Glasgow Coma Score6',\n",
        " 'Glasgow Coma Score7',\n",
        " 'Glasgow Coma Score8',\n",
        " 'Glasgow Coma Score9',\n",
        " 'Glasgow Coma Score10',\n",
        " 'Glasgow Coma Score11',\n",
        " 'Glasgow Coma Score12',\n",
        " 'Glasgow Coma Score13',\n",
        " 'Glasgow Coma Score14',\n",
        " 'Glasgow Coma Score15',\n",
        " 'Glasgow Coma Score16',\n",
        " 'Glasgow Coma Score17',\n",
        " 'Glasgow Coma Score18',\n",
        " 'Glasgow Coma Score19',\n",
        " 'Glasgow Coma Score20',\n",
        " 'Glasgow Coma Score21',\n",
        " 'Glasgow Coma Score0_current_stay',\n",
        " 'Glasgow Coma Score1_current_stay',\n",
        " 'Glasgow Coma Score2_current_stay',\n",
        " 'Glasgow Coma Score3_current_stay',\n",
        " 'Glasgow Coma Score4_current_stay',\n",
        " 'Glasgow Coma Score5_current_stay',\n",
        " 'Glasgow Coma Score6_current_stay',\n",
        " 'Glasgow Coma Score7_current_stay',\n",
        " 'Glasgow Coma Score8_current_stay',\n",
        " 'Glasgow Coma Score10_current_stay',\n",
        " 'Glasgow Coma Score11_current_stay',\n",
        " 'Glasgow Coma Score12_current_stay',\n",
        " 'Glasgow Coma Score13_current_stay',\n",
        " 'Glasgow Coma Score14_current_stay',\n",
        " 'Glasgow Coma Score15_current_stay',\n",
        " 'Glasgow Coma Score16_current_stay',\n",
        " 'Glasgow Coma Score17_current_stay',\n",
        " 'Glasgow Coma Score18_current_stay',\n",
        " 'Glasgow Coma Score19_current_stay',\n",
        " 'Glasgow Coma Score20_current_stay',\n",
        " 'Glasgow Coma Score21_current_stay',\n",
        " 'Heart Rate2',\n",
        " 'Heart Rate3',\n",
        " 'Heart Rate4',\n",
        " 'Heart Rate5',\n",
        " 'Heart Rate6',\n",
        " 'Heart Rate7',\n",
        " 'Heart Rate8',\n",
        " 'Heart Rate9',\n",
        " 'Heart Rate11',\n",
        " 'Heart Rate12',\n",
        " 'Heart Rate13',\n",
        " 'Heart Rate14',\n",
        " 'Heart Rate15',\n",
        " 'Heart Rate16',\n",
        " 'Heart Rate18',\n",
        " 'Heart Rate19',\n",
        " 'Heart Rate20',\n",
        " 'Heart Rate21',\n",
        " 'Heart Rate2_current_stay',\n",
        " 'Heart Rate3_current_stay',\n",
        " 'Heart Rate4_current_stay',\n",
        " 'Heart Rate5_current_stay',\n",
        " 'Heart Rate6_current_stay',\n",
        " 'Heart Rate8_current_stay',\n",
        " 'Heart Rate12_current_stay',\n",
        " 'Heart Rate13_current_stay',\n",
        " 'Heart Rate14_current_stay',\n",
        " 'Heart Rate16_current_stay',\n",
        " 'Heart Rate18_current_stay',\n",
        " 'Heart Rate19_current_stay',\n",
        " 'Heart Rate20_current_stay',\n",
        " 'Heart Rate21_current_stay',\n",
        " 'Mean Arterial Pressure2',\n",
        " 'Mean Arterial Pressure3',\n",
        " 'Mean Arterial Pressure4',\n",
        " 'Mean Arterial Pressure5',\n",
        " 'Mean Arterial Pressure6',\n",
        " 'Mean Arterial Pressure7',\n",
        " 'Mean Arterial Pressure8',\n",
        " 'Mean Arterial Pressure9',\n",
        " 'Mean Arterial Pressure11',\n",
        " 'Mean Arterial Pressure12',\n",
        " 'Mean Arterial Pressure13',\n",
        " 'Mean Arterial Pressure14',\n",
        " 'Mean Arterial Pressure15',\n",
        " 'Mean Arterial Pressure16',\n",
        " 'Mean Arterial Pressure18',\n",
        " 'Mean Arterial Pressure19',\n",
        " 'Mean Arterial Pressure20',\n",
        " 'Mean Arterial Pressure21',\n",
        " 'Mean Arterial Pressure2_current_stay',\n",
        " 'Mean Arterial Pressure3_current_stay',\n",
        " 'Mean Arterial Pressure4_current_stay',\n",
        " 'Mean Arterial Pressure5_current_stay',\n",
        " 'Mean Arterial Pressure6_current_stay',\n",
        " 'Mean Arterial Pressure8_current_stay',\n",
        " 'Mean Arterial Pressure12_current_stay',\n",
        " 'Mean Arterial Pressure13_current_stay',\n",
        " 'Mean Arterial Pressure14_current_stay',\n",
        " 'Mean Arterial Pressure16_current_stay',\n",
        " 'Mean Arterial Pressure18_current_stay',\n",
        " 'Mean Arterial Pressure19_current_stay',\n",
        " 'Mean Arterial Pressure20_current_stay',\n",
        " 'Mean Arterial Pressure21_current_stay',\n",
        " 'NEWS Conscious Level Score0',\n",
        " 'NEWS Conscious Level Score1',\n",
        " 'NEWS Conscious Level Score2',\n",
        " 'NEWS Conscious Level Score3',\n",
        " 'NEWS Conscious Level Score4',\n",
        " 'NEWS Conscious Level Score5',\n",
        " 'NEWS Conscious Level Score6',\n",
        " 'NEWS Conscious Level Score7',\n",
        " 'NEWS Conscious Level Score8',\n",
        " 'NEWS Conscious Level Score9',\n",
        " 'NEWS Conscious Level Score10',\n",
        " 'NEWS Conscious Level Score11',\n",
        " 'NEWS Conscious Level Score12',\n",
        " 'NEWS Conscious Level Score13',\n",
        " 'NEWS Conscious Level Score14',\n",
        " 'NEWS Conscious Level Score15',\n",
        " 'NEWS Conscious Level Score16',\n",
        " 'NEWS Conscious Level Score17',\n",
        " 'NEWS Conscious Level Score18',\n",
        " 'NEWS Conscious Level Score19',\n",
        " 'NEWS Conscious Level Score20',\n",
        " 'NEWS Conscious Level Score21',\n",
        " 'NEWS Conscious Level Score0_current_stay',\n",
        " 'NEWS Conscious Level Score1_current_stay',\n",
        " 'NEWS Conscious Level Score2_current_stay',\n",
        " 'NEWS Conscious Level Score3_current_stay',\n",
        " 'NEWS Conscious Level Score4_current_stay',\n",
        " 'NEWS Conscious Level Score5_current_stay',\n",
        " 'NEWS Conscious Level Score6_current_stay',\n",
        " 'NEWS Conscious Level Score7_current_stay',\n",
        " 'NEWS Conscious Level Score8_current_stay',\n",
        " 'NEWS Conscious Level Score9_current_stay',\n",
        " 'NEWS Conscious Level Score10_current_stay',\n",
        " 'NEWS Conscious Level Score11_current_stay',\n",
        " 'NEWS Conscious Level Score12_current_stay',\n",
        " 'NEWS Conscious Level Score13_current_stay',\n",
        " 'NEWS Conscious Level Score14_current_stay',\n",
        " 'NEWS Conscious Level Score15_current_stay',\n",
        " 'NEWS Conscious Level Score16_current_stay',\n",
        " 'NEWS Conscious Level Score17_current_stay',\n",
        " 'NEWS Conscious Level Score18_current_stay',\n",
        " 'NEWS Conscious Level Score19_current_stay',\n",
        " 'NEWS Conscious Level Score20_current_stay',\n",
        " 'NEWS Conscious Level Score21_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc0',\n",
        " 'NEWS Supplemental Oxygen Calc1',\n",
        " 'NEWS Supplemental Oxygen Calc2',\n",
        " 'NEWS Supplemental Oxygen Calc3',\n",
        " 'NEWS Supplemental Oxygen Calc4',\n",
        " 'NEWS Supplemental Oxygen Calc5',\n",
        " 'NEWS Supplemental Oxygen Calc6',\n",
        " 'NEWS Supplemental Oxygen Calc7',\n",
        " 'NEWS Supplemental Oxygen Calc8',\n",
        " 'NEWS Supplemental Oxygen Calc9',\n",
        " 'NEWS Supplemental Oxygen Calc10',\n",
        " 'NEWS Supplemental Oxygen Calc11',\n",
        " 'NEWS Supplemental Oxygen Calc12',\n",
        " 'NEWS Supplemental Oxygen Calc13',\n",
        " 'NEWS Supplemental Oxygen Calc14',\n",
        " 'NEWS Supplemental Oxygen Calc15',\n",
        " 'NEWS Supplemental Oxygen Calc16',\n",
        " 'NEWS Supplemental Oxygen Calc17',\n",
        " 'NEWS Supplemental Oxygen Calc18',\n",
        " 'NEWS Supplemental Oxygen Calc19',\n",
        " 'NEWS Supplemental Oxygen Calc20',\n",
        " 'NEWS Supplemental Oxygen Calc21',\n",
        " 'NEWS Supplemental Oxygen Calc0_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc1_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc2_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc3_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc4_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc5_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc6_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc7_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc8_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc9_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc10_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc11_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc12_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc13_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc14_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc15_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc16_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc17_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc18_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc19_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc20_current_stay',\n",
        " 'NEWS Supplemental Oxygen Calc21_current_stay',\n",
        " 'Respiratory Rate0',\n",
        " 'Respiratory Rate2',\n",
        " 'Respiratory Rate3',\n",
        " 'Respiratory Rate4',\n",
        " 'Respiratory Rate5',\n",
        " 'Respiratory Rate6',\n",
        " 'Respiratory Rate7',\n",
        " 'Respiratory Rate8',\n",
        " 'Respiratory Rate9',\n",
        " 'Respiratory Rate11',\n",
        " 'Respiratory Rate12',\n",
        " 'Respiratory Rate13',\n",
        " 'Respiratory Rate14',\n",
        " 'Respiratory Rate15',\n",
        " 'Respiratory Rate16',\n",
        " 'Respiratory Rate18',\n",
        " 'Respiratory Rate19',\n",
        " 'Respiratory Rate20',\n",
        " 'Respiratory Rate21',\n",
        " 'Respiratory Rate0_current_stay',\n",
        " 'Respiratory Rate2_current_stay',\n",
        " 'Respiratory Rate3_current_stay',\n",
        " 'Respiratory Rate4_current_stay',\n",
        " 'Respiratory Rate5_current_stay',\n",
        " 'Respiratory Rate6_current_stay',\n",
        " 'Respiratory Rate8_current_stay',\n",
        " 'Respiratory Rate12_current_stay',\n",
        " 'Respiratory Rate13_current_stay',\n",
        " 'Respiratory Rate14_current_stay',\n",
        " 'Respiratory Rate16_current_stay',\n",
        " 'Respiratory Rate18_current_stay',\n",
        " 'Respiratory Rate19_current_stay',\n",
        " 'Respiratory Rate20_current_stay',\n",
        " 'Respiratory Rate21_current_stay',\n",
        " 'SpO20',\n",
        " 'SpO22',\n",
        " 'SpO23',\n",
        " 'SpO24',\n",
        " 'SpO25',\n",
        " 'SpO26',\n",
        " 'SpO27',\n",
        " 'SpO28',\n",
        " 'SpO29',\n",
        " 'SpO211',\n",
        " 'SpO212',\n",
        " 'SpO213',\n",
        " 'SpO214',\n",
        " 'SpO215',\n",
        " 'SpO216',\n",
        " 'SpO218',\n",
        " 'SpO219',\n",
        " 'SpO220',\n",
        " 'SpO221',\n",
        " 'SpO20_current_stay',\n",
        " 'SpO22_current_stay',\n",
        " 'SpO23_current_stay',\n",
        " 'SpO24_current_stay',\n",
        " 'SpO25_current_stay',\n",
        " 'SpO26_current_stay',\n",
        " 'SpO28_current_stay',\n",
        " 'SpO212_current_stay',\n",
        " 'SpO213_current_stay',\n",
        " 'SpO214_current_stay',\n",
        " 'SpO216_current_stay',\n",
        " 'SpO218_current_stay',\n",
        " 'SpO219_current_stay',\n",
        " 'SpO220_current_stay',\n",
        " 'SpO221_current_stay',\n",
        " 'Systolic Blood Pressure2',\n",
        " 'Systolic Blood Pressure3',\n",
        " 'Systolic Blood Pressure4',\n",
        " 'Systolic Blood Pressure5',\n",
        " 'Systolic Blood Pressure6',\n",
        " 'Systolic Blood Pressure7',\n",
        " 'Systolic Blood Pressure8',\n",
        " 'Systolic Blood Pressure9',\n",
        " 'Systolic Blood Pressure11',\n",
        " 'Systolic Blood Pressure12',\n",
        " 'Systolic Blood Pressure13',\n",
        " 'Systolic Blood Pressure14',\n",
        " 'Systolic Blood Pressure15',\n",
        " 'Systolic Blood Pressure16',\n",
        " 'Systolic Blood Pressure18',\n",
        " 'Systolic Blood Pressure19',\n",
        " 'Systolic Blood Pressure20',\n",
        " 'Systolic Blood Pressure21',\n",
        " 'Systolic Blood Pressure2_current_stay',\n",
        " 'Systolic Blood Pressure3_current_stay',\n",
        " 'Systolic Blood Pressure4_current_stay',\n",
        " 'Systolic Blood Pressure5_current_stay',\n",
        " 'Systolic Blood Pressure6_current_stay',\n",
        " 'Systolic Blood Pressure8_current_stay',\n",
        " 'Systolic Blood Pressure12_current_stay',\n",
        " 'Systolic Blood Pressure13_current_stay',\n",
        " 'Systolic Blood Pressure14_current_stay',\n",
        " 'Systolic Blood Pressure16_current_stay',\n",
        " 'Systolic Blood Pressure18_current_stay',\n",
        " 'Systolic Blood Pressure19_current_stay',\n",
        " 'Systolic Blood Pressure20_current_stay',\n",
        " 'Systolic Blood Pressure21_current_stay',\n",
        " 'Temperature0',\n",
        " 'Temperature2',\n",
        " 'Temperature3',\n",
        " 'Temperature4',\n",
        " 'Temperature5',\n",
        " 'Temperature6',\n",
        " 'Temperature7',\n",
        " 'Temperature8',\n",
        " 'Temperature9',\n",
        " 'Temperature11',\n",
        " 'Temperature12',\n",
        " 'Temperature13',\n",
        " 'Temperature14',\n",
        " 'Temperature15',\n",
        " 'Temperature16',\n",
        " 'Temperature18',\n",
        " 'Temperature19',\n",
        " 'Temperature20',\n",
        " 'Temperature21',\n",
        " 'Temperature0_current_stay',\n",
        " 'Temperature2_current_stay',\n",
        " 'Temperature3_current_stay',\n",
        " 'Temperature4_current_stay',\n",
        " 'Temperature5_current_stay',\n",
        " 'Temperature6_current_stay',\n",
        " 'Temperature8_current_stay',\n",
        " 'Temperature12_current_stay',\n",
        " 'Temperature13_current_stay',\n",
        " 'Temperature14_current_stay',\n",
        " 'Temperature16_current_stay',\n",
        " 'Temperature18_current_stay',\n",
        " 'Temperature19_current_stay',\n",
        " 'Temperature20_current_stay',\n",
        " 'Temperature21_current_stay',\n",
        " 'Diastolic Blood Pressure2_difference',\n",
        " 'Diastolic Blood Pressure3_difference',\n",
        " 'Diastolic Blood Pressure4_difference',\n",
        " 'Diastolic Blood Pressure5_difference',\n",
        " 'Diastolic Blood Pressure6_difference',\n",
        " 'Diastolic Blood Pressure7_difference',\n",
        " 'Diastolic Blood Pressure8_difference',\n",
        " 'Diastolic Blood Pressure9_difference',\n",
        " 'Diastolic Blood Pressure11_difference',\n",
        " 'Diastolic Blood Pressure12_difference',\n",
        " 'Diastolic Blood Pressure13_difference',\n",
        " 'Diastolic Blood Pressure14_difference',\n",
        " 'Diastolic Blood Pressure15_difference',\n",
        " 'Diastolic Blood Pressure16_difference',\n",
        " 'Diastolic Blood Pressure18_difference',\n",
        " 'Diastolic Blood Pressure19_difference',\n",
        " 'Diastolic Blood Pressure20_difference',\n",
        " 'Diastolic Blood Pressure21_difference',\n",
        " 'Diastolic Blood Pressure2_current_stay_difference',\n",
        " 'Diastolic Blood Pressure3_current_stay_difference',\n",
        " 'Diastolic Blood Pressure4_current_stay_difference',\n",
        " 'Diastolic Blood Pressure5_current_stay_difference',\n",
        " 'Diastolic Blood Pressure6_current_stay_difference',\n",
        " 'Diastolic Blood Pressure8_current_stay_difference',\n",
        " 'Diastolic Blood Pressure12_current_stay_difference',\n",
        " 'Diastolic Blood Pressure13_current_stay_difference',\n",
        " 'Diastolic Blood Pressure14_current_stay_difference',\n",
        " 'Diastolic Blood Pressure16_current_stay_difference',\n",
        " 'Diastolic Blood Pressure18_current_stay_difference',\n",
        " 'Diastolic Blood Pressure19_current_stay_difference',\n",
        " 'Diastolic Blood Pressure21_current_stay_difference',\n",
        " 'Glasgow Coma Score0_difference',\n",
        " 'Glasgow Coma Score1_difference',\n",
        " 'Glasgow Coma Score2_difference',\n",
        " 'Glasgow Coma Score3_difference',\n",
        " 'Glasgow Coma Score4_difference',\n",
        " 'Glasgow Coma Score5_difference',\n",
        " 'Glasgow Coma Score6_difference',\n",
        " 'Glasgow Coma Score7_difference',\n",
        " 'Glasgow Coma Score8_difference',\n",
        " 'Glasgow Coma Score9_difference',\n",
        " 'Glasgow Coma Score10_difference',\n",
        " 'Glasgow Coma Score11_difference',\n",
        " 'Glasgow Coma Score12_difference',\n",
        " 'Glasgow Coma Score13_difference',\n",
        " 'Glasgow Coma Score14_difference',\n",
        " 'Glasgow Coma Score15_difference',\n",
        " 'Glasgow Coma Score16_difference',\n",
        " 'Glasgow Coma Score17_difference',\n",
        " 'Glasgow Coma Score18_difference',\n",
        " 'Glasgow Coma Score19_difference',\n",
        " 'Glasgow Coma Score20_difference',\n",
        " 'Glasgow Coma Score21_difference',\n",
        " 'Glasgow Coma Score0_current_stay_difference',\n",
        " 'Glasgow Coma Score1_current_stay_difference',\n",
        " 'Glasgow Coma Score2_current_stay_difference',\n",
        " 'Glasgow Coma Score3_current_stay_difference',\n",
        " 'Glasgow Coma Score4_current_stay_difference',\n",
        " 'Glasgow Coma Score5_current_stay_difference',\n",
        " 'Glasgow Coma Score6_current_stay_difference',\n",
        " 'Glasgow Coma Score7_current_stay_difference',\n",
        " 'Glasgow Coma Score8_current_stay_difference',\n",
        " 'Glasgow Coma Score10_current_stay_difference',\n",
        " 'Glasgow Coma Score11_current_stay_difference',\n",
        " 'Glasgow Coma Score12_current_stay_difference',\n",
        " 'Glasgow Coma Score13_current_stay_difference',\n",
        " 'Glasgow Coma Score14_current_stay_difference',\n",
        " 'Glasgow Coma Score15_current_stay_difference',\n",
        " 'Glasgow Coma Score16_current_stay_difference',\n",
        " 'Glasgow Coma Score17_current_stay_difference',\n",
        " 'Glasgow Coma Score18_current_stay_difference',\n",
        " 'Glasgow Coma Score19_current_stay_difference',\n",
        " 'Glasgow Coma Score20_current_stay_difference',\n",
        " 'Glasgow Coma Score21_current_stay_difference',\n",
        " 'Heart Rate2_difference',\n",
        " 'Heart Rate3_difference',\n",
        " 'Heart Rate4_difference',\n",
        " 'Heart Rate5_difference',\n",
        " 'Heart Rate6_difference',\n",
        " 'Heart Rate7_difference',\n",
        " 'Heart Rate8_difference',\n",
        " 'Heart Rate9_difference',\n",
        " 'Heart Rate11_difference',\n",
        " 'Heart Rate12_difference',\n",
        " 'Heart Rate13_difference',\n",
        " 'Heart Rate14_difference',\n",
        " 'Heart Rate15_difference',\n",
        " 'Heart Rate16_difference',\n",
        " 'Heart Rate18_difference',\n",
        " 'Heart Rate19_difference',\n",
        " 'Heart Rate20_difference',\n",
        " 'Heart Rate21_difference',\n",
        " 'Heart Rate2_current_stay_difference',\n",
        " 'Heart Rate3_current_stay_difference',\n",
        " 'Heart Rate4_current_stay_difference',\n",
        " 'Heart Rate5_current_stay_difference',\n",
        " 'Heart Rate6_current_stay_difference',\n",
        " 'Heart Rate8_current_stay_difference',\n",
        " 'Heart Rate12_current_stay_difference',\n",
        " 'Heart Rate13_current_stay_difference',\n",
        " 'Heart Rate14_current_stay_difference',\n",
        " 'Heart Rate16_current_stay_difference',\n",
        " 'Heart Rate18_current_stay_difference',\n",
        " 'Heart Rate19_current_stay_difference',\n",
        " 'Heart Rate21_current_stay_difference',\n",
        " 'Mean Arterial Pressure2_difference',\n",
        " 'Mean Arterial Pressure3_difference',\n",
        " 'Mean Arterial Pressure4_difference',\n",
        " 'Mean Arterial Pressure5_difference',\n",
        " 'Mean Arterial Pressure6_difference',\n",
        " 'Mean Arterial Pressure7_difference',\n",
        " 'Mean Arterial Pressure8_difference',\n",
        " 'Mean Arterial Pressure9_difference',\n",
        " 'Mean Arterial Pressure11_difference',\n",
        " 'Mean Arterial Pressure12_difference',\n",
        " 'Mean Arterial Pressure13_difference',\n",
        " 'Mean Arterial Pressure14_difference',\n",
        " 'Mean Arterial Pressure15_difference',\n",
        " 'Mean Arterial Pressure16_difference',\n",
        " 'Mean Arterial Pressure18_difference',\n",
        " 'Mean Arterial Pressure19_difference',\n",
        " 'Mean Arterial Pressure20_difference',\n",
        " 'Mean Arterial Pressure21_difference',\n",
        " 'Mean Arterial Pressure2_current_stay_difference',\n",
        " 'Mean Arterial Pressure3_current_stay_difference',\n",
        " 'Mean Arterial Pressure4_current_stay_difference',\n",
        " 'Mean Arterial Pressure5_current_stay_difference',\n",
        " 'Mean Arterial Pressure6_current_stay_difference',\n",
        " 'Mean Arterial Pressure8_current_stay_difference',\n",
        " 'Mean Arterial Pressure12_current_stay_difference',\n",
        " 'Mean Arterial Pressure13_current_stay_difference',\n",
        " 'Mean Arterial Pressure14_current_stay_difference',\n",
        " 'Mean Arterial Pressure16_current_stay_difference',\n",
        " 'Mean Arterial Pressure18_current_stay_difference',\n",
        " 'Mean Arterial Pressure19_current_stay_difference',\n",
        " 'Mean Arterial Pressure21_current_stay_difference',\n",
        " 'NEWS Conscious Level Score0_difference',\n",
        " 'NEWS Conscious Level Score1_difference',\n",
        " 'NEWS Conscious Level Score2_difference',\n",
        " 'NEWS Conscious Level Score3_difference',\n",
        " 'NEWS Conscious Level Score4_difference',\n",
        " 'NEWS Conscious Level Score5_difference',\n",
        " 'NEWS Conscious Level Score6_difference',\n",
        " 'NEWS Conscious Level Score7_difference',\n",
        " 'NEWS Conscious Level Score8_difference',\n",
        " 'NEWS Conscious Level Score9_difference',\n",
        " 'NEWS Conscious Level Score10_difference',\n",
        " 'NEWS Conscious Level Score11_difference',\n",
        " 'NEWS Conscious Level Score12_difference',\n",
        " 'NEWS Conscious Level Score13_difference',\n",
        " 'NEWS Conscious Level Score14_difference',\n",
        " 'NEWS Conscious Level Score15_difference',\n",
        " 'NEWS Conscious Level Score16_difference',\n",
        " 'NEWS Conscious Level Score17_difference',\n",
        " 'NEWS Conscious Level Score18_difference',\n",
        " 'NEWS Conscious Level Score19_difference',\n",
        " 'NEWS Conscious Level Score20_difference',\n",
        " 'NEWS Conscious Level Score21_difference',\n",
        " 'NEWS Conscious Level Score0_current_stay_difference',\n",
        " 'NEWS Conscious Level Score1_current_stay_difference',\n",
        " 'NEWS Conscious Level Score2_current_stay_difference',\n",
        " 'NEWS Conscious Level Score3_current_stay_difference',\n",
        " 'NEWS Conscious Level Score4_current_stay_difference',\n",
        " 'NEWS Conscious Level Score5_current_stay_difference',\n",
        " 'NEWS Conscious Level Score6_current_stay_difference',\n",
        " 'NEWS Conscious Level Score7_current_stay_difference',\n",
        " 'NEWS Conscious Level Score8_current_stay_difference',\n",
        " 'NEWS Conscious Level Score9_current_stay_difference',\n",
        " 'NEWS Conscious Level Score10_current_stay_difference',\n",
        " 'NEWS Conscious Level Score11_current_stay_difference',\n",
        " 'NEWS Conscious Level Score12_current_stay_difference',\n",
        " 'NEWS Conscious Level Score13_current_stay_difference',\n",
        " 'NEWS Conscious Level Score14_current_stay_difference',\n",
        " 'NEWS Conscious Level Score15_current_stay_difference',\n",
        " 'NEWS Conscious Level Score16_current_stay_difference',\n",
        " 'NEWS Conscious Level Score17_current_stay_difference',\n",
        " 'NEWS Conscious Level Score18_current_stay_difference',\n",
        " 'NEWS Conscious Level Score19_current_stay_difference',\n",
        " 'NEWS Conscious Level Score20_current_stay_difference',\n",
        " 'NEWS Conscious Level Score21_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc0_difference',\n",
        " 'NEWS Supplemental Oxygen Calc1_difference',\n",
        " 'NEWS Supplemental Oxygen Calc2_difference',\n",
        " 'NEWS Supplemental Oxygen Calc3_difference',\n",
        " 'NEWS Supplemental Oxygen Calc4_difference',\n",
        " 'NEWS Supplemental Oxygen Calc5_difference',\n",
        " 'NEWS Supplemental Oxygen Calc6_difference',\n",
        " 'NEWS Supplemental Oxygen Calc7_difference',\n",
        " 'NEWS Supplemental Oxygen Calc8_difference',\n",
        " 'NEWS Supplemental Oxygen Calc9_difference',\n",
        " 'NEWS Supplemental Oxygen Calc10_difference',\n",
        " 'NEWS Supplemental Oxygen Calc11_difference',\n",
        " 'NEWS Supplemental Oxygen Calc12_difference',\n",
        " 'NEWS Supplemental Oxygen Calc13_difference',\n",
        " 'NEWS Supplemental Oxygen Calc14_difference',\n",
        " 'NEWS Supplemental Oxygen Calc15_difference',\n",
        " 'NEWS Supplemental Oxygen Calc16_difference',\n",
        " 'NEWS Supplemental Oxygen Calc17_difference',\n",
        " 'NEWS Supplemental Oxygen Calc18_difference',\n",
        " 'NEWS Supplemental Oxygen Calc19_difference',\n",
        " 'NEWS Supplemental Oxygen Calc20_difference',\n",
        " 'NEWS Supplemental Oxygen Calc21_difference',\n",
        " 'NEWS Supplemental Oxygen Calc0_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc1_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc2_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc3_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc4_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc5_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc6_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc7_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc8_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc10_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc12_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc13_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc14_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc15_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc16_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc18_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc19_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc20_current_stay_difference',\n",
        " 'NEWS Supplemental Oxygen Calc21_current_stay_difference',\n",
        " 'Respiratory Rate2_difference',\n",
        " 'Respiratory Rate3_difference',\n",
        " 'Respiratory Rate4_difference',\n",
        " 'Respiratory Rate5_difference',\n",
        " 'Respiratory Rate6_difference',\n",
        " 'Respiratory Rate7_difference',\n",
        " 'Respiratory Rate8_difference',\n",
        " 'Respiratory Rate9_difference',\n",
        " 'Respiratory Rate11_difference',\n",
        " 'Respiratory Rate12_difference',\n",
        " 'Respiratory Rate13_difference',\n",
        " 'Respiratory Rate14_difference',\n",
        " 'Respiratory Rate15_difference',\n",
        " 'Respiratory Rate16_difference',\n",
        " 'Respiratory Rate18_difference',\n",
        " 'Respiratory Rate19_difference',\n",
        " 'Respiratory Rate20_difference',\n",
        " 'Respiratory Rate21_difference',\n",
        " 'Respiratory Rate0_current_stay_difference',\n",
        " 'Respiratory Rate2_current_stay_difference',\n",
        " 'Respiratory Rate3_current_stay_difference',\n",
        " 'Respiratory Rate4_current_stay_difference',\n",
        " 'Respiratory Rate5_current_stay_difference',\n",
        " 'Respiratory Rate6_current_stay_difference',\n",
        " 'Respiratory Rate8_current_stay_difference',\n",
        " 'Respiratory Rate12_current_stay_difference',\n",
        " 'Respiratory Rate13_current_stay_difference',\n",
        " 'Respiratory Rate14_current_stay_difference',\n",
        " 'Respiratory Rate16_current_stay_difference',\n",
        " 'Respiratory Rate18_current_stay_difference',\n",
        " 'Respiratory Rate19_current_stay_difference',\n",
        " 'Respiratory Rate21_current_stay_difference',\n",
        " 'SpO22_difference',\n",
        " 'SpO23_difference',\n",
        " 'SpO24_difference',\n",
        " 'SpO25_difference',\n",
        " 'SpO26_difference',\n",
        " 'SpO27_difference',\n",
        " 'SpO28_difference',\n",
        " 'SpO29_difference',\n",
        " 'SpO211_difference',\n",
        " 'SpO212_difference',\n",
        " 'SpO213_difference',\n",
        " 'SpO214_difference',\n",
        " 'SpO215_difference',\n",
        " 'SpO216_difference',\n",
        " 'SpO218_difference',\n",
        " 'SpO219_difference',\n",
        " 'SpO220_difference',\n",
        " 'SpO221_difference',\n",
        " 'SpO22_current_stay_difference',\n",
        " 'SpO23_current_stay_difference',\n",
        " 'SpO24_current_stay_difference',\n",
        " 'SpO25_current_stay_difference',\n",
        " 'SpO26_current_stay_difference',\n",
        " 'SpO28_current_stay_difference',\n",
        " 'SpO212_current_stay_difference',\n",
        " 'SpO213_current_stay_difference',\n",
        " 'SpO214_current_stay_difference',\n",
        " 'SpO216_current_stay_difference',\n",
        " 'SpO218_current_stay_difference',\n",
        " 'SpO219_current_stay_difference',\n",
        " 'SpO221_current_stay_difference',\n",
        " 'Systolic Blood Pressure2_difference',\n",
        " 'Systolic Blood Pressure3_difference',\n",
        " 'Systolic Blood Pressure4_difference',\n",
        " 'Systolic Blood Pressure5_difference',\n",
        " 'Systolic Blood Pressure6_difference',\n",
        " 'Systolic Blood Pressure7_difference',\n",
        " 'Systolic Blood Pressure8_difference',\n",
        " 'Systolic Blood Pressure9_difference',\n",
        " 'Systolic Blood Pressure11_difference',\n",
        " 'Systolic Blood Pressure12_difference',\n",
        " 'Systolic Blood Pressure13_difference',\n",
        " 'Systolic Blood Pressure14_difference',\n",
        " 'Systolic Blood Pressure15_difference',\n",
        " 'Systolic Blood Pressure16_difference',\n",
        " 'Systolic Blood Pressure18_difference',\n",
        " 'Systolic Blood Pressure19_difference',\n",
        " 'Systolic Blood Pressure20_difference',\n",
        " 'Systolic Blood Pressure21_difference',\n",
        " 'Systolic Blood Pressure2_current_stay_difference',\n",
        " 'Systolic Blood Pressure3_current_stay_difference',\n",
        " 'Systolic Blood Pressure4_current_stay_difference',\n",
        " 'Systolic Blood Pressure5_current_stay_difference',\n",
        " 'Systolic Blood Pressure6_current_stay_difference',\n",
        " 'Systolic Blood Pressure8_current_stay_difference',\n",
        " 'Systolic Blood Pressure12_current_stay_difference',\n",
        " 'Systolic Blood Pressure13_current_stay_difference',\n",
        " 'Systolic Blood Pressure14_current_stay_difference',\n",
        " 'Systolic Blood Pressure16_current_stay_difference',\n",
        " 'Systolic Blood Pressure18_current_stay_difference',\n",
        " 'Systolic Blood Pressure19_current_stay_difference',\n",
        " 'Systolic Blood Pressure21_current_stay_difference',\n",
        " 'Temperature2_difference',\n",
        " 'Temperature3_difference',\n",
        " 'Temperature4_difference',\n",
        " 'Temperature5_difference',\n",
        " 'Temperature6_difference',\n",
        " 'Temperature7_difference',\n",
        " 'Temperature8_difference',\n",
        " 'Temperature9_difference',\n",
        " 'Temperature11_difference',\n",
        " 'Temperature12_difference',\n",
        " 'Temperature13_difference',\n",
        " 'Temperature14_difference',\n",
        " 'Temperature15_difference',\n",
        " 'Temperature16_difference',\n",
        " 'Temperature18_difference',\n",
        " 'Temperature19_difference',\n",
        " 'Temperature20_difference',\n",
        " 'Temperature21_difference',\n",
        " 'Temperature2_current_stay_difference',\n",
        " 'Temperature3_current_stay_difference',\n",
        " 'Temperature4_current_stay_difference',\n",
        " 'Temperature5_current_stay_difference',\n",
        " 'Temperature6_current_stay_difference',\n",
        " 'Temperature8_current_stay_difference',\n",
        " 'Temperature12_current_stay_difference',\n",
        " 'Temperature13_current_stay_difference',\n",
        " 'Temperature14_current_stay_difference',\n",
        " 'Temperature16_current_stay_difference',\n",
        " 'Temperature18_current_stay_difference',\n",
        " 'Temperature19_current_stay_difference',\n",
        " 'Temperature21_current_stay_difference']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1711549564896
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Function to remove outliers\n",
        "def remove_data_outliers(df, coeff=6, tol=0):\n",
        "    \"\"\"Utility function to remove data outliers from the data set using Z-Score method.\n",
        "    Args:\n",
        "        df (DataFrame): Input transformed data set.\n",
        "        coeff (float, optional): Scaling coefficient for outlier removal strategy. Defaults to 6.\n",
        "        tol (int, optional): Feature tolerance on how many features with NaN values may exist. Defaults to 0.\n",
        "    Returns:\n",
        "        Data set (DataFrame): Output data set without outlier values.\n",
        "        Outliers per variable (Series): Number of outliers remaining per variable.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate IQR = Q3 - Q1\n",
        "    q1, q3 = df.quantile(.25), df.quantile(.75)\n",
        "    IQR = q3 - q1\n",
        "    lower_bound = q1 - (coeff * IQR)\n",
        "    upper_bound = q3 + (coeff * IQR)\n",
        "\n",
        "    # Set the outliers to unique number\n",
        "    df[(df < lower_bound) | (df > upper_bound)] = 999999999\n",
        "\n",
        "    # Store number of outliers per column\n",
        "    outlier_count = df[df == 999999999].count(axis=0)\n",
        "\n",
        "    # Set the outliers to NaN\n",
        "    df = df.replace(999999999, np.NaN)\n",
        "\n",
        "    # Return complete profiles and outliers per column\n",
        "    return df, outlier_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1711549566193
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def generate_synthetic_data(df, percentiles=None, trend=None, seed=0, new_df_length=10):\n",
        "    synthetic_data = pd.DataFrame()\n",
        "    np.random.seed(seed)  # Set a seed for reproducibility\n",
        "\n",
        "    for col in df.columns:\n",
        "        if percentiles and col in percentiles:\n",
        "            # Specify the desired percentile range for each column\n",
        "            lower_percentile, upper_percentile = percentiles[col]\n",
        "            lower_limit = np.nanpercentile(df[col], lower_percentile)\n",
        "            upper_limit = np.nanpercentile(df[col], upper_percentile)\n",
        "            \n",
        "            # Filter data within the specified percentile range\n",
        "            within_percentile_range = df[(df[col] >= lower_limit) & (df[col] <= upper_limit)]\n",
        "            \n",
        "            # Calculate mean and std only within the specified percentile range\n",
        "            mean, std = within_percentile_range[col].mean(), within_percentile_range[col].std()\n",
        "            \n",
        "            # Generate synthetic data by sampling from a Gaussian distribution\n",
        "            synthetic_values = np.random.normal(loc=mean, scale=std, size=new_df_length)\n",
        "            \n",
        "            # Apply an increasing trend with a defined rate of change\n",
        "            if trend and col in trend:\n",
        "                rate_of_change = trend[col]\n",
        "                synthetic_values += np.arange(len(synthetic_values)) * rate_of_change\n",
        "            \n",
        "            # Clip values to within the real data range\n",
        "            synthetic_values = np.clip(synthetic_values, df[col].min(), df[col].max())\n",
        "            \n",
        "            synthetic_data[col] = synthetic_values\n",
        "        else:\n",
        "            # If no specific percentile range is specified, use the entire distribution\n",
        "            # Calculate mean and std\n",
        "            mean, std = df[col].mean(), df[col].std()\n",
        "            # Generate synthetic data by sampling from a Gaussian distribution\n",
        "            synthetic_values = np.random.normal(loc=mean, scale=std, size=new_df_length)\n",
        "\n",
        "            # Apply an increasing trend with a defined rate of change\n",
        "            if trend and col in trend:\n",
        "                rate_of_change = trend[col]\n",
        "                synthetic_values += np.arange(len(synthetic_values)) * rate_of_change\n",
        "            \n",
        "            # Clip values to within the real data range\n",
        "            synthetic_values = np.clip(synthetic_values, df[col].min(), df[col].max())\n",
        "            \n",
        "            synthetic_data[col] = synthetic_values\n",
        "\n",
        "    return synthetic_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1711549566719
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define C22 function\n",
        "def c22_24_fun(df):\n",
        "    c22 = Catch22(catch24=True) # Add catch24 = True\n",
        "    master_df = pd.DataFrame()\n",
        "    overlord_df = pd.DataFrame()\n",
        "    remove_set = set()\n",
        "    for x in range(len(df.columns)): # Iterate through columns so not to many nans\n",
        "        print('column number:', x)\n",
        "        working_df = df.iloc[:, x]\n",
        "        working_df = working_df.to_frame()\n",
        "        for column_name in working_df:\n",
        "            master_df = pd.DataFrame()\n",
        "            master_df2 = pd.DataFrame()\n",
        "            for stay_id, new_df in working_df[[column_name]].groupby(level=0):\n",
        "                    new_df2 = new_df.reset_index(drop=True).dropna()\n",
        "                    \n",
        "                    # C22 for current day\n",
        "                    if len(new_df2) <= 2: # c22 only works with 3 or more timepoints\n",
        "                        transformed_data = pd.DataFrame()\n",
        "                        np_data = new_df2.to_numpy()\n",
        "                        if not np_data.size == 0:\n",
        "                            transformed_data['22'] = np.mean(new_df2.to_numpy())\n",
        "                            transformed_data['23'] = np.std(new_df.to_numpy())\n",
        "                    else:\n",
        "                        transformed_data = c22.fit_transform(new_df2)\n",
        "\n",
        "                    transformed_data = transformed_data.add_prefix(column_name)           \n",
        "                    transformed_data.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                    transformed_data.insert(1, 'date', new_df.reset_index().iloc[-1]['date'])\n",
        "                    transformed_data.insert(2, '24_hour_flag', 1)\n",
        "\n",
        "                    # C22 for all data to date for stay - same for first 24 hours\n",
        "                    transformed_data2 = transformed_data.iloc[:,3:].copy()\n",
        "                    transformed_data2 = transformed_data2.add_suffix('_current_stay') # Indicate different as temporal over whole of current stay\n",
        "                    transformed_data2.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                    transformed_data2.insert(1, 'date', new_df.reset_index().iloc[-1]['date'])\n",
        "                    transformed_data2.insert(2, '24_hour_flag', 1)\n",
        "\n",
        "                    # Create master df's\n",
        "                    master_df = pd.concat([master_df, transformed_data])\n",
        "                    master_df2 = pd.concat([master_df2, transformed_data2])\n",
        "\n",
        "\n",
        "            master_df.reset_index(inplace=True, drop=True)\n",
        "            master_df2.reset_index(inplace=True, drop=True)\n",
        "\n",
        "            master_df = master_df.merge(master_df2, how='left', on=['SPELL_IDENTIFIER', 'date', '24_hour_flag'])\n",
        "\n",
        "        if x == 0:\n",
        "            overlord_df = master_df.copy()\n",
        "        else:\n",
        "            overlord_df = overlord_df.merge(master_df, how='outer', on=['SPELL_IDENTIFIER', 'date', '24_hour_flag'])\n",
        "        \n",
        "    return overlord_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1711549567153
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define C22 function\n",
        "def c22_48_fun(df):\n",
        "    c22 = Catch22(catch24=True)\n",
        "    c22_2 = Catch22(catch24=True)\n",
        "    master_df = pd.DataFrame()\n",
        "    overlord_df = pd.DataFrame()\n",
        "    remove_set = set()\n",
        "    for x in range(len(df.columns)): # Iterate through columns so not to many nans\n",
        "        print('column number:', x)\n",
        "        working_df = df.iloc[:, x]\n",
        "        working_df = working_df.to_frame()\n",
        "        for column_name in working_df:\n",
        "            master_df = pd.DataFrame()\n",
        "            master_df2 = pd.DataFrame()\n",
        "            for stay_id, new_df in working_df[[column_name]].groupby(level=0):\n",
        "\n",
        "                    new_df2 = new_df.tail(4).reset_index(drop=True).dropna()\n",
        "                    new_df3 = new_df.reset_index(drop=True).dropna()\n",
        "                    \n",
        "                    # C22 for latest day\n",
        "                    if len(new_df2) <= 2: # c22 only works with 3 or more timepoints\n",
        "                        transformed_data = pd.DataFrame()\n",
        "                        np_data = new_df2.to_numpy()\n",
        "                        if not np_data.size == 0:\n",
        "                            transformed_data['22'] = np.mean(np_data)\n",
        "                            transformed_data['23'] = np.std(np_data)\n",
        "                    else: \n",
        "                        transformed_data = c22.fit_transform(new_df2)\n",
        "                    transformed_data = transformed_data.add_prefix(column_name)           \n",
        "                    transformed_data.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                    transformed_data.insert(1, 'date', new_df.reset_index().iloc[-1]['date'])\n",
        "                    transformed_data.insert(2, '48_hour_flag', 1)\n",
        "\n",
        "                    # C22 for all data to date for stay\n",
        "                    if len(new_df3) <= 2: # c22 only works with 3 or more timepoints\n",
        "                        transformed_data2 = pd.DataFrame()\n",
        "                        np_data = new_df3.to_numpy()\n",
        "                        if not np_data.size == 0:\n",
        "                            transformed_data2['22'] = np.mean(np_data)\n",
        "                            transformed_data2['23'] = np.std(np_data) \n",
        "                    else:\n",
        "                        transformed_data2 = c22_2.fit_transform(new_df3)\n",
        "                    transformed_data2 = transformed_data2.add_prefix(column_name)  \n",
        "                    transformed_data2 = transformed_data2.add_suffix('_current_stay') # Indicate different as temporal over whole of current stay             \n",
        "                    transformed_data2.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                    transformed_data2.insert(1, 'date', new_df.reset_index().iloc[-1]['date'])\n",
        "                    transformed_data2.insert(2, '48_hour_flag', 1)\n",
        "\n",
        "                    # Create master df's\n",
        "                    master_df = pd.concat([master_df, transformed_data])\n",
        "                    master_df2 = pd.concat([master_df2, transformed_data2])\n",
        "\n",
        "            master_df.reset_index(inplace=True, drop=True)\n",
        "            master_df2.reset_index(inplace=True, drop=True)\n",
        "\n",
        "            master_df = master_df.merge(master_df2, how='left', on=['SPELL_IDENTIFIER', 'date', '48_hour_flag'])\n",
        "\n",
        "        if x == 0:\n",
        "            overlord_df = master_df.copy()\n",
        "        else:\n",
        "            overlord_df = overlord_df.merge(master_df, how='outer', on=['SPELL_IDENTIFIER', 'date', '48_hour_flag'])\n",
        "\n",
        "    return overlord_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1711549567618
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def c22_other_fun(df):\n",
        "    c22 = Catch22(catch24=True)\n",
        "    master_df = pd.DataFrame()\n",
        "    overlord_df = pd.DataFrame()\n",
        "    for x in range(len(df.columns)): # Iterate through columns sas this c22 does not work on multiple columns\n",
        "        print('column number:', x)\n",
        "        working_df = df.iloc[:, x]\n",
        "        working_df = working_df.to_frame()\n",
        "        for column_name in working_df:\n",
        "            master_df = pd.DataFrame()\n",
        "            master_df2 = pd.DataFrame()\n",
        "            for stay_id, new_df in working_df[[column_name]].groupby(level=0, dropna=False): # Iterate through stays\n",
        "\n",
        "                n_list = list(range(1, math.ceil(len(new_df)/4)+1))\n",
        "                for n in range(1, math.ceil(len(new_df)/4)+1): # Do this to understand how many 'days' / sets of data we will have for each stay beyond 24 and 48 hours\n",
        "                    # Ignore first 48 hours as calculated seperatly\n",
        "                    if n == 1:\n",
        "                        continue\n",
        "                    elif n == 2:\n",
        "                        continue\n",
        "                    # This is for exceptional cases where we want hours grouped 1 for last day and the spell starts on hours grouped 2\n",
        "                    elif (new_df.reset_index().iloc[0]['hours_grouped'] == 2) and ((n == (len(new_df)/4)) and (n == n_list[-1])):\n",
        "                        exit_flag = True\n",
        "                        flag_2 = False\n",
        "                        flag_1 = False\n",
        "                        # Get index of nth 2 hours grouped value\n",
        "                        try:\n",
        "                            index_value = new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index][new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index]['hours_grouped'] == 2].index.values[0]\n",
        "                            new_df2 = new_df.iloc[:index_value+1]\n",
        "                            exit_flag = False\n",
        "                            flag_2 = True\n",
        "                        #  Look at nth 1 hours grouped  \n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                        try:\n",
        "                            index_value = new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index][new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index]['hours_grouped'] == 1].index.values[0]\n",
        "                            new_df3 = new_df.iloc[:index_value+1]\n",
        "                            exit_flag = False\n",
        "                            flag_1 = True\n",
        "                        except:\n",
        "                            pass\n",
        "                        \n",
        "                        if exit_flag == True:\n",
        "                            continue\n",
        "                        \n",
        "                        if flag_2 == True:\n",
        "                            new_df2_2 = new_df2.tail(4).reset_index(drop=True).dropna()\n",
        "                            new_df2_3 = new_df2.reset_index(drop=True).dropna()\n",
        "                    \n",
        "                            # C22 for latest day\n",
        "                            if len(new_df2_2) <= 2: # c22 only works with 3 or more timepoints\n",
        "                                transformed_data = pd.DataFrame()\n",
        "                                np_data = new_df2_2.to_numpy()\n",
        "                                if not np_data.size == 0:\n",
        "                                    transformed_data['22'] = np.mean(np_data)\n",
        "                                    transformed_data['23'] = np.std(np_data) \n",
        "                            else: \n",
        "                                transformed_data = c22.fit_transform(new_df2_2)\n",
        "\n",
        "                            transformed_data = transformed_data.add_prefix(column_name)           \n",
        "                            transformed_data.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                            transformed_data.insert(1, 'date', new_df2.reset_index().iloc[-1]['date'])\n",
        "\n",
        "                            # C22 for all data to date for stay\n",
        "                            if len(new_df2_3) <= 2: # c22 only works with 3 or more timepoints\n",
        "                                transformed_data2 = pd.DataFrame()\n",
        "                                np_data = new_df2_3.to_numpy()\n",
        "                                if not np_data.size == 0:\n",
        "                                    transformed_data2['22'] = np.mean(np_data)\n",
        "                                    transformed_data2['23'] = np.std(np_data)\n",
        "                            else: \n",
        "                                transformed_data2 = c22.fit_transform(new_df2_3)\n",
        "\n",
        "                            transformed_data2 = transformed_data2.add_prefix(column_name)  \n",
        "                            transformed_data2 = transformed_data2.add_suffix('_current_stay') # Indicate different as temporal over whole of current stay             \n",
        "                            transformed_data2.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                            transformed_data2.insert(1, 'date', new_df2.reset_index().iloc[-1]['date'])\n",
        "\n",
        "                        else:\n",
        "                            transformed_data = pd.DataFrame()\n",
        "                            transformed_data2 = pd.DataFrame()\n",
        "                        \n",
        "                        if flag_1 == True:\n",
        "                            new_df3_2 = new_df3.tail(4).reset_index(drop=True).dropna()\n",
        "                            new_df3_3 = new_df3.reset_index(drop=True).dropna()\n",
        "\n",
        "                            # C22 for latest day\n",
        "                            if len(new_df3_2) <= 2: # c22 only works with 3 or more timepoints\n",
        "                                transformed_data3 = pd.DataFrame()\n",
        "                                np_data = new_df3_2.to_numpy()\n",
        "                                if not np_data.size == 0:\n",
        "                                    transformed_data3['22'] = np.mean(np_data)\n",
        "                                    transformed_data3['23'] = np.std(np_data)\n",
        "                            else: \n",
        "                                transformed_data3 = c22.fit_transform(new_df3_2)\n",
        "\n",
        "                            transformed_data3 = transformed_data3.add_prefix(column_name)           \n",
        "                            transformed_data3.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                            transformed_data3.insert(1, 'date', new_df.reset_index().iloc[-1]['date'])\n",
        "\n",
        "                            # C22 for all data to date for stay\n",
        "                            if len(new_df3_3) <= 2: # c22 only works with 3 or more timepoints\n",
        "                                transformed_data4 = pd.DataFrame()\n",
        "                                np_data = new_df3_3.to_numpy()\n",
        "                                if not np_data.size == 0:\n",
        "                                    transformed_data4['22'] = np.mean(np_data)\n",
        "                                    transformed_data4['23'] = np.std(np_data) \n",
        "                            else: \n",
        "                                transformed_data4 = c22.fit_transform(new_df3_3)\n",
        "                                transformed_data4 = transformed_data4.add_prefix(column_name)  \n",
        "                                transformed_data4 = transformed_data4.add_suffix('_current_stay') # Indicate different as temporal over whole of current stay             \n",
        "                                transformed_data4.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                                transformed_data4.insert(1, 'date', new_df3.reset_index().iloc[-1]['date'])\n",
        "                        else:\n",
        "                            transformed_data3 = pd.DataFrame()\n",
        "                            transformed_data4 = pd.DataFrame()\n",
        "                        \n",
        "                        # Combine\n",
        "                        transformed_data = pd.concat([transformed_data, transformed_data3], ignore_index=True)\n",
        "                        transformed_data2 = pd.concat([transformed_data2, transformed_data4], ignore_index=True)\n",
        "\n",
        "                        # Create master df's\n",
        "                        master_df = pd.concat([master_df, transformed_data])\n",
        "                        master_df2 = pd.concat([master_df2, transformed_data2])\n",
        "\n",
        "\n",
        "                    # This is for most cases  \n",
        "                    else:\n",
        "                        # Get index of nth 2 hours grouped value\n",
        "                        try:\n",
        "                            index_value = new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index][new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index]['hours_grouped'] == 2].index.values[0]\n",
        "                            new_df2 = new_df.iloc[:index_value+1]\n",
        "                        except:\n",
        "                            # If fails look at nth 1 hours grouped  \n",
        "                            try:\n",
        "                                index_value = new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index][new_df.reset_index().iloc[(new_df.reset_index().groupby('hours_grouped').cumcount() == n-1)[new_df.reset_index().groupby('hours_grouped').cumcount() == n-1].index]['hours_grouped'] == 1].index.values[0]\n",
        "                                new_df2 = new_df.iloc[:index_value+1]\n",
        "                            except:\n",
        "                                continue\n",
        "\n",
        "                        new_df2_2 = new_df2.tail(4).reset_index(drop=True).dropna()\n",
        "                        new_df2_3 = new_df2.reset_index(drop=True).dropna()\n",
        "                    \n",
        "                        # C22 for latest day\n",
        "                        if len(new_df2_2) <= 2: # c22 only works with 3 or more timepoints\n",
        "                            transformed_data = pd.DataFrame()\n",
        "                            np_data = new_df2_2.to_numpy()\n",
        "                            if not np_data.size == 0:\n",
        "                                transformed_data['22'] = np.mean(np_data)\n",
        "                                transformed_data['23'] = np.std(np_data) \n",
        "                        else: \n",
        "                            transformed_data = c22.fit_transform(new_df2_2)                        \n",
        "                        \n",
        "                        transformed_data = transformed_data.add_prefix(column_name)           \n",
        "                        transformed_data.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                        transformed_data.insert(1, 'date', new_df2.reset_index().iloc[-1]['date'])\n",
        "\n",
        "                        # C22 for all data to date for stay\n",
        "                        if len(new_df2_3) <= 2: # c22 only works with 3 or more timepoints\n",
        "                            transformed_data2 = pd.DataFrame()\n",
        "                            np_data = new_df2_3.to_numpy()\n",
        "                            if not np_data.size == 0:\n",
        "                                transformed_data2['22'] = np.mean(np_data)\n",
        "                                transformed_data2['23'] = np.std(np_data)\n",
        "                        else: \n",
        "                            transformed_data2 = c22.fit_transform(new_df2_3)                        \n",
        "\n",
        "                        transformed_data2 = transformed_data2.add_prefix(column_name)  \n",
        "                        transformed_data2 = transformed_data2.add_suffix('_current_stay') # Indicate different as temporal over whole of current stay             \n",
        "                        transformed_data2.insert(0, 'SPELL_IDENTIFIER', stay_id)\n",
        "                        transformed_data2.insert(1, 'date', new_df2.reset_index().iloc[-1]['date'])\n",
        "\n",
        "                        # Create master df's\n",
        "                        master_df = pd.concat([master_df, transformed_data])\n",
        "                        master_df2 = pd.concat([master_df2, transformed_data2])\n",
        "\n",
        "            master_df.reset_index(inplace=True, drop=True)\n",
        "            master_df2.reset_index(inplace=True, drop=True)\n",
        "\n",
        "            if master_df.empty:\n",
        "                if master_df2.empty:\n",
        "                    continue\n",
        "                else:\n",
        "                    master_df = master_df2\n",
        "            else:\n",
        "                master_df = master_df.merge(master_df2, how='left', on=['SPELL_IDENTIFIER', 'date'])\n",
        "\n",
        "        if x == 0:\n",
        "            overlord_df = master_df.copy()\n",
        "        elif master_df.empty:\n",
        "            continue\n",
        "        else:\n",
        "            overlord_df = overlord_df.merge(master_df, how='outer', on=['SPELL_IDENTIFIER', 'date'])\n",
        "            overlord_df.dropna(axis=0, how='all', inplace=True)\n",
        "        \n",
        "        # Save as go through\n",
        "        overlord_df.to_csv('switch_data/new_c22_other_days.csv', index=False)\n",
        "\n",
        "    return overlord_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1711549568096
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def preprocess_fun(data):\n",
        "    # Split X y\n",
        "    X = data.drop(columns=['SPELL_IDENTIFIER', 'date', 'ROUTE', 'po_flag', 'iv_treatment_length', '24_hour_flag', '48_hour_flag'])\n",
        "    y = data['po_flag']\n",
        "    # Remove outliers\n",
        "    times = 2\n",
        "    X2, outlier_count = remove_data_outliers(X, coeff=times)\n",
        "    # Forward fill based on stay_id and -1 fill missing\n",
        "    X2 = pd.concat([X2, data['SPELL_IDENTIFIER']], axis=1)\n",
        "    ffilled_data = X2.groupby('SPELL_IDENTIFIER').transform(lambda p: p.ffill())\n",
        "    ffilled_features = ffilled_data\n",
        "    # Filling missing data, normalize features\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    data_scaled = min_max_scaler.fit_transform(ffilled_features)\n",
        "    processed_data = np.nan_to_num(data_scaled, nan=-1)\n",
        "\n",
        "    # Add back lables\n",
        "    feature_names = list(ffilled_features.columns)\n",
        "    X3 = pd.DataFrame(processed_data, columns=feature_names)\n",
        "\n",
        "    model_data = pd.concat([data[['SPELL_IDENTIFIER', 'date', 'ROUTE', 'po_flag', 'iv_treatment_length', '24_hour_flag', '48_hour_flag']], X3], axis=1)\n",
        "\n",
        "    return model_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1711549568639
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def set_transformer_processing_fun(patient_df, snomed_embedding):\n",
        "    # Str\n",
        "    patient_df.columns = patient_df.columns.astype(str)\n",
        "    snomed_embedding['snomed_code'] = snomed_embedding['snomed_code'].astype(str)\n",
        "    # Filter\n",
        "    snomed_embedding = snomed_embedding[snomed_embedding['snomed_code'].isin(patient_df.columns.tolist())]\n",
        "    snomed_embedding.set_index('snomed_code', inplace=True)\n",
        "    # Get lengths of each patients co-morbidities\n",
        "    comorbidity_len = np.array(patient_df.sum(axis=1))\n",
        "    # Add padding embedding \n",
        "    padding_df = pd.DataFrame(np.random.choice([0], size=len(snomed_embedding.columns)))\n",
        "    padding_df = padding_df.T\n",
        "    padding_df.index = ['9999999999']\n",
        "    padding_df.columns = snomed_embedding.columns\n",
        "    snomed_embedding2 = pd.concat([snomed_embedding, padding_df])\n",
        "    snomed_embedding2.index = snomed_embedding2.index.astype(str)\n",
        "    # Get max number of co-morbidities\n",
        "    max_len = 22 # Define for same for all splits (train val etr)\n",
        "    # Format patients embeddings into set and pad / create array\n",
        "    feature_array = np.zeros(shape=(len(patient_df), max_len , 128))\n",
        "    n = -1\n",
        "    for index, row in patient_df.iterrows():\n",
        "        n += 1\n",
        "        n2 = -1\n",
        "        code_list = row[row ==1].index.tolist()\n",
        "        while len(code_list) < max_len:\n",
        "            code_list.append('9999999999')\n",
        "        for code in code_list:\n",
        "            n2 += 1\n",
        "            feature_array[n, n2] = np.array(snomed_embedding2.loc[code])\n",
        "    \n",
        "    # Create mask tensor based on lengths\n",
        "    comorbidity_len2 = torch.as_tensor(comorbidity_len, dtype=torch.long)\n",
        "    mask = torch.arange(max_len)[None, :] < comorbidity_len2[:, None]\n",
        "\n",
        "    return feature_array, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1711549569063
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "class SetTransformer(nn.Module):\n",
        "    def __init__(self, dim_input, num_outputs, dim_output,\n",
        "            num_inds=36, dim_hidden=160, num_heads=4, ln=False):\n",
        "        super(SetTransformer, self).__init__()\n",
        "        self.enc = nn.Sequential(\n",
        "                ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),\n",
        "                ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln))\n",
        "        self.isab = ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln)\n",
        "        self.pma = PMA(dim_hidden, num_heads, num_outputs, ln=ln)\n",
        "        self.dec = nn.Sequential(\n",
        "                #SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
        "                #SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
        "                nn.Linear(dim_hidden, dim_output))\n",
        "\n",
        "    def forward(self, X, batch_mask):\n",
        "        x = self.isab(X, batch_mask)\n",
        "        x = self.pma(x, batch_mask)\n",
        "        return self.dec(x)#, x\n",
        "\n",
        "class MAB0(nn.Module):\n",
        "    def __init__(self, dim_Q, dim_K, dim_V, num_heads, ln=False):\n",
        "        super(MAB0, self).__init__()\n",
        "        self.dim_V = dim_V\n",
        "        self.num_heads = num_heads\n",
        "        self.fc_q = nn.Linear(dim_Q, dim_V)\n",
        "        self.fc_k = nn.Linear(dim_K, dim_V)\n",
        "        self.fc_v = nn.Linear(dim_K, dim_V)\n",
        "        if ln:\n",
        "            self.ln0 = nn.LayerNorm(dim_V)\n",
        "            self.ln1 = nn.LayerNorm(dim_V)\n",
        "        self.fc_o = nn.Linear(dim_V, dim_V)\n",
        "\n",
        "    def forward(self, Q, K, mask):\n",
        "        Q = self.fc_q(Q)\n",
        "        K, V = self.fc_k(K), self.fc_v(K)\n",
        "\n",
        "        dim_split = self.dim_V // self.num_heads\n",
        "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
        "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
        "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
        "\n",
        "        # Create new variable for softmax\n",
        "        WB_ = Q_.bmm(K_.transpose(1,2))/math.sqrt(self.dim_V)\n",
        "        # Exspand mask dimensions to align\n",
        "        mask = mask.unsqueeze(1).repeat(self.num_heads, Q.shape[1], 1)\n",
        "        # Mask for softmax\n",
        "        WB_[~mask] = float('-inf')\n",
        "\n",
        "        A = torch.softmax(WB_, 2)\n",
        "        O = torch.cat((Q_ + A.bmm(V_)).split(Q.size(0), 0), 2)\n",
        "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
        "        O = O + F.relu(self.fc_o(O))\n",
        "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
        "        return O\n",
        "\n",
        "class MAB(nn.Module):\n",
        "    def __init__(self, dim_Q, dim_K, dim_V, num_heads, ln=False):\n",
        "        super(MAB, self).__init__()\n",
        "        self.dim_V = dim_V\n",
        "        self.num_heads = num_heads\n",
        "        self.fc_q = nn.Linear(dim_Q, dim_V)\n",
        "        self.fc_k = nn.Linear(dim_K, dim_V)\n",
        "        self.fc_v = nn.Linear(dim_K, dim_V)\n",
        "        if ln:\n",
        "            self.ln0 = nn.LayerNorm(dim_V)\n",
        "            self.ln1 = nn.LayerNorm(dim_V)\n",
        "        self.fc_o = nn.Linear(dim_V, dim_V)\n",
        "\n",
        "    def forward(self, Q, K):\n",
        "        Q = self.fc_q(Q)\n",
        "        K, V = self.fc_k(K), self.fc_v(K)\n",
        "\n",
        "        dim_split = self.dim_V // self.num_heads\n",
        "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
        "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
        "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
        "\n",
        "        A = torch.softmax(Q_.bmm(K_.transpose(1,2))/math.sqrt(self.dim_V), 2)\n",
        "        O = torch.cat((Q_ + A.bmm(V_)).split(Q.size(0), 0), 2)\n",
        "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
        "        O = O + F.relu(self.fc_o(O))\n",
        "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
        "        return O\n",
        "\n",
        "class SAB(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out, num_heads, ln=False):\n",
        "        super(SAB, self).__init__()\n",
        "        self.mab = MAB(dim_in, dim_in, dim_out, num_heads, ln=ln)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.mab(X, X)\n",
        "\n",
        "class ISAB(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out, num_heads, num_inds, ln=False):\n",
        "        super(ISAB, self).__init__()\n",
        "        self.I = nn.Parameter(torch.Tensor(1, num_inds, dim_out))\n",
        "        nn.init.xavier_uniform_(self.I)\n",
        "        self.mab0 = MAB0(dim_out, dim_in, dim_out, num_heads, ln=ln)\n",
        "        self.mab1 = MAB(dim_in, dim_out, dim_out, num_heads, ln=ln)\n",
        "\n",
        "    def forward(self, X, mask):\n",
        "        H = self.mab0(self.I.repeat(X.size(0), 1, 1), X, mask)\n",
        "        return self.mab1(X, H)\n",
        "\n",
        "class PMA(nn.Module):\n",
        "    def __init__(self, dim, num_heads, num_seeds, ln=False):\n",
        "        super(PMA, self).__init__()\n",
        "        self.S = nn.Parameter(torch.Tensor(1, num_seeds, dim))\n",
        "        nn.init.xavier_uniform_(self.S)\n",
        "        self.mab = MAB0(dim, dim, dim, num_heads, ln=ln)\n",
        "\n",
        "    def forward(self, X, mask):\n",
        "        return self.mab(self.S.repeat(X.size(0), 1, 1), X, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1711549569487
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "class Initial_vitals_model(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.BatchNorm1d(input_dim),\n",
        "            nn.Linear(input_dim, hid_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hid_dim, output_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x1 = self.layers(x)\n",
        "\n",
        "        return x1\n",
        "\n",
        "\n",
        "class Chronic_switch_model(nn.Module):\n",
        "    def __init__(self, \n",
        "    final_input_dim, \n",
        "    final_output_dim, \n",
        "    final_hid_dim, \n",
        "    final_hid_dim2,\n",
        "    demographics_input_dim,\n",
        "    demographics_output_dim,\n",
        "    vital_input_dim, \n",
        "    vital_hid_dim, \n",
        "    vital_output_dim, \n",
        "    dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.final_layers = nn.Sequential(\n",
        "            nn.Linear(final_input_dim, final_hid_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(final_hid_dim, final_hid_dim2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(final_hid_dim2, final_output_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout))\n",
        "\n",
        "        self.vital_model = Initial_vitals_model(vital_input_dim, vital_output_dim, vital_hid_dim, dropout)\n",
        "\n",
        "        self.set_transformer = SetTransformer(dim_input=128, num_outputs=1, dim_output=128, num_inds=32, dim_hidden=160, num_heads=4, ln=False)\n",
        "\n",
        "        # Embedding for demographics (passing feature directly)\n",
        "        self.demographics = nn.Linear(demographics_input_dim, demographics_output_dim)\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor, batch_mask: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        # Directly pass demographics feature to embedding\n",
        "        demographics = self.demographics(inputs[1])\n",
        "\n",
        "        # Pass other inputs through initial models\n",
        "        vital_embeddings = self.vital_model(inputs[0])\n",
        "        comorbidity_embeddings = self.set_transformer(inputs[2], batch_mask)\n",
        "        comorbidity_embeddings = torch.squeeze(comorbidity_embeddings)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        concatenated_embeddings = torch.cat([demographics, vital_embeddings, comorbidity_embeddings], dim=1)\n",
        "\n",
        "        # Pass through final layers\n",
        "        output = self.final_layers(concatenated_embeddings)\n",
        "\n",
        "        return output\n",
        "    \n",
        "    def latent_representation(self, inputs: torch.Tensor, batch_mask: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        # Directly pass demographics feature to embedding\n",
        "        demographics = self.demographics(inputs[1])\n",
        "\n",
        "        # Pass other inputs through initial models\n",
        "        vital_embeddings = self.vital_model(inputs[0])\n",
        "        comorbidity_embeddings = self.set_transformer(inputs[2], batch_mask)\n",
        "        comorbidity_embeddings = torch.squeeze(comorbidity_embeddings)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        concatenated_embeddings = torch.cat([demographics, vital_embeddings, comorbidity_embeddings], dim=1)\n",
        "        \n",
        "        return concatenated_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1711549569892
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "class MultiInputDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dfs_list, labels, comorbidites, padding_mask):\n",
        "        self.dfs_list = dfs_list\n",
        "        self.labels = labels\n",
        "        self.padding_mask = padding_mask\n",
        "        self.comorbidites = comorbidites\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = [torch.tensor(df.iloc[idx].values) for df in self.dfs_list]\n",
        "        labels = torch.tensor(self.labels[['po_flag']].iloc[idx].to_numpy())\n",
        "        features.append(self.comorbidites[idx])\n",
        "        sample = {\"labels\": labels, \"features\": features, \"mask\":self.padding_mask[idx]}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1711549570292
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    batch_prediction_list = []\n",
        "    batch_label_list = []\n",
        "\n",
        "    # use the with torch.no_grad() block to ensure no gradients are calculated within the bloc\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, sample in enumerate(tqdm(dataloader)):\n",
        "            labels = sample[\"labels\"]\n",
        "            features = sample[\"features\"]\n",
        "            batch_mask = sample[\"mask\"]\n",
        "            features = [data.float() for data in features]\n",
        "            features = [data.to(device=device) for data in features]\n",
        "            labels = labels.float()\n",
        "            labels = labels.to(device=device)\n",
        "            batch_mask = batch_mask.to(device)\n",
        "\n",
        "            # Run model\n",
        "            output = model(features, batch_mask)\n",
        "\n",
        "            # Generate loss\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Get predictions for performance calc - masking outputs and labels\n",
        "            sig = torch.nn.Sigmoid()\n",
        "            output = sig(output)  \n",
        "            np_predictions = output.cpu().detach().numpy()\n",
        "            np_labels = labels.cpu().detach().numpy()\n",
        "\n",
        "            np_predictions = np_predictions.squeeze()\n",
        "            np_labels = np_labels.squeeze()\n",
        "\n",
        "            np_predictions = np_predictions.flatten()\n",
        "            np_labels = np_labels.flatten()\n",
        "            \n",
        "            # Create list\n",
        "            for x in np_predictions:\n",
        "                batch_prediction_list.append(x)\n",
        "            for x in np_labels:\n",
        "                batch_label_list.append(x)\n",
        "\n",
        "        final_predictions = np.array(batch_prediction_list)\n",
        "\n",
        "        final_labels = np.array(batch_label_list)\n",
        "\n",
        "        try:\n",
        "            auroc = roc_auc_score(final_labels, final_predictions)\n",
        "        except:\n",
        "            auroc = np.nan\n",
        "        \n",
        "        try:\n",
        "            final_loss = epoch_loss / len(dataloader)\n",
        "        except:\n",
        "            final_loss = np.nan\n",
        "\n",
        "        return final_loss, auroc, final_predictions, final_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1711549570689
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Function to obtain embeddings\n",
        "def embedding_fun(data, model, comorbidity_embeddings):\n",
        "    # Split up dfs\n",
        "    vitals_data = data.iloc[:,2:255]\n",
        "    demographics_data = data.iloc[:,255:267]\n",
        "    comorbidity_data = data.iloc[:, 267:]\n",
        "\n",
        "    # Get labels\n",
        "    labels = data[['po_flag']]\n",
        "\n",
        "    # Preprocess comorbidity data\n",
        "    print('Working on set_transformer_processing_fun...')\n",
        "    comorbidity_data, comorbidity_mask = set_transformer_processing_fun(comorbidity_data, comorbidity_embeddings)\n",
        "    print('Done!')\n",
        "\n",
        "    #Define batch size\n",
        "    batch_size = 512 #len(vitals_data) # crashes\n",
        "\n",
        "    # Define dataloaders\n",
        "    train_dataset =  MultiInputDataset([vitals_data, demographics_data], labels, comorbidity_data, comorbidity_mask)\n",
        "    dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch_idx, sample in enumerate(tqdm(dataloader)):\n",
        "        labels = sample[\"labels\"]\n",
        "        features = sample[\"features\"]\n",
        "        batch_mask = sample[\"mask\"]\n",
        "        features = [data.float() for data in features]\n",
        "        features = [data.to(device=device) for data in features]\n",
        "        labels = labels.float()\n",
        "        labels = labels.to(device=device)\n",
        "        batch_mask = batch_mask.to(device)\n",
        "        \n",
        "        embeddings = model.latent_representation(features, batch_mask)\n",
        "\n",
        "        np_embeddings = embeddings.cpu().detach().numpy()\n",
        "\n",
        "        if batch_idx == 0:\n",
        "            working_embeddings = np_embeddings.copy()\n",
        "        else:\n",
        "            working_embeddings = np.concatenate((working_embeddings, np_embeddings), axis=0)\n",
        "\n",
        "    return working_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1711549571088
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Calculate the number of trainable parameters in the model.\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1711549571590
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 1,126,583 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "final_input_dim = 268\n",
        "final_output_dim = 1\n",
        "final_hid_dim = 512\n",
        "final_hid_dim2 = 128\n",
        "demographics_input_dim = 12\n",
        "demographics_output_dim = 12\n",
        "vital_input_dim = 253\n",
        "vital_hid_dim = 512\n",
        "vital_output_dim = 128\n",
        "dropout = 0.1\n",
        "\n",
        "# Define model\n",
        "model = Chronic_switch_model(\n",
        "    final_input_dim, \n",
        "    final_output_dim, \n",
        "    final_hid_dim, \n",
        "    final_hid_dim2,\n",
        "    demographics_input_dim,\n",
        "    demographics_output_dim,\n",
        "    vital_input_dim, \n",
        "    vital_hid_dim, \n",
        "    vital_output_dim, \n",
        "    dropout).to(device)\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(f'chronic_switch_model2.pt'))\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1711549572039
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def adjust_dataframe(df, adjustment_factor=0.05):\n",
        "    \"\"\"\n",
        "    Adjusts values in a pandas DataFrame randomly based on the type of data in each column.\n",
        "\n",
        "    Parameters:\n",
        "    - df: pandas DataFrame\n",
        "    - adjustment_factor: float, optional, default: 0.1\n",
        "        The factor by which the values are adjusted.\n",
        "\n",
        "    Returns:\n",
        "    - Adjusted pandas DataFrame.\n",
        "    \"\"\"\n",
        "    adjusted_df = df.copy()\n",
        "\n",
        "    for col in df.iloc[:,2:255].columns: # Just vary vitals\n",
        "        if np.issubdtype(df[col].dtype, np.number):  # Check if column contains numeric data\n",
        "            if df[col].nunique() > 3:  # For continuous columns\n",
        "                mask = (df[col] >= 0) & (df[col] <= 1)  # Select values between 0 and 1\n",
        "                adjustment = np.random.uniform(1 - adjustment_factor, 1 + adjustment_factor, size=len(adjusted_df.loc[mask, col]))\n",
        "                adjusted_df.loc[mask, col] *= adjustment  \n",
        "    return adjusted_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1711549572423
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def new_threshold_fun(predictions, bound=0.7373848): # Set threshold\n",
        "    new_predictions = [1 if a_ >= bound else 0 for a_ in predictions]\n",
        "    return new_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Get all embeddings "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1711549578734
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/chronic_switch_icare_df_preprocessed.csv'\n",
        "icare_df_preprocessed = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_episodes.csv'\n",
        "episodes = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_disease.csv'\n",
        "disease = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_demographics.csv'\n",
        "demographics = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/snomed_embedding_128d-copy.csv'\n",
        "snomed_embedding = pd.read_csv(path)\n",
        "\n",
        "# Import\n",
        "path = r'switch_data/chronic_switch_problem_dummies.csv'\n",
        "problem_dummies = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "gather": {
          "logged": 1711446695757
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/chronic_switch_problem_dummies.csv'\n",
        "problem_dummies = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1711549726554
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting...\n",
            "Done\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Merge\n",
        "problem_dummies2 = pd.merge(problem_dummies, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "problem_dummies2 = pd.merge(icare_df_preprocessed[['SPELL_IDENTIFIER', 'date']], problem_dummies2)\n",
        "\n",
        "# Strip name \n",
        "problem_dummies2.columns = problem_dummies2.columns.str.removeprefix('PROBLEM_')\n",
        "\n",
        "# Convert the date columns to datetime objects if they are not already\n",
        "problem_dummies2['date'] = pd.to_datetime(problem_dummies2['date'])\n",
        "problem_dummies2['DT_TM'] = pd.to_datetime(problem_dummies2['DT_TM'])\n",
        "\n",
        "# Calculate the absolute time difference between 'date' and 'DT_TM'\n",
        "problem_dummies2['time_diff'] = (problem_dummies2['date'] - problem_dummies2['DT_TM']).abs()\n",
        "\n",
        "# Filter rows where 'time_diff' is not negative\n",
        "problem_dummies2 = problem_dummies2[problem_dummies2['time_diff'] >= pd.Timedelta(0)]\n",
        "\n",
        "# Sort the DataFrame by 'SPELL_IDENTIFIER' and 'time_diff'\n",
        "problem_dummies2.sort_values(by=['SPELL_IDENTIFIER', 'time_diff'], inplace=True)\n",
        "\n",
        "# Convert to str\n",
        "problem_dummies2['date'] = problem_dummies2['date'].astype(str)\n",
        "\n",
        "# Keep only the rows with the smallest time difference for each 'SPELL_IDENTIFIER'\n",
        "problem_dummies2 = problem_dummies2.groupby(['SPELL_IDENTIFIER', 'date']).first().reset_index()\n",
        "\n",
        "### REASON the problem_dummies2 is shorter is not because it is missing some dates! \n",
        "### It is because in the final data we have some dates repeated for a spesfic spell \n",
        "### if they were admited in between 6am and 12pm the 12hour prediction is done at 6am \n",
        "### of the first day, then 48 done at 6am the next day, then the next prediction done \n",
        "### at 12pm that day causing there to be two prediction for that day...phew\n",
        "### So just get a set of co-morbidities for each spell and merge \n",
        "\n",
        "# Drop the 'time_diff' column as it's no longer needed\n",
        "problem_dummies2.drop(columns=['time_diff', 'SUBJECT', 'DT_TM', 'new_subject', 'date'], inplace=True)\n",
        "\n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(inplace=True)\n",
        "\n",
        "# Some still got through by having their co-morbidid diagnosis updated during their stay \n",
        "# In this case we just use the frst one throughout and remove the others \n",
        "# Drop duplicates\n",
        "problem_dummies2.drop_duplicates(subset=['SPELL_IDENTIFIER'], keep='first', inplace=True)\n",
        "\n",
        "# Filter for features\n",
        "X_data = icare_df_preprocessed.drop(columns=['SPELL_IDENTIFIER', 'po_flag'])\n",
        "X_data = X_data.drop(columns=columns_to_drop)\n",
        "model_data = pd.concat([icare_df_preprocessed[['SPELL_IDENTIFIER', 'po_flag']], X_data], axis=1)\n",
        "# Merge\n",
        "demographics = pd.merge(demographics, episodes[['SUBJECT', 'SPELL_IDENTIFIER']])\n",
        "demographics.drop(columns=['SUBJECT'], inplace=True)\n",
        "model_data = pd.merge(model_data, demographics, how='left')\n",
        "model_data = pd.merge(model_data, disease, how='left')\n",
        "# Drop \n",
        "model_data = model_data.drop(columns=['date', 'ROUTE', '24_hour_flag', '48_hour_flag', 'iv_treatment_length'])\n",
        "# fillna\n",
        "model_data['AGE'] = model_data['AGE'].fillna(-1)\n",
        "model_data['IMDDECIL'] = model_data['IMDDECIL'].fillna(-1)\n",
        "model_data = model_data.fillna(0)\n",
        "# Merge co-morbidites\n",
        "model_data = pd.merge(model_data, problem_dummies2, how='left')\n",
        "# Rename\n",
        "model_data.rename(columns={'SPELL_IDENTIFIER': 'stay_id'}, inplace=True)\n",
        "# Random shuffle\n",
        "stays = model_data['stay_id'].unique()\n",
        "random.Random(5).shuffle(stays)\n",
        "model_data = model_data.set_index(\"stay_id\").loc[stays].reset_index()\n",
        "\n",
        "# Slightly change values so not real patient data\n",
        "print('Adjusting...')\n",
        "model_data = adjust_dataframe(model_data)\n",
        "print('Done')\n",
        "\n",
        "del icare_df_preprocessed\n",
        "del episodes\n",
        "del disease\n",
        "del demographics\n",
        "del problem_dummies\n",
        "del problem_dummies2\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1711549833070
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on set_transformer_processing_fun...\n",
            "Done!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 62/62 [00:47<00:00,  1.31it/s]\n"
          ]
        }
      ],
      "source": [
        "# Obtain embeddings\n",
        "main_embeddings = embedding_fun(model_data, model, snomed_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1711549834337
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "path = r'switch_data/antibiotic_vitals_2023.csv'\n",
        "antibiotic_vitals_2023 = pd.read_csv(path)\n",
        "# Import\n",
        "path = r'switch_data/antibiotic_vitals.csv'\n",
        "antibiotic_vitals_pivoted_4 = pd.read_csv(path)\n",
        "\n",
        "joint_antibiotic_vitals = pd.concat([antibiotic_vitals_pivoted_4, antibiotic_vitals_2023])\n",
        "# Needs to be type int for c22 to work\n",
        "joint_antibiotic_vitals['hours_grouped'] = joint_antibiotic_vitals['hours_grouped'].astype(int)\n",
        "\n",
        "# Remove outliers\n",
        "times = 6\n",
        "joint_antibiotic_vitals['Diastolic Blood Pressure'], outlier_count = remove_data_outliers_series(joint_antibiotic_vitals['Diastolic Blood Pressure'], coeff=times)\n",
        "joint_antibiotic_vitals['Heart Rate'], outlier_count = remove_data_outliers_series(joint_antibiotic_vitals['Heart Rate'], coeff=times)\n",
        "joint_antibiotic_vitals['Mean Arterial Pressure'], outlier_count = remove_data_outliers_series(joint_antibiotic_vitals['Mean Arterial Pressure'], coeff=times)\n",
        "joint_antibiotic_vitals['Respiratory Rate'], outlier_count = remove_data_outliers_series(joint_antibiotic_vitals['Respiratory Rate'], coeff=times)\n",
        "joint_antibiotic_vitals['SpO2'], outlier_count = remove_data_outliers_series(joint_antibiotic_vitals['SpO2'], coeff=times)\n",
        "joint_antibiotic_vitals['Systolic Blood Pressure'], outlier_count = remove_data_outliers_series(joint_antibiotic_vitals['Systolic Blood Pressure'], coeff=times)\n",
        "joint_antibiotic_vitals['Temperature'], outlier_count = remove_data_outliers_series(joint_antibiotic_vitals['Temperature'], coeff=times)\n",
        "\n",
        "# Clip SpO2\n",
        "joint_antibiotic_vitals['SpO2'] = joint_antibiotic_vitals['SpO2'].clip(upper=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1711550235480
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "column number: 0\n",
            "column number: 1\n",
            "column number: 2\n",
            "column number: 3\n",
            "column number: 4\n",
            "column number: 5\n",
            "column number: 6\n",
            "column number: 7\n",
            "column number: 8\n",
            "column number: 9\n",
            "column number: 0\n",
            "column number: 1\n",
            "column number: 2\n",
            "column number: 3\n",
            "column number: 4\n",
            "column number: 5\n",
            "column number: 6\n",
            "column number: 7\n",
            "column number: 8\n",
            "column number: 9\n",
            "column number: 0\n",
            "column number: 1\n",
            "column number: 2\n",
            "column number: 3\n",
            "column number: 4\n",
            "column number: 5\n",
            "column number: 6\n",
            "column number: 7\n",
            "column number: 8\n",
            "column number: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:473: RuntimeWarning: All-NaN slice encountered\n",
            "  data_min = np.nanmin(X, axis=0)\n",
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:474: RuntimeWarning: All-NaN slice encountered\n",
            "  data_max = np.nanmax(X, axis=0)\n"
          ]
        }
      ],
      "source": [
        "# Specify the percentiles for each column (e.g., top 50%, bottom 25%, etc.)\n",
        "percentiles = {\n",
        "'Diastolic Blood Pressure': (0, 30),\n",
        "'Glasgow Coma Score': (90, 100),\n",
        "'Heart Rate': (90, 100),\n",
        "'Mean Arterial Pressure': (20, 40),\n",
        "'NEWS Conscious Level Score': (0, 10),\n",
        "'NEWS Supplemental Oxygen Calc': (0, 10),\n",
        "'Respiratory Rate': (90, 100),\n",
        "'SpO2': (10, 30),\n",
        "'Systolic Blood Pressure': (0, 30),\n",
        "'Temperature': (30, 60),\n",
        "}\n",
        "\n",
        "# Specify the rate of change for each column (e.g., 0.1 for a 10% increase per time step)\n",
        "trend = {\n",
        "'Diastolic Blood Pressure': 0,\n",
        "'Glasgow Coma Score': 0,\n",
        "'Heart Rate': -1.5,\n",
        "'Mean Arterial Pressure': 0,\n",
        "'NEWS Conscious Level Score': 0,\n",
        "'NEWS Supplemental Oxygen Calc': 0,\n",
        "'Respiratory Rate': -0.15,\n",
        "'SpO2': 0.5,\n",
        "'Systolic Blood Pressure': 0,\n",
        "'Temperature': 0,#-0.05,\n",
        "}\n",
        "\n",
        "new_df_length=22\n",
        "\n",
        "# Generate synthetic data using the specified percentiles and trend\n",
        "synthetic_data = generate_synthetic_data(joint_antibiotic_vitals.iloc[:,3:], percentiles, trend, seed=0, new_df_length=new_df_length)\n",
        "\n",
        "# Set Mean Arterial Pressure to mean of Diastolic Blood Pressure and Systolic Blood Pressure\n",
        "synthetic_data['Mean Arterial Pressure'] = synthetic_data[['Diastolic Blood Pressure', 'Systolic Blood Pressure']].mean(axis=1)\n",
        "\n",
        "# Round scores\n",
        "synthetic_data['Glasgow Coma Score'] = synthetic_data['Glasgow Coma Score'].round()\n",
        "synthetic_data['NEWS Conscious Level Score'] = synthetic_data['NEWS Conscious Level Score'].round()\n",
        "synthetic_data['NEWS Supplemental Oxygen Calc'] = synthetic_data['NEWS Supplemental Oxygen Calc'].round()\n",
        "\n",
        "# Add other columns \n",
        "synthetic_data['SPELL_IDENTIFIER'] = '001'\n",
        "start_value = 1\n",
        "synthetic_data['date'] = (pd.to_datetime('2023-12-31') + pd.to_timedelta(synthetic_data.index + start_value, unit='day'))\n",
        "sequence = [1, 2, 3, 4]\n",
        "sequence_column = sequence * (len(synthetic_data) // len(sequence)) + sequence[:len(synthetic_data) % len(sequence)]\n",
        "synthetic_data['hours_grouped'] = sequence_column\n",
        "\n",
        "# Reorder the columns\n",
        "columns = synthetic_data.columns.tolist()\n",
        "new_order = columns[-3:] + columns[:-3]\n",
        "synthetic_data = synthetic_data[new_order]\n",
        "\n",
        "### 24 hours ###\n",
        "c22_24 = synthetic_data.groupby('SPELL_IDENTIFIER').head(4)\n",
        "c22_24.set_index(['SPELL_IDENTIFIER', 'date', 'hours_grouped'] ,inplace=True, drop=True)\n",
        "# Run\n",
        "c22_24_hour_df = c22_24_fun(c22_24)\n",
        "\n",
        "### 48 hours ###\n",
        "c22_48 = synthetic_data.groupby('SPELL_IDENTIFIER').head(8)\n",
        "# Remove those without enough data\n",
        "c22_48 = c22_48[c22_48['SPELL_IDENTIFIER'].isin((c22_48.groupby('SPELL_IDENTIFIER').size() > 7).where(lambda x : x == True).dropna().reset_index()['SPELL_IDENTIFIER'].to_list())]\n",
        "# Set index\n",
        "c22_48.set_index(['SPELL_IDENTIFIER', 'date', 'hours_grouped'] ,inplace=True, drop=True)\n",
        "# Run\n",
        "c22_48_hour_df = c22_48_fun(c22_48)\n",
        "\n",
        "### Other ###\n",
        "# Remove those without enough data\n",
        "c22_other = synthetic_data[synthetic_data['SPELL_IDENTIFIER'].isin((synthetic_data.groupby('SPELL_IDENTIFIER').size() > 8).where(lambda x : x == True).dropna().reset_index()['SPELL_IDENTIFIER'].to_list())]\n",
        "# Set index\n",
        "c22_other.set_index(['SPELL_IDENTIFIER', 'date', 'hours_grouped'] ,inplace=True, drop=True)\n",
        "# Run\n",
        "c22_other_days_df = c22_other_fun(c22_other)\n",
        "\n",
        "# Combine\n",
        "c22_combined = pd.concat([c22_24_hour_df, c22_48_hour_df, c22_other_days_df])\n",
        "# Move column\n",
        "col = c22_combined.pop(\"48_hour_flag\")\n",
        "c22_combined.insert(3, col.name, col)\n",
        "# Reset index\n",
        "c22_combined2 = c22_combined.reset_index(drop=True)\n",
        "\n",
        "# Difference\n",
        "c22_combined3 = c22_combined2.drop(columns=['date', '24_hour_flag', '48_hour_flag'])\n",
        "\n",
        "c22_combined_diff = pd.DataFrame()\n",
        "c22_combined3.set_index('SPELL_IDENTIFIER', inplace=True)\n",
        "for stay_id, new_df in c22_combined3.groupby(level=0):\n",
        "    diff_df = new_df.diff()\n",
        "    diff_df = diff_df.add_suffix('_difference')\n",
        "    c22_combined_diff = pd.concat([c22_combined_diff, diff_df], ignore_index=True)\n",
        "\n",
        "c22_combined3.reset_index(inplace=True)\n",
        "c22_combined_diff = pd.concat([c22_combined3, c22_combined_diff], axis=1)\n",
        "c22_combined_diff = pd.concat([c22_combined2[['date', '24_hour_flag', '48_hour_flag']], c22_combined_diff], axis=1)\n",
        "col = c22_combined_diff.pop(\"SPELL_IDENTIFIER\")\n",
        "c22_combined_diff.insert(0, col.name, col)\n",
        "\n",
        "### Normalise ###\n",
        "# Import\n",
        "path = r'switch_data/icare_switch_data.csv'\n",
        "icare_df = pd.read_csv(path)\n",
        "# Combine\n",
        "icare_df_preprocessed = pd.concat([c22_combined_diff, icare_df])\n",
        "icare_df_preprocessed.reset_index(inplace=True, drop=True)\n",
        "del icare_df\n",
        "# Preprocess\n",
        "icare_df_preprocessed = preprocess_fun(icare_df_preprocessed)\n",
        "# Select synthetic rows\n",
        "icare_df_preprocessed = icare_df_preprocessed[icare_df_preprocessed['SPELL_IDENTIFIER'] == '001']\n",
        "\n",
        "\n",
        "# Drop columns \n",
        "final_synthetic_data = icare_df_preprocessed.drop(columns=columns_to_drop)\n",
        "final_synthetic_data = final_synthetic_data.drop(columns=['date', '24_hour_flag', '48_hour_flag', 'iv_treatment_length', 'ROUTE'])\n",
        "# Rename\n",
        "final_synthetic_data.rename(columns={'SPELL_IDENTIFIER': 'stay_id'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "gather": {
          "logged": 1711448102763
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SPELL_IDENTIFIER</th>\n",
              "      <th>date</th>\n",
              "      <th>hours_grouped</th>\n",
              "      <th>Diastolic Blood Pressure</th>\n",
              "      <th>Glasgow Coma Score</th>\n",
              "      <th>Heart Rate</th>\n",
              "      <th>Mean Arterial Pressure</th>\n",
              "      <th>NEWS Conscious Level Score</th>\n",
              "      <th>NEWS Supplemental Oxygen Calc</th>\n",
              "      <th>Respiratory Rate</th>\n",
              "      <th>SpO2</th>\n",
              "      <th>Systolic Blood Pressure</th>\n",
              "      <th>Temperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>70.59</td>\n",
              "      <td>15.0</td>\n",
              "      <td>104.74</td>\n",
              "      <td>85.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.10</td>\n",
              "      <td>94.72</td>\n",
              "      <td>99.61</td>\n",
              "      <td>36.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-02</td>\n",
              "      <td>2</td>\n",
              "      <td>63.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>103.87</td>\n",
              "      <td>81.79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.81</td>\n",
              "      <td>94.92</td>\n",
              "      <td>100.39</td>\n",
              "      <td>36.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-03</td>\n",
              "      <td>3</td>\n",
              "      <td>66.33</td>\n",
              "      <td>15.0</td>\n",
              "      <td>95.25</td>\n",
              "      <td>84.16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.85</td>\n",
              "      <td>96.38</td>\n",
              "      <td>101.99</td>\n",
              "      <td>36.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-04</td>\n",
              "      <td>4</td>\n",
              "      <td>73.17</td>\n",
              "      <td>15.0</td>\n",
              "      <td>111.49</td>\n",
              "      <td>89.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.29</td>\n",
              "      <td>95.69</td>\n",
              "      <td>105.23</td>\n",
              "      <td>36.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-05</td>\n",
              "      <td>1</td>\n",
              "      <td>71.15</td>\n",
              "      <td>15.0</td>\n",
              "      <td>89.10</td>\n",
              "      <td>86.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.02</td>\n",
              "      <td>96.15</td>\n",
              "      <td>102.69</td>\n",
              "      <td>36.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-06</td>\n",
              "      <td>2</td>\n",
              "      <td>55.71</td>\n",
              "      <td>15.0</td>\n",
              "      <td>99.84</td>\n",
              "      <td>75.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.92</td>\n",
              "      <td>97.04</td>\n",
              "      <td>95.70</td>\n",
              "      <td>36.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-07</td>\n",
              "      <td>3</td>\n",
              "      <td>66.17</td>\n",
              "      <td>15.0</td>\n",
              "      <td>92.37</td>\n",
              "      <td>83.44</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.50</td>\n",
              "      <td>97.50</td>\n",
              "      <td>100.70</td>\n",
              "      <td>36.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-08</td>\n",
              "      <td>4</td>\n",
              "      <td>60.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>102.07</td>\n",
              "      <td>75.04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.54</td>\n",
              "      <td>99.31</td>\n",
              "      <td>89.89</td>\n",
              "      <td>36.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-09</td>\n",
              "      <td>1</td>\n",
              "      <td>60.46</td>\n",
              "      <td>15.0</td>\n",
              "      <td>92.73</td>\n",
              "      <td>84.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.91</td>\n",
              "      <td>99.29</td>\n",
              "      <td>109.39</td>\n",
              "      <td>36.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-10</td>\n",
              "      <td>2</td>\n",
              "      <td>63.24</td>\n",
              "      <td>15.0</td>\n",
              "      <td>85.38</td>\n",
              "      <td>78.69</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.10</td>\n",
              "      <td>99.32</td>\n",
              "      <td>94.14</td>\n",
              "      <td>36.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-11</td>\n",
              "      <td>3</td>\n",
              "      <td>61.80</td>\n",
              "      <td>15.0</td>\n",
              "      <td>93.95</td>\n",
              "      <td>79.67</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.62</td>\n",
              "      <td>99.11</td>\n",
              "      <td>97.55</td>\n",
              "      <td>36.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-12</td>\n",
              "      <td>4</td>\n",
              "      <td>68.91</td>\n",
              "      <td>15.0</td>\n",
              "      <td>96.44</td>\n",
              "      <td>87.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.04</td>\n",
              "      <td>100.00</td>\n",
              "      <td>105.47</td>\n",
              "      <td>36.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-13</td>\n",
              "      <td>1</td>\n",
              "      <td>65.14</td>\n",
              "      <td>15.0</td>\n",
              "      <td>91.78</td>\n",
              "      <td>82.60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.01</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.05</td>\n",
              "      <td>36.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-14</td>\n",
              "      <td>2</td>\n",
              "      <td>61.68</td>\n",
              "      <td>15.0</td>\n",
              "      <td>92.34</td>\n",
              "      <td>88.67</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.12</td>\n",
              "      <td>100.00</td>\n",
              "      <td>115.67</td>\n",
              "      <td>36.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>3</td>\n",
              "      <td>63.42</td>\n",
              "      <td>15.0</td>\n",
              "      <td>82.65</td>\n",
              "      <td>79.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.71</td>\n",
              "      <td>100.00</td>\n",
              "      <td>96.26</td>\n",
              "      <td>36.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-16</td>\n",
              "      <td>4</td>\n",
              "      <td>62.83</td>\n",
              "      <td>15.0</td>\n",
              "      <td>83.53</td>\n",
              "      <td>84.88</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.02</td>\n",
              "      <td>100.00</td>\n",
              "      <td>106.94</td>\n",
              "      <td>36.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-17</td>\n",
              "      <td>1</td>\n",
              "      <td>69.12</td>\n",
              "      <td>15.0</td>\n",
              "      <td>79.32</td>\n",
              "      <td>86.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.92</td>\n",
              "      <td>100.00</td>\n",
              "      <td>104.84</td>\n",
              "      <td>36.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-18</td>\n",
              "      <td>2</td>\n",
              "      <td>59.90</td>\n",
              "      <td>15.0</td>\n",
              "      <td>80.55</td>\n",
              "      <td>78.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.81</td>\n",
              "      <td>100.00</td>\n",
              "      <td>97.11</td>\n",
              "      <td>36.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-19</td>\n",
              "      <td>3</td>\n",
              "      <td>62.71</td>\n",
              "      <td>15.0</td>\n",
              "      <td>75.09</td>\n",
              "      <td>85.70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.14</td>\n",
              "      <td>100.00</td>\n",
              "      <td>108.69</td>\n",
              "      <td>36.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-20</td>\n",
              "      <td>4</td>\n",
              "      <td>56.38</td>\n",
              "      <td>15.0</td>\n",
              "      <td>65.62</td>\n",
              "      <td>80.16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.15</td>\n",
              "      <td>100.00</td>\n",
              "      <td>103.93</td>\n",
              "      <td>36.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-21</td>\n",
              "      <td>1</td>\n",
              "      <td>47.16</td>\n",
              "      <td>15.0</td>\n",
              "      <td>80.74</td>\n",
              "      <td>78.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.02</td>\n",
              "      <td>100.00</td>\n",
              "      <td>110.39</td>\n",
              "      <td>36.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>001</td>\n",
              "      <td>2024-01-22</td>\n",
              "      <td>2</td>\n",
              "      <td>64.56</td>\n",
              "      <td>15.0</td>\n",
              "      <td>74.19</td>\n",
              "      <td>87.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.77</td>\n",
              "      <td>100.00</td>\n",
              "      <td>110.75</td>\n",
              "      <td>36.61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SPELL_IDENTIFIER       date  hours_grouped  Diastolic Blood Pressure  Glasgow Coma Score  Heart Rate  Mean Arterial Pressure  NEWS Conscious Level Score  NEWS Supplemental Oxygen Calc  Respiratory Rate    SpO2  Systolic Blood Pressure  Temperature\n",
              "0               001 2024-01-01              1                     70.59                15.0      104.74                   85.10                         0.0                            0.0             19.10   94.72                    99.61        36.79\n",
              "1               001 2024-01-02              2                     63.19                15.0      103.87                   81.79                         0.0                            0.0             19.81   94.92                   100.39        36.72\n",
              "2               001 2024-01-03              3                     66.33                15.0       95.25                   84.16                         0.0                            0.0             18.85   96.38                   101.99        36.58\n",
              "3               001 2024-01-04              4                     73.17                15.0      111.49                   89.20                         0.0                            0.0             20.29   95.69                   105.23        36.60\n",
              "4               001 2024-01-05              1                     71.15                15.0       89.10                   86.92                         0.0                            0.0             20.02   96.15                   102.69        36.70\n",
              "5               001 2024-01-06              2                     55.71                15.0       99.84                   75.71                         0.0                            0.0             18.92   97.04                    95.70        36.67\n",
              "6               001 2024-01-07              3                     66.17                15.0       92.37                   83.44                         0.0                            0.0             19.50   97.50                   100.70        36.67\n",
              "7               001 2024-01-08              4                     60.19                15.0      102.07                   75.04                         0.0                            0.0             17.54   99.31                    89.89        36.48\n",
              "8               001 2024-01-09              1                     60.46                15.0       92.73                   84.92                         0.0                            0.0             16.91   99.29                   109.39        36.61\n",
              "9               001 2024-01-10              2                     63.24                15.0       85.38                   78.69                         0.0                            0.0             19.10   99.32                    94.14        36.55\n",
              "10              001 2024-01-11              3                     61.80                15.0       93.95                   79.67                         0.0                            0.0             18.62   99.11                    97.55        36.64\n",
              "11              001 2024-01-12              4                     68.91                15.0       96.44                   87.19                         0.0                            0.0             19.04  100.00                   105.47        36.61\n",
              "12              001 2024-01-13              1                     65.14                15.0       91.78                   82.60                         0.0                            0.0             21.01  100.00                   100.05        36.69\n",
              "13              001 2024-01-14              2                     61.68                15.0       92.34                   88.67                         0.0                            0.0             19.12  100.00                   115.67        36.64\n",
              "14              001 2024-01-15              3                     63.42                15.0       82.65                   79.84                         0.0                            0.0             16.71  100.00                    96.26        36.68\n",
              "15              001 2024-01-16              4                     62.83                15.0       83.53                   84.88                         0.0                            0.0             19.02  100.00                   106.94        36.58\n",
              "16              001 2024-01-17              1                     69.12                15.0       79.32                   86.98                         0.0                            0.0             15.92  100.00                   104.84        36.54\n",
              "17              001 2024-01-18              2                     59.90                15.0       80.55                   78.51                         0.0                            0.0             16.81  100.00                    97.11        36.58\n",
              "18              001 2024-01-19              3                     62.71                15.0       75.09                   85.70                         0.0                            0.0             17.14  100.00                   108.69        36.61\n",
              "19              001 2024-01-20              4                     56.38                15.0       65.62                   80.16                         0.0                            0.0             19.15  100.00                   103.93        36.65\n",
              "20              001 2024-01-21              1                     47.16                15.0       80.74                   78.78                         0.0                            0.0             16.02  100.00                   110.39        36.80\n",
              "21              001 2024-01-22              2                     64.56                15.0       74.19                   87.65                         0.0                            0.0             15.77  100.00                   110.75        36.61"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "synthetic_data.round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711550247706
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "### Need to add demographics and comorbidites ### \n",
        "\n",
        "# Add po_flag column at the specified location\n",
        "label_data = [0, 0, 0, 1, 1, 1]\n",
        "final_synthetic_data['po_flag'] = label_data\n",
        "\n",
        "# Demographics \n",
        "final_synthetic_data['AGE'] = 0.30\n",
        "final_synthetic_data['IMDDECIL'] = 0.888889\n",
        "final_synthetic_data['GENDER_DESC_Female'] = 1.0\n",
        "final_synthetic_data['GENDER_DESC_Male'] = 0.0\n",
        "final_synthetic_data['grouped_ethincity_Asian'] = 0.0\n",
        "final_synthetic_data['grouped_ethincity_Black'] = 0.0\n",
        "final_synthetic_data['grouped_ethincity_Other'] = 0.0\n",
        "final_synthetic_data['grouped_ethincity_White'] = 1.0\n",
        "final_synthetic_data['uti'] = 1.0\n",
        "final_synthetic_data['pneumonia'] = 0.0\n",
        "final_synthetic_data['sepsis'] = 0.0\n",
        "final_synthetic_data['cellulitis'] = 0.0\n",
        "\n",
        "# Make sure to make above and below float and not int!\n",
        "\n",
        "# Add comorbidity columns and fill them with 0\n",
        "for col in model_data.iloc[:, 267:].columns:\n",
        "    final_synthetic_data[col] = 0.0\n",
        "\n",
        "# Change spesfic comorbidities if neccisary\n",
        "# Cateract\n",
        "final_synthetic_data['193570009'] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1710419371651
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stay_id</th>\n",
              "      <th>po_flag</th>\n",
              "      <th>Diastolic Blood Pressure0</th>\n",
              "      <th>Diastolic Blood Pressure1</th>\n",
              "      <th>Diastolic Blood Pressure10</th>\n",
              "      <th>Diastolic Blood Pressure17</th>\n",
              "      <th>Diastolic Blood Pressure22</th>\n",
              "      <th>Diastolic Blood Pressure23</th>\n",
              "      <th>Diastolic Blood Pressure0_current_stay</th>\n",
              "      <th>Diastolic Blood Pressure1_current_stay</th>\n",
              "      <th>Diastolic Blood Pressure7_current_stay</th>\n",
              "      <th>Diastolic Blood Pressure9_current_stay</th>\n",
              "      <th>Diastolic Blood Pressure10_current_stay</th>\n",
              "      <th>Diastolic Blood Pressure11_current_stay</th>\n",
              "      <th>Diastolic Blood Pressure15_current_stay</th>\n",
              "      <th>Diastolic Blood Pressure17_current_stay</th>\n",
              "      <th>Diastolic Blood Pressure22_current_stay</th>\n",
              "      <th>Diastolic Blood Pressure23_current_stay</th>\n",
              "      <th>Glasgow Coma Score22</th>\n",
              "      <th>Glasgow Coma Score23</th>\n",
              "      <th>...</th>\n",
              "      <th>49631001</th>\n",
              "      <th>63171007</th>\n",
              "      <th>429271009</th>\n",
              "      <th>232440009</th>\n",
              "      <th>3321001</th>\n",
              "      <th>218613000</th>\n",
              "      <th>423716004</th>\n",
              "      <th>263226008</th>\n",
              "      <th>283473009</th>\n",
              "      <th>18283000</th>\n",
              "      <th>110081000119109</th>\n",
              "      <th>59997006</th>\n",
              "      <th>725910009</th>\n",
              "      <th>370247008</th>\n",
              "      <th>126962006</th>\n",
              "      <th>94602001</th>\n",
              "      <th>429447000</th>\n",
              "      <th>7678002</th>\n",
              "      <th>446979005</th>\n",
              "      <th>249944006</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001</td>\n",
              "      <td>1</td>\n",
              "      <td>0.401739</td>\n",
              "      <td>0.371042</td>\n",
              "      <td>0.468884</td>\n",
              "      <td>0.576748</td>\n",
              "      <td>0.364757</td>\n",
              "      <td>0.179284</td>\n",
              "      <td>0.406681</td>\n",
              "      <td>0.374575</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.506938</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.269577</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.361299</td>\n",
              "      <td>0.163484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001</td>\n",
              "      <td>1</td>\n",
              "      <td>0.393152</td>\n",
              "      <td>0.389206</td>\n",
              "      <td>0.468032</td>\n",
              "      <td>0.565610</td>\n",
              "      <td>0.374097</td>\n",
              "      <td>0.172812</td>\n",
              "      <td>0.395559</td>\n",
              "      <td>0.356423</td>\n",
              "      <td>2.761707e-31</td>\n",
              "      <td>0.205404</td>\n",
              "      <td>0.531704</td>\n",
              "      <td>0.562907</td>\n",
              "      <td>0.437901</td>\n",
              "      <td>0.502328</td>\n",
              "      <td>0.366393</td>\n",
              "      <td>0.161605</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001</td>\n",
              "      <td>1</td>\n",
              "      <td>0.370148</td>\n",
              "      <td>0.413000</td>\n",
              "      <td>0.674006</td>\n",
              "      <td>0.592753</td>\n",
              "      <td>0.408618</td>\n",
              "      <td>0.294808</td>\n",
              "      <td>0.379435</td>\n",
              "      <td>0.376695</td>\n",
              "      <td>3.547259e-30</td>\n",
              "      <td>0.261800</td>\n",
              "      <td>0.587515</td>\n",
              "      <td>0.358459</td>\n",
              "      <td>0.795180</td>\n",
              "      <td>0.520128</td>\n",
              "      <td>0.380714</td>\n",
              "      <td>0.236833</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows  2883 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  stay_id  po_flag  Diastolic Blood Pressure0  Diastolic Blood Pressure1  Diastolic Blood Pressure10  Diastolic Blood Pressure17  Diastolic Blood Pressure22  Diastolic Blood Pressure23  Diastolic Blood Pressure0_current_stay  Diastolic Blood Pressure1_current_stay  Diastolic Blood Pressure7_current_stay  Diastolic Blood Pressure9_current_stay  Diastolic Blood Pressure10_current_stay  Diastolic Blood Pressure11_current_stay  Diastolic Blood Pressure15_current_stay  Diastolic Blood Pressure17_current_stay  Diastolic Blood Pressure22_current_stay  Diastolic Blood Pressure23_current_stay  Glasgow Coma Score22  Glasgow Coma Score23  ...  49631001  63171007  429271009  232440009  3321001  218613000  423716004  263226008  283473009  18283000  110081000119109  59997006  725910009  370247008  126962006  94602001  429447000  7678002  446979005  249944006\n",
              "0     001        1                   0.401739                   0.371042                    0.468884                    0.576748                    0.364757                    0.179284                                0.406681                                0.374575                            0.000000e+00                                0.000000                                 0.506938                                 0.500000                                 0.269577                                -1.000000                                 0.361299                                 0.163484                   0.0                   0.0  ...       0.0       0.0        0.0        0.0      0.0        0.0        0.0        0.0        0.0       0.0              0.0       0.0        0.0        0.0        0.0       0.0        0.0      0.0        0.0        0.0\n",
              "1     001        1                   0.393152                   0.389206                    0.468032                    0.565610                    0.374097                    0.172812                                0.395559                                0.356423                            2.761707e-31                                0.205404                                 0.531704                                 0.562907                                 0.437901                                 0.502328                                 0.366393                                 0.161605                   0.0                   0.0  ...       0.0       0.0        0.0        0.0      0.0        0.0        0.0        0.0        0.0       0.0              0.0       0.0        0.0        0.0        0.0       0.0        0.0      0.0        0.0        0.0\n",
              "2     001        1                   0.370148                   0.413000                    0.674006                    0.592753                    0.408618                    0.294808                                0.379435                                0.376695                            3.547259e-30                                0.261800                                 0.587515                                 0.358459                                 0.795180                                 0.520128                                 0.380714                                 0.236833                   0.0                   0.0  ...       0.0       0.0        0.0        0.0      0.0        0.0        0.0        0.0        0.0       0.0              0.0       0.0        0.0        0.0        0.0       0.0        0.0      0.0        0.0        0.0\n",
              "\n",
              "[3 rows x 2883 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_synthetic_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1711550249796
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on set_transformer_processing_fun...\n",
            "Done!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|| 1/1 [00:00<00:00, 57.98it/s]\n"
          ]
        }
      ],
      "source": [
        "### Obtain embeddings ###\n",
        "synthetic_embeddings = embedding_fun(final_synthetic_data, model, snomed_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1711550252766
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "### Find most closly matched patients ###\n",
        "# Get closest point for each point\n",
        "distance, index = spatial.KDTree(main_embeddings).query(synthetic_embeddings, k=15)\n",
        "index = pd.DataFrame(index)\n",
        "index.columns = {x:y for x,y in zip(index.columns,range(0,len(index.columns)))}\n",
        "distance = pd.DataFrame(distance)\n",
        "distance.columns = {x:y for x,y in zip(distance.columns,range(0,len(distance.columns)))}\n",
        "distance = 1/distance # Make it so larger is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "gather": {
          "logged": 1711449104899
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.199413</td>\n",
              "      <td>0.196416</td>\n",
              "      <td>0.196013</td>\n",
              "      <td>0.191634</td>\n",
              "      <td>0.190926</td>\n",
              "      <td>0.188076</td>\n",
              "      <td>0.187624</td>\n",
              "      <td>0.186396</td>\n",
              "      <td>0.185299</td>\n",
              "      <td>0.184870</td>\n",
              "      <td>0.184177</td>\n",
              "      <td>0.183880</td>\n",
              "      <td>0.183527</td>\n",
              "      <td>0.182432</td>\n",
              "      <td>0.181453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.226828</td>\n",
              "      <td>0.192639</td>\n",
              "      <td>0.190055</td>\n",
              "      <td>0.189787</td>\n",
              "      <td>0.188291</td>\n",
              "      <td>0.182523</td>\n",
              "      <td>0.182119</td>\n",
              "      <td>0.181615</td>\n",
              "      <td>0.181428</td>\n",
              "      <td>0.181201</td>\n",
              "      <td>0.180991</td>\n",
              "      <td>0.180773</td>\n",
              "      <td>0.179785</td>\n",
              "      <td>0.178176</td>\n",
              "      <td>0.178152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.237640</td>\n",
              "      <td>0.225511</td>\n",
              "      <td>0.215522</td>\n",
              "      <td>0.211760</td>\n",
              "      <td>0.211655</td>\n",
              "      <td>0.209591</td>\n",
              "      <td>0.208685</td>\n",
              "      <td>0.208511</td>\n",
              "      <td>0.206955</td>\n",
              "      <td>0.206702</td>\n",
              "      <td>0.206361</td>\n",
              "      <td>0.204583</td>\n",
              "      <td>0.203988</td>\n",
              "      <td>0.203746</td>\n",
              "      <td>0.202520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.278555</td>\n",
              "      <td>0.250271</td>\n",
              "      <td>0.244711</td>\n",
              "      <td>0.242455</td>\n",
              "      <td>0.239117</td>\n",
              "      <td>0.238894</td>\n",
              "      <td>0.238401</td>\n",
              "      <td>0.229019</td>\n",
              "      <td>0.228538</td>\n",
              "      <td>0.227520</td>\n",
              "      <td>0.224044</td>\n",
              "      <td>0.223663</td>\n",
              "      <td>0.220741</td>\n",
              "      <td>0.220621</td>\n",
              "      <td>0.220563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.267615</td>\n",
              "      <td>0.263257</td>\n",
              "      <td>0.261132</td>\n",
              "      <td>0.254029</td>\n",
              "      <td>0.237267</td>\n",
              "      <td>0.236160</td>\n",
              "      <td>0.232577</td>\n",
              "      <td>0.229590</td>\n",
              "      <td>0.229461</td>\n",
              "      <td>0.229176</td>\n",
              "      <td>0.222128</td>\n",
              "      <td>0.220909</td>\n",
              "      <td>0.216584</td>\n",
              "      <td>0.213895</td>\n",
              "      <td>0.213603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.271758</td>\n",
              "      <td>0.269161</td>\n",
              "      <td>0.262519</td>\n",
              "      <td>0.262491</td>\n",
              "      <td>0.249495</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.237314</td>\n",
              "      <td>0.236427</td>\n",
              "      <td>0.235026</td>\n",
              "      <td>0.229889</td>\n",
              "      <td>0.228966</td>\n",
              "      <td>0.219927</td>\n",
              "      <td>0.219843</td>\n",
              "      <td>0.217364</td>\n",
              "      <td>0.217089</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2         3         4         5         6         7         8         9         10        11        12        13        14\n",
              "0  0.199413  0.196416  0.196013  0.191634  0.190926  0.188076  0.187624  0.186396  0.185299  0.184870  0.184177  0.183880  0.183527  0.182432  0.181453\n",
              "1  0.226828  0.192639  0.190055  0.189787  0.188291  0.182523  0.182119  0.181615  0.181428  0.181201  0.180991  0.180773  0.179785  0.178176  0.178152\n",
              "2  0.237640  0.225511  0.215522  0.211760  0.211655  0.209591  0.208685  0.208511  0.206955  0.206702  0.206361  0.204583  0.203988  0.203746  0.202520\n",
              "3  0.278555  0.250271  0.244711  0.242455  0.239117  0.238894  0.238401  0.229019  0.228538  0.227520  0.224044  0.223663  0.220741  0.220621  0.220563\n",
              "4  0.267615  0.263257  0.261132  0.254029  0.237267  0.236160  0.232577  0.229590  0.229461  0.229176  0.222128  0.220909  0.216584  0.213895  0.213603\n",
              "5  0.271758  0.269161  0.262519  0.262491  0.249495  0.239216  0.237314  0.236427  0.235026  0.229889  0.228966  0.219927  0.219843  0.217364  0.217089"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "gather": {
          "logged": 1711449101982
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3399</td>\n",
              "      <td>20170</td>\n",
              "      <td>13270</td>\n",
              "      <td>4398</td>\n",
              "      <td>24568</td>\n",
              "      <td>1457</td>\n",
              "      <td>20745</td>\n",
              "      <td>21205</td>\n",
              "      <td>27009</td>\n",
              "      <td>15608</td>\n",
              "      <td>2915</td>\n",
              "      <td>22554</td>\n",
              "      <td>4007</td>\n",
              "      <td>23601</td>\n",
              "      <td>13877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21206</td>\n",
              "      <td>21293</td>\n",
              "      <td>9549</td>\n",
              "      <td>21207</td>\n",
              "      <td>9548</td>\n",
              "      <td>28113</td>\n",
              "      <td>22917</td>\n",
              "      <td>9547</td>\n",
              "      <td>13878</td>\n",
              "      <td>7158</td>\n",
              "      <td>13271</td>\n",
              "      <td>17423</td>\n",
              "      <td>3400</td>\n",
              "      <td>13879</td>\n",
              "      <td>28388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21207</td>\n",
              "      <td>21206</td>\n",
              "      <td>28113</td>\n",
              "      <td>9549</td>\n",
              "      <td>9548</td>\n",
              "      <td>17423</td>\n",
              "      <td>9551</td>\n",
              "      <td>28112</td>\n",
              "      <td>9550</td>\n",
              "      <td>7158</td>\n",
              "      <td>21293</td>\n",
              "      <td>3402</td>\n",
              "      <td>15003</td>\n",
              "      <td>10540</td>\n",
              "      <td>22917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21207</td>\n",
              "      <td>21206</td>\n",
              "      <td>9549</td>\n",
              "      <td>9551</td>\n",
              "      <td>9550</td>\n",
              "      <td>9548</td>\n",
              "      <td>3402</td>\n",
              "      <td>28113</td>\n",
              "      <td>9552</td>\n",
              "      <td>15003</td>\n",
              "      <td>3401</td>\n",
              "      <td>7158</td>\n",
              "      <td>3403</td>\n",
              "      <td>17423</td>\n",
              "      <td>9553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9551</td>\n",
              "      <td>21207</td>\n",
              "      <td>9550</td>\n",
              "      <td>9552</td>\n",
              "      <td>9549</td>\n",
              "      <td>9553</td>\n",
              "      <td>15003</td>\n",
              "      <td>21206</td>\n",
              "      <td>3402</td>\n",
              "      <td>3404</td>\n",
              "      <td>3403</td>\n",
              "      <td>9548</td>\n",
              "      <td>29241</td>\n",
              "      <td>29239</td>\n",
              "      <td>15005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9551</td>\n",
              "      <td>21207</td>\n",
              "      <td>9552</td>\n",
              "      <td>9550</td>\n",
              "      <td>9553</td>\n",
              "      <td>9549</td>\n",
              "      <td>3404</td>\n",
              "      <td>15003</td>\n",
              "      <td>3402</td>\n",
              "      <td>21206</td>\n",
              "      <td>3403</td>\n",
              "      <td>9548</td>\n",
              "      <td>29241</td>\n",
              "      <td>15004</td>\n",
              "      <td>15005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0      1      2      3      4      5      6      7      8      9      10     11     12     13     14\n",
              "0   3399  20170  13270   4398  24568   1457  20745  21205  27009  15608   2915  22554   4007  23601  13877\n",
              "1  21206  21293   9549  21207   9548  28113  22917   9547  13878   7158  13271  17423   3400  13879  28388\n",
              "2  21207  21206  28113   9549   9548  17423   9551  28112   9550   7158  21293   3402  15003  10540  22917\n",
              "3  21207  21206   9549   9551   9550   9548   3402  28113   9552  15003   3401   7158   3403  17423   9553\n",
              "4   9551  21207   9550   9552   9549   9553  15003  21206   3402   3404   3403   9548  29241  29239  15005\n",
              "5   9551  21207   9552   9550   9553   9549   3404  15003   3402  21206   3403   9548  29241  15004  15005"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "gather": {
          "logged": 1711447969860
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AGE                             0.3\n",
              "IMDDECIL                   0.888889\n",
              "GENDER_DESC_Female              1.0\n",
              "GENDER_DESC_Male                0.0\n",
              "grouped_ethincity_Asian         0.0\n",
              "grouped_ethincity_Black         0.0\n",
              "grouped_ethincity_Other         0.0\n",
              "grouped_ethincity_White         1.0\n",
              "uti                             1.0\n",
              "pneumonia                       0.0\n",
              "sepsis                          0.0\n",
              "cellulitis                      0.0\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Demograpics of case\n",
        "final_synthetic_data.iloc[0,255:267].T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711449147143
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Demograpics of similar examples (Day 5)\n",
        "d = 5\n",
        "\n",
        "subset = model_data.loc[index.loc[d].values.tolist()]\n",
        "subset = subset.loc[[9551, 21207, 3404, 15003, 29241]] # Select only those relevant / unique\n",
        "\n",
        "subset.iloc[:,255:267]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "gather": {
          "logged": 1711447990124
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "193570009    1.0\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Comorbidities of case\n",
        "final_synthetic_data.iloc[0, 267:][final_synthetic_data.iloc[0, 267:] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711449155036
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Comorbidities of similar examples (Day 5)\n",
        "d = 5\n",
        "\n",
        "subset = model_data.loc[index.loc[d].values.tolist()]\n",
        "subset = subset.loc[[9551, 21207, 3404, 15003, 29241]] # Select only those relevant / unique\n",
        "\n",
        "for n in range(len(subset)):\n",
        "    print(subset.iloc[n].name)\n",
        "    subset.iloc[n, 267:][subset.iloc[n, 267:] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711449164863
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Obtain predictions for similar examples (day 5) #\n",
        "# Select patient\n",
        "d = 5\n",
        "temp_data = model_data.loc[index.loc[d].values.tolist()]\n",
        "# Split up dfs\n",
        "vitals_data = temp_data.iloc[:,2:255]\n",
        "demographics_data = temp_data.iloc[:,255:267]\n",
        "comorbidity_data = temp_data.iloc[:, 267:]\n",
        "\n",
        "# Get labels\n",
        "labels = temp_data[['po_flag']]\n",
        "\n",
        "# Preprocess comorbidity data\n",
        "print('Working on set_transformer_processing_fun...')\n",
        "comorbidity_data, comorbidity_mask = set_transformer_processing_fun(comorbidity_data, snomed_embedding)\n",
        "print('Done!')\n",
        "\n",
        "# Define batch size\n",
        "batch_size = len(vitals_data)\n",
        "\n",
        "# Define dataloaders\n",
        "train_dataset =  MultiInputDataset([vitals_data, demographics_data], labels, comorbidity_data, comorbidity_mask)\n",
        "dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
        "\n",
        "# Define loss\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Evaluate\n",
        "loss, auroc, predictions, labels_out = evaluate(model, dataloader, criterion)\n",
        "\n",
        "# Apply threshold \n",
        "new_predictions = new_threshold_fun(predictions)\n",
        "\n",
        "output_df = temp_data.iloc[:, :2]\n",
        "output_df['labels_out'] = labels_out\n",
        "output_df['new_predictions'] = new_predictions\n",
        "output_df['predictions'] = predictions\n",
        "output_df.loc[[9551, 21207, 3404, 15003, 29241]]\n",
        "#output_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "gather": {
          "logged": 1711449182219
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_447234/3426371078.py:28: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  cbar.set_ticklabels(['0%', '20%', '40%', '60%', '80%', '100%'])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Features')"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Similar Patient')"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Difference for similar examples (Day 5) - final\n",
        "d = 5\n",
        "\n",
        "subset = model_data.loc[index.loc[d].values.tolist()]\n",
        "subset = subset.loc[[9551, 21207, 3404, 15003, 29241]] # Select only those relevant / unique\n",
        "subset = subset.iloc[:,2:255]\n",
        "subset = subset.replace(-1, 0)\n",
        "difference = subset.sub(final_synthetic_data.iloc[d,2:255].replace(-1, 0)).abs()\n",
        "\n",
        "# Set the figure size, adjusting the height to make it taller\n",
        "fig, ax = plt.subplots(figsize=(10, 6)) \n",
        "\n",
        "# Plot the heatmap\n",
        "bottom = 5.5\n",
        "top = 0.5\n",
        "left = -0.5\n",
        "right = 253.5\n",
        "extent = [left, right, bottom, top]\n",
        "\n",
        "im = ax.imshow(difference, cmap='viridis', interpolation='none', aspect='auto', extent=extent)\n",
        "\n",
        "# Add colorbar\n",
        "cbar = ax.figure.colorbar(im, ax=ax)\n",
        "cbar.set_label('Difference between features')\n",
        "# Set the range of the color bar to 0 and 1\n",
        "cbar.mappable.set_clim(vmin=0, vmax=1)\n",
        "# Change the format of tick labels on the color bar to percentage\n",
        "cbar.set_ticklabels(['0%', '20%', '40%', '60%', '80%', '100%'])\n",
        "\n",
        "# Set labels and title\n",
        "#ax.set_title('Similarity Heatmap')\n",
        "ax.set_xlabel('Features')\n",
        "ax.set_ylabel('Similar Patient')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "gather": {
          "logged": 1711447800090
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on set_transformer_processing_fun...\n",
            "Done!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|| 1/1 [00:00<00:00, 50.20it/s]\n"
          ]
        }
      ],
      "source": [
        "### Obtain predictions ###\n",
        "# Split up dfs\n",
        "vitals_data = final_synthetic_data.iloc[:,2:255]\n",
        "demographics_data = final_synthetic_data.iloc[:,255:267]\n",
        "comorbidity_data = final_synthetic_data.iloc[:, 267:]\n",
        "\n",
        "# Get labels\n",
        "labels = final_synthetic_data[['po_flag']]\n",
        "\n",
        "# Preprocess comorbidity data\n",
        "print('Working on set_transformer_processing_fun...')\n",
        "comorbidity_data, comorbidity_mask = set_transformer_processing_fun(comorbidity_data, snomed_embedding)\n",
        "print('Done!')\n",
        "\n",
        "#Define batch size\n",
        "batch_size = len(vitals_data)\n",
        "\n",
        "# Define dataloaders\n",
        "train_dataset =  MultiInputDataset([vitals_data, demographics_data], labels, comorbidity_data, comorbidity_mask)\n",
        "dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
        "\n",
        "# Define loss\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Evaluate\n",
        "loss, auroc, predictions, labels_out = evaluate(model, dataloader, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "gather": {
          "logged": 1711447802940
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Apply threshold \n",
        "new_predictions = new_threshold_fun(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "gather": {
          "logged": 1711447815163
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.5       , 0.5       , 0.5514007 , 0.66838676, 0.7259835 ,\n",
              "       0.7542743 ], dtype=float32)"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "array([0., 0., 1., 1., 1., 1.], dtype=float32)"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 1]"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 1., 1.], dtype=float32)"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions\n",
        "predictions.round()\n",
        "new_predictions\n",
        "labels_out"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
